<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<?asciidoc-toc?>
<?asciidoc-numbered?>

<article lang="en">
<articleinfo>
    <title>The Data Journalism Handbook</title>
</articleinfo>
<section id="_0_前付け">
<title>0. 前付け</title>
<section id="_偉大なる無名の協力者達に">
<title>偉大なる無名の協力者達に</title>
<figure id="FIG1"><title>かくしてすべては始まった</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/00-01.jpg" contentwidth="600"/>
  </imageobject>
  <textobject><phrase>figs/incoming/00-01.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>データジャーナリズムハンドブックは、ロンドンで開かれたMozilla Festival 2011における48時間のワークショップで誕生した。その後、データジャーナリズムの中心人物や最良の実践者たちを巻き込んだ国際的な共同作業の取り組みにまで広がった。</simpara>
<simpara>全文が公開されるまでの6ヶ月間、何百もの人たちが様々な形で貢献してくれた。彼ら全員を記録すべく最善を尽くしてきたが、匿名、ハンドルネーム、また追跡できない人たちによって編集された部分もかなりある。</simpara>
<simpara>貢献したにもかかわらず、以下に名前のない方々全員に二つのことを伝えたい。一つ目に、協力に感謝する。二つ目に、しかるべきところにクレジットを与えられるようどうかお名前を教えていただきたい。</simpara>
</section>
<section id="_貢献した人たち">
<title>貢献した人たち</title>
<simpara>以下の人たちが、本書の現バージョンに文章を書いたり、あるいは別の方法で直接貢献してくれた。イラストはグラフィックデザイナーのケイト・ハドソンによるものである。</simpara>
<itemizedlist>
<listitem>
<simpara>
グレゴール・アイシュ, オープンナレッジ財団
</simpara>
</listitem>
<listitem>
<simpara>
ブリジット・アルフター, Journalismfund.eu
</simpara>
</listitem>
<listitem>
<simpara>
デヴィッド・アンダートン, フリージャーナリスト
</simpara>
</listitem>
<listitem>
<simpara>
ジェームス・ボール, ガーディアン
</simpara>
</listitem>
<listitem>
<simpara>
カエラン・バー, Citywire
</simpara>
</listitem>
<listitem>
<simpara>
マリアナ・ベルーゾ, Hacks/Hackers Buenos Aires
</simpara>
</listitem>
<listitem>
<simpara>
マイケル・ブラストランド, フリージャーナリスト
</simpara>
</listitem>
<listitem>
<simpara>
マリアーノ・Blejman, Hacks/Hackers Buenos Aires
</simpara>
</listitem>
<listitem>
<simpara>
ジョン・ボーンズ, ヴェルデンス・ガング
</simpara>
</listitem>
<listitem>
<simpara>
マリアンヌ・ボーチャート, ブルームバーグ・ニュース
</simpara>
</listitem>
<listitem>
<simpara>
リリアナ・ボーネグル, ヨーロッパ・ジャーナリズム・センター
</simpara>
</listitem>
<listitem>
<simpara>
ブライアン・ボイヤー, シカゴ・トリビューン
</simpara>
</listitem>
<listitem>
<simpara>
ポール・ブラッドショー, バーミンガム市立大学
</simpara>
</listitem>
<listitem>
<simpara>
ウェンディ・カーライル, オーストラリア放送協会
</simpara>
</listitem>
<listitem>
<simpara>
ルーシー・チェンバース, オープンナレッジ財団
</simpara>
</listitem>
<listitem>
<simpara>
サラ・コーエン, デューク大学
</simpara>
</listitem>
<listitem>
<simpara>
アラステア・ダント, ガーディアン
</simpara>
</listitem>
<listitem>
<simpara>
ヘレン・ダービーシャ, Access Info Europe
</simpara>
</listitem>
<listitem>
<simpara>
チェース・デイヴィス, Center for Investigative Reporting
</simpara>
</listitem>
<listitem>
<simpara>
スティーヴ・ドイグ, アリゾナ州立大学ウォルター・クロンカイト・ジャーナリズムスクール
</simpara>
</listitem>
<listitem>
<simpara>
リサ・エヴァンス, ガーディアン
</simpara>
</listitem>
<listitem>
<simpara>
トム・フリーズ, Bertelsmann Stiftung
</simpara>
</listitem>
<listitem>
<simpara>
ダンカン・ジーレ, ワイアードUK
</simpara>
</listitem>
<listitem>
<simpara>
ジャック・ギラム, AP通信
</simpara>
</listitem>
<listitem>
<simpara>
ジョナサン・グレイ, オープンナレッジ財団
</simpara>
</listitem>
<listitem>
<simpara>
アレックス・ハワード, オライリー・メディア
</simpara>
</listitem>
<listitem>
<simpara>
ベラ・ハレル, BBC
</simpara>
</listitem>
<listitem>
<simpara>
ニコラス・カイザー＝ブリル, Journalism++
</simpara>
</listitem>
<listitem>
<simpara>
ジョン・キーフ, WNYC
</simpara>
</listitem>
<listitem>
<simpara>
スコット・クライン, ProPublica
</simpara>
</listitem>
<listitem>
<simpara>
アレキサンドル・Léchenet, ル・モンド
</simpara>
</listitem>
<listitem>
<simpara>
マーク・リー・ハンター, INSEAD
</simpara>
</listitem>
<listitem>
<simpara>
アンドリュー・Leimdorfer, BBC
</simpara>
</listitem>
<listitem>
<simpara>
フリードリッヒ・リンデンバーグ, オープンナレッジ財団
</simpara>
</listitem>
<listitem>
<simpara>
マイク・Linksvayer, クリエイティブ・コモンズ
  ミルコ・ロレンス, ドイチェ・ヴェレ
</simpara>
</listitem>
<listitem>
<simpara>
Esa Mäkinen, ヘルシンギン・サノマット
</simpara>
</listitem>
<listitem>
<simpara>
ペドロ・マークン, Transparência Hacker
</simpara>
</listitem>
<listitem>
<simpara>
Isao Matsunami, 東京新聞
</simpara>
</listitem>
<listitem>
<simpara>
ローレンス・Matzat, OpenDataCity
</simpara>
</listitem>
<listitem>
<simpara>
ジェフ・マッギー, スタンフォード大学
</simpara>
</listitem>
<listitem>
<simpara>
フィリップ・メイヤー, ノースカロライナ大学チャペルヒル校名誉教授
</simpara>
</listitem>
<listitem>
<simpara>
クレア・ミラー, WalesOnline
</simpara>
</listitem>
<listitem>
<simpara>
シンシア・O’Murchu, フィナンシャル・タイムズ
</simpara>
</listitem>
<listitem>
<simpara>
Oluseun Onigbinde, BudgIT
</simpara>
</listitem>
<listitem>
<simpara>
ジョルジェ・Padejski, ナイト・ジャーナリズム・フェロー、スタンフォード大学
</simpara>
</listitem>
<listitem>
<simpara>
ジェーン・パーク, クリエイティブ・コモンズ
</simpara>
</listitem>
<listitem>
<simpara>
アンジェリカ・ペラルタ・ラモス, La Nacion（アルゼンチン）
</simpara>
</listitem>
<listitem>
<simpara>
シェリル・フィリップス, シアトル・タイムズ
</simpara>
</listitem>
<listitem>
<simpara>
アロン・Pilhofer, ニューヨーク・タイムズ
</simpara>
</listitem>
<listitem>
<simpara>
ルル・ピニー, フリーのインフォグラフィックデザイナー
</simpara>
</listitem>
<listitem>
<simpara>
ポール・ラドゥ, Organised Crime and Corruption Reporting Project
</simpara>
</listitem>
<listitem>
<simpara>
サイモン・ロジャース, ガーディアン
</simpara>
</listitem>
<listitem>
<simpara>
マーティン・ローゼンバウム, BBC
</simpara>
</listitem>
<listitem>
<simpara>
アマンダ・ロッシ, Friends of Januária
</simpara>
</listitem>
<listitem>
<simpara>
マーティン・サラセール, Hacks/Hackers Buenos Aires
</simpara>
</listitem>
<listitem>
<simpara>
ファブリツィオ・Scrollini, ロンドン・スクール・オブ・エコノミクス
</simpara>
</listitem>
<listitem>
<simpara>
サラ・スロービン, ウォール・ストリート・ジャーナル
</simpara>
</listitem>
<listitem>
<simpara>
セルジオ・ソリン, Hacks/Hackers Buenos Aires
</simpara>
</listitem>
<listitem>
<simpara>
ジョナサン・ストレイ, The Overview Project
</simpara>
</listitem>
<listitem>
<simpara>
ブライアン・スーダ, (optional.is)
</simpara>
</listitem>
<listitem>
<simpara>
クリス・タガート, OpenCorporates
</simpara>
</listitem>
<listitem>
<simpara>
Jer Thorp, ニューヨーク・タイムズR&amp;Dグループ
</simpara>
</listitem>
<listitem>
<simpara>
アンディ・トゥ, Hacks/Hackers Buenos Aires
</simpara>
</listitem>
<listitem>
<simpara>
ルーク・N・ファン・ワッセンホフ, INSEAD
</simpara>
</listitem>
<listitem>
<simpara>
サーシャ・ヴェノー, ツァイト・オンライン
</simpara>
</listitem>
<listitem>
<simpara>
ジェリー・ヴァーマネン, NU.nl
</simpara>
</listitem>
<listitem>
<simpara>
セザール・ヴィアナ, ゴイアス大学
</simpara>
</listitem>
<listitem>
<simpara>
ファリダ・ヴィス, レスター大学
</simpara>
</listitem>
<listitem>
<simpara>
ピート・ウォーデン, 独立系データアナリスト兼開発者
</simpara>
</listitem>
<listitem>
<simpara>
クリス・ウー, Hacks/Hackers
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_本書はどういう本か_そして_どういう本ではないか">
<title>本書はどういう本か（そして、どういう本ではないか）</title>
<simpara>本書は、データジャーナリストになる、あるいはデータジャーナリズムに興味を持った人に役に立つ情報源となることを目的としている。</simpara>
<simpara>多くの人たちが本書を書くのに貢献してくれたし、我々は編集する過程を通じて、いろいろな声や意見に光を当てるよう努力してきた。データジャーナリズムとは何か、なぜそれが重要なのか、そしてどうやって実践するのか、豊かで有益な対話をしている、そんなつもりで読んでもらえれば幸いだ。</simpara>
<simpara>残念ながら、本書を読んだからといって、データジャーナリストになるのに必要な知識とスキルがひと通り備わるわけではない。それには、さまざまな疑問に答えられる専門家がいっぱいいる、巨大な図書館が必要だろう。ありがたいことにその図書館は実在し、インターネットと呼ばれている。そうした知識ではなく、本書ではデータジャーナリズムの始め方や、さらに先に進みたい場合にどこに目を向けるべきか、そういった考え方を与えることができれば、と思っている。したがって、例やチュートリアルは網羅的ではないが、説明に役立つものとなっている。</simpara>
<simpara>貢献してくれたすべての人たちから多大な時間、エネルギー、そして忍耐を得て、その有効利用に全力を尽くせて我々は幸運だと思う。我々としては、本書が――有益な情報源となるだけでなく――情熱と熱狂、新たな動きのヴィジョンとエネルギーを記録するものになればと思う。本書は、舞台裏で起こっていること、ストーリーの背後にあるストーリーの感覚を与えようとする試みである。</simpara>
<simpara>データジャーナリズムハンドブックは進行中の作品である。修正されるべき、あるいは欠けているのが目立つところがあると思うなら、次版でそれを入れられるよう注意いただきたい。データジャーナリズムハンドブックはまた、<ulink url="http://creativecommons.org/licenses/by-sa/3.0/">クリエイティブ・コモンズの表示―継承ライセンス</ulink>の下で自由に利用可能なので、興味を持って読んでくれるかもと思う人と本書をシェアすることを強くお勧めする。</simpara>
<simpara><emphasis>リリアーナ・ボーネグル (<ulink url="https://twitter.com/bb_liliana">@bb_liliana</ulink>)</emphasis><?asciidoc-br?>
<emphasis>ルーシー・チェンバース (<ulink url="https://twitter.com/lucyfedia">@lucyfedia</ulink>)</emphasis><?asciidoc-br?>
<emphasis>ジョナサン・グレイ  (<ulink url="https://twitter.com/jwyg">@jwyg</ulink>)</emphasis><?asciidoc-br?>
<emphasis>2012年3月</emphasis></simpara>
</section>
<section id="_ハンドブックを一目で理解する">
<title>ハンドブックを一目で理解する</title>
<simpara>インフォグラフィックの興行主であるルル・ピニーがこの素晴らしいポスターを作ってくれたが、これはデータジャーナリズムハンドブックのの大要を説明するものだ。</simpara>
<figure><title>ハンドブックを一目で理解する</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/00-poster.png" contentwidth="600"/>
  </imageobject>
  <textobject><phrase>[図2]</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_はじめに">
<title>はじめに</title>
<informalfigure role="informal">
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-00-cover.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-00-cover.png</phrase></textobject>
</mediaobject>
</informalfigure>
<?dbfo-need height="1in"?>
<simpara>データジャーナリズムとは何か？データジャーナリズムとはどのような可能性を持っているのか？データジャーナリズムの限界はどこか？このセクションで、我々は「データジャーナリズムとは何か？」と「データジャーナリズムがニュース組織に対して何を意味するのか」について目を向けていく。Paul Bradshaw (Birmingham City University) と Mirko Lorenz (Deutsche Welle)は「データジャーナリズムにおいて何が特色なのか」についてもう少し詳しく話す。データジャーナリストを導くことは我々に、「なぜデータジャーナリストがデータジャーナリズムが重要であると考えているのか」ということと「データジャーナリストの好きな例が何なのか」について教えてくれる。最後に、Liliana Bounegru (European Journalism Centre) はデータジャーナリズムを、より広い歴史的な文脈の中に置いてくれる。</simpara>
<section id="_データジャーナリズムとは何か">
<title>データジャーナリズムとは何か？</title>
<simpara>データジャーナリズムとは何か？ 私なら単純に、データで実現するジャーナリズムと答える。しかし、それではあまり理解の助けにならない。</simpara>
<simpara>「データ」も「ジャーナリズム」と共に厄介な用語だ。スプレッドシートなどまさにそうだが、数字の集合ならなんでも「データ」と考える人もいる。20年前なら、ジャーナリストが扱うデータといえば大概その類だけだった。しかし、我々が今住んでいるのはデジタルな世界、ほとんど何でも数字で表現可能な――そして実際ほとんどすべてがそうなっている――世界なのだ。</simpara>
<simpara>あなたの経歴、30万もの機密文書、あなたの交友関係で誰が誰を知っているかはたった二つの数字で表現可能なのだ（実際表現される）。つまり、0と1である。写真、ビデオ、音声もすべて同じ二つの数字で表現される。0と1だ。殺人、病気、投票、腐敗、そして嘘、これもまた0と1で表現される。</simpara>
<simpara>データジャーナリズムをそれ以外のジャーナリズムと違うものにしているのは何だろう？ おそらく、従来からの「ニュースをかぎつける鼻」や人の心に訴える物語を語る力と現在利用可能な壮大なスケールと範囲に及ぶデジタル情報を組み合わせることで開ける新たな可能性ではないだろうか。</simpara>
<simpara>そしてその可能性は、ジャーナリストの作業過程のどの段階にも入ってくる可能性がある。エイドリアン・ホロヴァッティが<ulink url="http://chicago.everyblock.com/crime/">ChicagoCrime</ulink> で、その後<ulink url="http://www.everyblock.com/">EveryBlock</ulink> で行ったように、プログラミングで地方自治体、警察、その他の市民からの情報を収集して組み合わせるプロセスを自動化するわけだ。</simpara>
<simpara>あるいはテレグラフが<ulink url="http://www.telegraph.co.uk/news/newstopics/mps-expenses/">国会議員の出費</ulink> についてやったように、数十万もの文書間のつながりをソフトウェア使って見つけるとか。</simpara>
<figure id="FIG012"><title>国会議員の出費を調べる（ガーディアン）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-01.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>データジャーナリズムは、ジャーナリストが人をひきつけるインフォグラフィックで複雑な話を説明する助けになりうる。例えば、<ulink url="http://www.gapminder.org/">Gapminder</ulink> で世界の貧困問題を視覚化するハンス・ロスリングの鮮烈な講演は、世界中の数百万もの視聴者を魅了してきた。また巨大な数字――公共支出を関連付けて筋道を通したり、アイスランドの火山によって引き起こされたり、防がれたりする汚染など――を精製してみせるデヴィッド・マッカンドレスの人気作品は、<ulink url="http://www.informationisbeautiful.net/">Information is Beautiful</ulink> における明快なデザインの重要性を見せ付けている。</simpara>
<simpara>データジャーナリズムは、BBCとフィナンシャル・タイムスが現在日常的に予算についてインタラクティブに行うように、データはある記事が個人にどんな関係があるか解説する役に立つ（その予算が「一般大衆」でなくあなたにどんな影響を及ぼすか分かる）。またガーディアンが<ulink url="http://www.guardian.co.uk/news/datablog">Datablog</ulink> でデータ、文脈、そして質問の共有にかなり成功しているように、データはニュース収集プロセスそのものを切り開く可能性がある。</simpara>
<simpara>データはデータジャーナリズムのソース、もしくはストーリーと一緒に話されるツール、もしくはその両方になりうる。他のソースやツールのように、データは懐疑的な見方を持って取り扱いされるべきだ。我々は、データと共に作られるストーリーを、データがどのように形作りまた制限できるかについて意識するべきだ。</simpara>
<simpara>&mdash; <emphasis>Paul Bradshaw, Birmingham City University</emphasis></simpara>
</section>
<section id="_why_journalists_should_use_data">
<title>Why Journalists Should Use Data</title>
<simpara>ジャーナリズムは危機に直面している。かつて我々は産業として、翌朝に起こることを拡大、流通させる技術をつかさどる唯一の存在なのに依存していた。印刷機は玄関口の役割を果たし、誰か翌朝にある都市なり地域の人たちに声を届けたければ、新聞に頼ったものだ。これは過去の話だ。</simpara>
<simpara>Today, news stories are flowing in as they happen, from multiple sources, eyewitnesses, and blogs, and what has happened is filtered through a vast network of social connections, being ranked, commented on&#8212;and more often than not, ignored.</simpara>
<simpara>これこそデータジャーナリズムがとても重要な理由である。目が届かないところで起きていることを集め、フィルタし、視覚化することの価値が高まっている。朝に飲むオレンジジュースやコーヒー――今日のグローバル経済ではこれらの製品、他の人たち、そしてあなたの間には目に見えないつながりがある。このネットワークにおける言語がデータなのだ。一例を見るだけでは多くの場合関連がない情報の些細なポイントが、正しい角度から見れば俄然重要になる。</simpara>
<simpara>現時点では、我々の周りで起きていることやそれが我々にどんな影響を及ぼす可能性があるか深い洞察を行うのにデータがいかに活用できるかを既に実践しているジャーナリストは少ない。</simpara>
<simpara>データ解析は「ストーリーの全体像」（サラ・コーエン）を明らかにしたり、「新しいカメラ」（デヴィッド・マッキャンドルズ）を我々にもたらしうる。データを活用することで、ジャーナリストの仕事は、報道を行う最初の存在であることから、ある展開に実際にはどんな意味があるのかを我々に伝える存在になることに移る。話題の幅はいたるところに広がりうる。市場における次の金融危機、我々が利用する製品の背後にある経済、投資信託会社による資金流用や政治的失態といったものが、議論の余地をほとんど残さない強力なデータ視覚化でもって提示されるのだ。</simpara>
<simpara>だからジャーナリストはデータをチャンスをみるべきなのだ。例えば、失業者数などある抽象的な脅威が、年齢、性別、教育をベースに人々にどんな影響を及ぼすか明らかにできる。データを活用すれば、抽象的なものが誰もが理解し関わることができるものに変わる。</simpara>
<simpara>ジャーナリストがパーソナライズされた計算機を作ることで、車や家を買ったり、人生における教育や職業のコースを決めたり、借金しないで済むよう経費を厳しくチェックしたりする人々が決定を行うのを支援できる。</simpara>
<simpara>暴動や政治討論など複雑な状況の力学を解析し、誤った議論を明らかにし、皆が複雑な問題に対する可能な解決策を理解する助けができるのだ。</simpara>
<simpara>データの検索、整理、視覚化に通じることは、情報収集という専門的職業にも変化をもたらす。これを修得したジャーナリストは、記事を事実や洞察を土台に組み立てるのが安心なのを身をもって知るだろう。推測を少なくし、引用探しを少なくすれば、ジャーナリストはデータに裏打ちされた強力な地位を確立できるし、これはジャーナリズムの地位に多大な影響を及ぼしうる。</simpara>
<simpara>それに加え、データジャーナリズムに足を踏み入れることが未来の展望をもたらす。現在編集局は縮小され、ほとんどのジャーナリストは広報への異動を希望している。データジャーナリストやデータ科学者は既に従業員の人気グループだが、これはメディアだけの話ではない。世界中の企業や公共機関が、データを掘り返し、それを具体的なものに変える方法を知る「センスメーカー（sensemakers）」なり専門家を求めている。</simpara>
<simpara>データは裏づけになるが、これこそ編集局を駆り立てるものであり、編集局は新しいタイプの記者を求めている。フリーランスの場合、データに熟達することで新たな仕事のオファーや安定した報酬への道も開ける。このように見てみよう。価値の低いコンテンツでパージやウェブサイトを素早く埋めるジャーナリストを雇うのでなく、データを活用すれば相互作用的な包括契約への需要を生み出せる。それには一週間で一つの問題を解決するしかない。これはメディアの多くの部門で歓迎される変化なのだ。</simpara>
<simpara>ジャーナリストがこの可能性を利用しない障壁が一つ存在する。最初の疑問に始まりビッグデータ主導のスクープまで全手順を通したデータを使って働く方法を学ぶためのトレーニングである。</simpara>
<?dbfo-need height="2in"?>
<simpara>データを使って働くのは、広大な未知の領域に踏み込むようなものだ。一見すると、生のデータは目や心を混乱させる。データそれ自体は扱いにくいものだ。それを視覚化するために正しく形を整えるのは実に大変である。それには、多くの場合分かりにくく退屈な生のデータを見て、その中に隠れたストーリーを「理解する」持久力のある経験豊かなジャーナリストが必要である。</simpara>
<simpara>&mdash; <emphasis>ミルコ・ローレンツ, ドイチェ・ヴェレ</emphasis></simpara>
<sidebar>
<title>調査</title>
<simpara>ヨーロッパ・ジャーナリズム・センターが、ジャーナリストのトレーニングニーズについてより多くを知るために <ulink url="http://datadrivenjournalism.net/news_and_analysis/training_data_driven_journalism_mind_the_gaps">調査を行った</ulink> 。従来のジャーナリズムの安全地帯から外に出て、新たなスキルを修得するのに時間を投資しようという強い意思があるのが分かった。調査結果からジャーナリストはチャンスと見ているが、データとともに働くのを妨げる初期問題をはねのけるために少しサポートが必要なのも分かった。データジャーナリズムがもっと採用されれば、ワークフロー、ツール、そして仕事の成果は程なく向上するはずだという確信がある。ガーディアン、ニューヨーク・タイムズ、テキサス・トリビューン、そしてディー・ツァイトといった先駆者たちがデータ主導の記事でその水準を引き上げ続けている。</simpara>
<simpara>データジャーナリズムはごく一握りの先駆者のものであり続けるのだろうか、それともすべての報道機関がすぐに独自のデータジャーナリズムチームを持つようになるのだろうか？ 我々としては、このハンドブックがより多くのジャーナリストや編集局がこの新興分野をうまく活用する助けとなることを願っている。</simpara>
</sidebar>
<figure id="FIG013"><title>European Journalism Centre survey on training needs</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-DD.png" scale="85"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-DD.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_なぜデータジャーナリズムが重要なのか">
<title>なぜデータジャーナリズムが重要なのか？</title>
<simpara>何人かのデータジャーナリズムの主要な実践者や支持者に、なぜデータジャーナリズムが重要な発展だと思うのか尋ねた。以下が彼らの回答である。</simpara>
<section id="_データの流れをフィルタする">
<title>データの流れをフィルタする</title>
<simpara>情報が乏しかった頃、我々の努力の大半はその探求と収集にささげられていた。今では情報はありあまっており、その処理がより重要である。我々は (1) 際限のないデータの流れから意味と構造を引き出す分析を行い (2) 重要で今日的な意味のあるものを消費者の頭に入れるプレゼンテーションをする二つのレベルで処理を行う。科学同様、データジャーナリズムは手法を開示し、複製で検証可能な形で発見を提示する。</simpara>
<simpara>&mdash; <emphasis>フィリップ・メイヤー, ノースカロライナ大学チャペルヒル校名誉教授</emphasis></simpara>
</section>
<section id="_ストーリーテリングの新しいアプローチ">
<title>ストーリーテリングの新しいアプローチ</title>
<simpara>データジャーナリズムは、私が思うに、増え続けるストーリーテリングについてのツール、技術、アプローチの一式を包含する包括的用語である。従来からのコンピュータを補助に使った報道（データを「情報源」として使う）から最も最先端のデータ視覚化やニュースのアプリケーションまですべてを含むかもしれない。どちらにしろ目標はジャーナリスティックなものだ。つまり、現代の重要な問題に関するすべてを我々に伝えるのを支援すべく情報と分析を提供するという。</simpara>
<simpara>&mdash; <emphasis>アロン・Pilhofer, ニューヨーク・タイムズ</emphasis></simpara>
</section>
<section id="_ラップトップ付きのフォトジャーナリズムみたいなもの">
<title>ラップトップ付きのフォトジャーナリズムみたいなもの</title>
<simpara>「データジャーナリズム」と「言葉によるジャーナリズム」の違いは、異なる道具箱を使っているという点だけだ。我々は皆、生活のためにニュースを嗅ぎ分け、報じ、関連付ける。「写真によるジャーナリズム」みたいなものだ。カメラをラップトップに換えただけだよ。</simpara>
<simpara>&mdash; <emphasis>ブライアン・ボイヤー, シカゴ・トリビューン</emphasis></simpara>
</section>
<section id="_データジャーナリズムこそ未来">
<title>データジャーナリズムこそ未来</title>
<simpara>データ主導のジャーナリズムこそ未来だ。ジャーナリストはデータに精通する必要がある。かつてはバーにいる人たちと話をしてニュースを得たものだし、今後も時にはそういうやり方をするのかもしれない。しかし今や、それはデータをじっくり調べ、データを分析するツールを武器にし、面白いものを選び出すことにもなろうとしている。そして全体像の中でデータを捉え、どこですべてが組み合わさり、その国で何が起こっているかを人々が真に理解する助けるのだ。</simpara>
<simpara>&mdash; _ティム・バーナーズ＝リー, ワールド・ワイド・ウェブの創始者_</simpara>
</section>
<section id="_数値演算と文章家の出会い">
<title>数値演算と文章家の出会い</title>
<simpara>データジャーナリズムは、統計技術者と文章家の間のギャップをつなぐものである。外れ値を探し、統計的に重要なだけでなく今日の元々複雑な世界を逆コンパイルするのに適切なトレンドを特定するのだ。</simpara>
<simpara>&mdash; <emphasis>デヴィッド・アンダートン, フリージャーナリスト</emphasis></simpara>
</section>
<section id="_スキルセットのアップデート">
<title>スキルセットのアップデート</title>
<simpara>データジャーナリズムは、既存のジャーナリズムにおける基本スキルでは十分でない時代におけるデジタルな情報源の検索、理解、そして視覚化の新たなスキルセットである。それは既存のジャーナリズムの替わりではなく、それに追加を行うものである。</simpara>
<simpara>情報源がデジタルな時代には、ジャーナリストはそれらの情報源にさらに近づくことが可能だし、そうしなければならない。インターネットは、我々の現状の理解を超える可能性を切り開いた。データジャーナリズムは、オンラインに適合すべく我々のこれまでの経験を進化させるまさに始まりなのだ。</simpara>
<simpara>データジャーナリズムは、報道機関にとって二つの重要な役割を果たす。それは（ニュースワイヤー以外から）ユニークなニュースを見つけ、監視機能を果たすことだ。特に金融危機の折には、これらは新聞が遂行すべき重要な目標である。</simpara>
<simpara>地方新聞の視点から見ても、データジャーナリズムは重要だ。「自分ちの玄関の緩んだタイルは、遠い異国の暴動より重要だ」という言い回しがある。タイルが顔にあたれば、人生にずっと直接的なインパクトがある。同時に、デジタル化はいたるところで進んでいる。地方新聞は身近なところでこの直接的なインパクトを受けるし、情報源はデジタル化しているのだから、ジャーナリストはデータからニュースを見つけ、分析し、視覚化する方法を知らなくてはならない。</simpara>
<simpara>&mdash; <emphasis>ジェリー・ヴァーマネン</emphasis></simpara>
</section>
<section id="_情報の非対称への救済策">
<title>情報の非対称への救済策</title>
<simpara>Information asymmetry&#8212;not the lack of information, but the inability to take in and process it with the speed and volume that it comes to us&#8212;is one of the most significant problems that citizens face in making choices about how to live their lives. Information taken in from print, visual, and audio media influence citizens' choices and actions. Good data journalism helps to combat information asymmetry.</simpara>
<simpara>&mdash; <emphasis>トム・フリーズ, Bertelsmann Stiftung</emphasis></simpara>
</section>
<section id="_データ主導のprへの回答">
<title>データ主導のPRへの回答</title>
<simpara>計測ツールが使え、またその価格が下がっていることが、社会のあらゆる面での成果と効率への関心と自律的に組み合わさることで、政策決定者は自身の政策の進捗を計り、トレンドを監視して機会を見極めるようになった。</simpara>
<simpara>企業は、自分たちのパフォーマンスを示す新しい評価基準を作り出し続ける。政治家は失業者数の下落やGDPの上昇を誇示するのが好きだ。エンロン、ワールドコム、マドフ、ソリンドラの事件に見られるジャーナリスティックな洞察の欠如は、多くのジャーナリストが明らかに数字の本質を見抜けなくなっている証拠である。たとえまったくのでっち上げであっても、図は誠実さのオーラをまとうので事実よりも鵜呑みにされやすい。</simpara>
<simpara>Fluency with data will help journalists sharpen their critical sense when faced with numbers and will hopefully help them gain back some terrain in their exchanges with PR departments.</simpara>
<simpara>&mdash; <emphasis>Nicolas Kayser-Bril, Journalism++</emphasis></simpara>
</section>
<section id="_公式情報から独自の解釈を提供">
<title>公式情報から独自の解釈を提供</title>
<simpara>2011年の壊滅的な地震とそれに続く福島原発の惨事の後、一般にデジタルジャーナリズムの分野で遅れを取っている国である日本のメディアの人間にもデータジャーナリズムの重要性がはっきり認識されるようになった。</simpara>
<simpara>政府や専門家が被害について信頼できるデータを出さず、我々は途方に暮れた。役人が（放射性物質の拡散を予測した）SPEEDIのデータを大衆から隠匿したが、たとえそれがリークされても我々にはそれを解析する用意がなかった。ボランティアが自らの機器を使って放射能に関するデータを集め出したが、我々には統計、補間、視覚化などの知識が備わってなかった。ジャーナリストは生のデータにアクセスし、公式見解に依存しないことを学ぶ必要がある。</simpara>
<simpara>&mdash; <emphasis>Isao Matsunami, 中日／東京新聞</emphasis></simpara>
</section>
<section id="_データの氾濫への対処">
<title>データの氾濫への対処</title>
<simpara>デジタル革命が作り出す課題とチャンスはジャーナリズムを破壊し続ける。情報が潤沢な時代には、我々が深夜のデータダンプを処理して中東で21世紀の地下出版を行っていたり、ある国の水質を可視化する最良の方法を探していたりするかに関わらず、ジャーナリストも市民も皆同じくより良いツールを必要とする。我々がデータの氾濫が作り出す消費の問題に取り組むように、新たな出版プラットフォームもまた皆にデータをデジタルに集めて共有する力を与えつつあり、データを情報に変えている。記者や編集者がこれまでは情報の収集や伝達を担ってきたが、2012年のフラットな情報環境では、今やニュースデスクでなくまずオンラインにニュースが流れる。</simpara>
<simpara>事実、世界中でデータとジャーナリズムの結びつきが強さを増している。ビッグデータ時代において、データジャーナリズムの増大する重要性は、その実践者が文脈や明瞭さを提供し、おそらく最も重要なのが、世界で増大するデジタルコンテンツから真実を発見する能力にかかっている。それは、今日の統合されたメディア組織が重要な役割を果たすことを意味しない。決してそうではない。情報時代において、ジャーナリストはこれまで以上にデータの波をキュレーションし、検証し、分析し、合成することが求められる。そうすることでデータジャーナリズムは社会で深い重要性を獲得する。</simpara>
<simpara>今日、ビッグデータ、特に構造化されていないデータの理解が世界中のデータ科学者たちの中心的目標になるだろうが、それはデータが編集局にあろうが、ウォールストリートにあろうが、シリコンバレーにあろうが関係ない。特にその目標は増加する一般的なツールセットにより実質的に実現するだろうが、そのツールセットを使うのが政府の科学技術者だろうが、ヘルスケアの科学技術者だろうが、編集局の開発者だろうが関係ない。</simpara>
<simpara>&mdash; <emphasis>アレックス・ハワード, オライリー・メディア</emphasis></simpara>
</section>
<section id="_我々の生活がデータ">
<title>我々の生活がデータ</title>
<simpara>良質なデータジャーナリズムは難しい。なぜなら優れたジャーナリズムは難しいものだからだ。データジャーナリズムとはデータを取得し、それを理解し、そしてニュースを見つける方法を理解することを意味する。たかが右ボタンを押すくらいの話なら、それはジャーナリズムとは言わない。けれども、データジャーナリズムはデータを価値あるものにするものだし――我々の生活がますますデータ化する世界では――自由で公平な社会に欠かせないものである。</simpara>
<simpara>&mdash; <emphasis>クリス・タガート, OpenCorporates</emphasis></simpara>
</section>
<section id="_時間を節約する方法">
<title>時間を節約する方法</title>
<simpara>ジャーナリストには、何かを手で書き写したり、PDFからデータを取り出そうといじくり回して無駄にする時間はないので、少しばかりコードを習うなり助けになる人をどこで探すか知ることにものすごく価値がある。</simpara>
<simpara>フォーリャ・ジ・サンパウロ紙のある記者は、地方予算に取り組んでいて、サンパウロ市役所の会計をオンラインにあげたことに感謝する電話をくれた（一人のハッカーが二日でやった仕事だ！）。彼が言うには、この三ヶ月もの間それを手で書き起こして記事を書こうとしていたそうだ。私はそれを聞いて、議会を監視する報道機関の「Contas Abertas」が「PDF問題」を解決した話を思い出す。そこは15分かけて書いた15行のコードで一月分の仕事を解決したのだ。</simpara>
<simpara>&mdash; <emphasis>ペドロ・マークン, Transparência Hacker</emphasis></simpara>
</section>
<section id="_ジャーナリストの道具箱における欠かせないパーツ">
<title>ジャーナリストの道具箱における欠かせないパーツ</title>
<simpara>I think it&#8217;s important to stress the "journalism" or reporting aspect of "data journalism." The exercise should not be about just analyzing or visualizing data for the sake of it, but to use it as a tool to get closer to the truth of what is going on in the world. I see the ability to be able to analyze and interpret data as an essential part of today&#8217;s journalists' toolkit, rather than a separate discipline. Ultimately, it is all about good reporting, and telling stories in the most appropriate way.</simpara>
<simpara>データジャーナリズムは世界を観察し、説明をする力を保つこれまでと違った方法なのだ。入手できるデータ量が増える中、ジャーナリストがデータジャーナリズムの技術を知ることは今やかつてないほど重要である。これはどんなジャーナリストのツールキットにもある道具になるはずだ。それは直接データを処理するか、あるいはそれが可能な誰かと共同作業をするかは関係ない。</simpara>
<simpara>データジャーナリズムは世界を観察し、説明をする力を保つこれまでと違った方法なのだ。入手できるデータ量が増える中、ジャーナリストがデータジャーナリズムの技術を知ることは今やかつてないほど重要である。これはどんなジャーナリストのツールキットにもある道具になるはずだ。それは直接データを処理するか、あるいはそれが可能な誰かと共同作業をするかは関係ない。</simpara>
<simpara>理想的には、データを使って外れ値なり、関心がある分野なり、意外なものなりを正確に指摘することになる。この意味で、データは主役であったりマル秘情報の役割を果たす可能性がある。確かに数字は面白いかもしれないが、データについて書くだけでは十分ではない。そのデータが意味するところを説く報道を行う必要がやはりあるのだ。</simpara>
<simpara>&mdash; <emphasis>シンシア・O’Murchu, フィナンシャル・タイムズ</emphasis></simpara>
</section>
<section id="_我々の情報環境の変化に適合する">
<title>我々の情報環境の変化に適合する</title>
<simpara>新たなデジタル技術は、社会に知識を生み出し、広める新たな手法をもたらす。データジャーナリズムは、メディアが我々の情報環境の変化への適合、対処を試みていると理解できる――それは読者がニュースの基となる情報源を調べることが可能になり、ニュース記事を作り出し、評価するプロセスに参加することを促す、より双方向的で多元的なストーリーテリングを含む。</simpara>
<simpara>&mdash; <emphasis>セザール・ヴィアナ, ゴイアス大学</emphasis></simpara>
</section>
<section id="_他の形では見られないものを見る方法">
<title>他の形では見られないものを見る方法</title>
<simpara>ニュース記事には、データの分析――と場合によっては視覚化――を経ないと理解し解説できないものがある。権力を持つ人なり団体の間にあるつながりは、隠匿されたままだったであろう麻薬政策による死、景色がそのままであり続けるのを損なう環境政策を秘密にするだろう。しかし、ジャーナリストがデータを手に入れ、分析し、読者に提供することで上記事項は変化した。データは、必要最小限のスプレッドシートや携帯電話の通話記録ぐらいシンプルかもしれないし、学校のテストの成績や病院の感染データくらい複雑かもしれないが、その中を見ればすべては語る価値があるニュースなのだ。</simpara>
<simpara>&mdash; <emphasis>シェリル・フィリップス, シアトル・タイムズ</emphasis></simpara>
</section>
<section id="_もっと豊かなニュースを語る方法">
<title>もっと豊かなニュースを語る方法</title>
<simpara>We can paint pictures of our entire lives with our digital trails. From what we consume and browse, to where and when we travel, to our musical preferences, our first loves, our children’s milestones, even our last wishes – it all can be tracked, digitized, stored in the cloud, and disseminated. This universe of data can be surfaced to tell stories, answer questions and impart an understanding of life in ways that currently surpass even the most rigorous and careful reconstruction of anecdotes.</simpara>
<simpara>&mdash; _サラ・スロービン, ウォール・ストリート・ジャーナル</simpara>
<sidebar>
<title>You Don&#8217;t Need New Data to Make a Scoop</title>
<simpara>Sometimes the data is already public and available, but no one has looked at it closely. In the case of the Associated Press&#8217;s report on 4,500 pages of declassified documents describing the actions of private security contractors during the Iraq war, the material was obtained by an independent journalist over several years, using Freedom of Information requests addressed to the U.S. State Department. They scanned the paper results and uploaded them to DocumentCloud, which made it possible for us to do our comprehensive analysis.</simpara>
<simpara>&mdash; <emphasis>Jonathan Stray, The Overview Project</emphasis></simpara>
</sidebar>
</section>
</section>
<section id="_成功例の紹介">
<title>成功例の紹介</title>
<simpara>貢献者の何人かにデータジャーナリズムのお気に入りの事例とそれのどこが好きなのか尋ねてみた。以下がその回答である。</simpara>
<section id="_ラスベガス_サンの_do_no_harm">
<title>ラスベガス・サンの Do No Harm</title>
<simpara>私のお気に入りの例は、ラスベガス・サンが2010年に病院看護の分野で行った <ulink url="http://www.lasvegassun.com/hospital-care/">Do No Harm</ulink>シリーズだ。サンは290万を超える請求書の記録を分析し、避けられた怪我、感染、手術ミスが3600件を超えることを明らかにした。サンは公記録を請求して取得し、避けられるはずだったミスのせいで患者が死んだ300件を超える事例を特定した。Do No Harm はいろんな要素を含んでいる。それは外科的損傷がどこで想定以上に発生しているか読者が病院ごとに見ることができる <ulink url="http://www.lasvegassun.com/hospital-care/surgical-injuries-interactive/">対話型グラフィックス</ulink>であり、病院ごとに院内感染の広がりを表示する時系列付きの<ulink url="http://www.lasvegassun.com/hospital-care/infections-interactive/">地図</ulink> であり、そしてユーザが避けられた怪我や人々が被害にあっている病院ごとにデータを取り出せる<ulink url="http://www.lasvegassun.com/hospital-care/events-chart/">対話型グラフィックス</ulink> である。ここが好きなのは、理解して利用するのがとても簡単だからだ。ユーザはかなり直感的にデータを調査できる。</simpara>
<?dbfo-need height="1in"?>
<simpara>Do No Harmは現実にも影響を与えた。ネバダ州議会は<ulink url="http://www.lasvegassun.com/news/2011/apr/14/health-care-transparency-bills-pass-key-milestone-/">6つの法案</ulink>でこれに応えた。これに関わったジャーナリストは、データを入手して整理するのに懸命に働いた。そうしたジャーナリストの一人であるアレックス・リチャーズは、誤りを訂正してもらうために、病院と州に <ulink url="http://www.poynter.org/latest-news/als-morning-meeting/128672/las-vegas-sun-pulitzer-finalists-explain-how-they-turned-data-into-web-gold/">少なくとも十数回</ulink>データを返送している。</simpara>
<simpara>&mdash; <emphasis>アンジェリカ・ペラルタ・ラモス, La Nacion（アルゼンチン）</emphasis></simpara>
<figure id="FIG014"><title>Do No Harm（ラスベガス・サン）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-GG.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-GG.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_公務員給与データベース">
<title>公務員給与データベース</title>
<simpara>私は小規模の独立系の組織が毎日やっている仕事が好きで、ProPublicaやテキサス・トリビューンみたいな優れたデータ記者を抱えているところだ。あえて選ぶなら、テキサス・トリビューンの<ulink url="http://bit.ly/texastrib-employee">公務員給与データベース</ulink> プロジェクトになる。このプロジェクトは、660,000人もの公務員給与情報をデータベースに集め、利用者が検索して記事を作成するのを支援する。このデータベースは部局、氏名、給与で検索をかけられる。シンプルにして有意義で、近づきがたい情報を明らかにするものである。これを利用して記事を自動生成するのは容易だ。これこそテキサス・トリビューンのサイトへのトラフィックがこのデータページからのものが大半である理由が分かる良い実例といえる。</simpara>
<simpara>&mdash; <emphasis>サイモン・ロジャース, ガーディアン</emphasis></simpara>
<figure id="FIG015"><title>公務員の給与 (ザ・テキサス・トリビューン)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-FF.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-FF.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_ap通信のイラク戦争記録の全文視覚化">
<title>AP通信のイラク戦争記録の全文視覚化</title>
<simpara>Jonathan Stray （ジョナサン）と Julian Burgess （ジュリアン）の仕事に <ulink url="http://bit.ly/jstray-warlogs">Iraq War Logs</ulink> （イラクの戦争記録）というのがある。これは、巨大なテキストデータ群の中から探索に値するテーマを見抜くために、実験的な手法を用いてテキスト分析と可視化する刺激的な試みであった。</simpara>
<simpara>ジョナサンとジュリアンは、テキスト分析の技術とアルゴリズムを用いることで、ウィキリークスによって漏洩された何千という米国政府のイラク戦争に関するレポートからキーワードのまとまりを視覚的に表現する方法を編み出した。</simpara>
<simpara>提示される手法には制限があるし、そのアプローチは実験的だが、革新的なアプローチを提供するものである。この技術は、すべてのファイルを読もうとしたり、特定のキーワードを入力してその結果を評するという先入観をもった戦争記録の論評を行うことなく、特に問題となる話題／キーワードを算出して視覚化するものである。</simpara>
<simpara>データ量――文章データ（電子メール、報告書など）と数値データの両方――の増大やパブリックドメインへの参入により、主要な関心領域を目立たせる方法を見つけることがますます重要になる――それこそデータジャーナリズムの刺激的なところである。</simpara>
<simpara>&mdash; <emphasis>シンシア・O’Murchu, フィナンシャル・タイムズ</emphasis></simpara>
<figure id="FIG016"><title>戦争記録分析（AP通信）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-YY.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-YY.jpg</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_murder_mysteries">
<title>Murder Mysteries</title>
<simpara>私が好きなデータジャーナリズムの場の一つがScripps Howard News Serviceのトム・ハーグローヴによる projects.scrippsnews.com/magazine/murder-mysteries/[<emphasis>Murder Mysteries</emphasis>] プロジェクトである。彼は政府のデータと公記録から、185,000件を超える未解決の殺人事件についての人口統計学的に詳細なデータベースを作り上げ、それから連続殺人鬼が存在する可能性を示唆するパターンを検索するアルゴリズムを設計した。このプロジェクトには、政府独自のデータベースよりも優れたデータベースを寄せ集める重労働、社会科学の技術を用いた巧妙な分析、そして読者が自分で探究可能なオンラインにおけるデータの双方向的なプレゼンテーションのすべてがある。</simpara>
<simpara>&mdash; <emphasis>スティーヴ・ドイグ, アリゾナ州立大学ウォルター・クロンカイト・ジャーナリズムスクール</emphasis></simpara>
<figure id="FIG017"><title>Murder Mysteries (Scripps Howard News Service)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-XX.jpg" scale="94"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-XX.jpg</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_message_machine">
<title>Message Machine</title>
<simpara>私はProPublicaの<ulink url="http://www.propublica.org/special/message-machine-you-probably-dont-know-janet">Message Machine</ulink>の記事や <ulink url="http://www.propublica.org/nerds/item/when-are-190-emails-like-six-emails">おたくっぽいブログ投稿</ulink> が好きだ。Message Machineは、一部のツイッターユーザがオバマ陣営からいろんな電子メールを受信することへの好奇心を表明したことがすべての始まりである。ProPublicaの人たちがそれに気づき、読者にオバマ陣営から受け取ったどんな電子メールも転送するようお願いした。その結果はエレガントな、その晩送られたさまざまな電子メールの見て分かる差分だった。これがすごいのは、ProPublicaが独自のデータを収集したことだ（サンプル数は明らかに少ないが、ストーリーを語るには十分に大きい）。でももっとすごいのは、彼らが新興の現象である、特定の個人に向けてメッセージを送る選挙キャンペーンにおけるビッグデータの話を語っているところだ。これはこれから起こることの序章に過ぎない。</simpara>
<simpara>&mdash; <emphasis>ブライアン・ボイヤー, シカゴ・トリビューン</emphasis></simpara>
<figure id="FIG018"><title>Message Machine (ProPublica)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-HH.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-HH.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_チャートボール">
<title>チャートボール</title>
<simpara>私の好きなデータ・ジャーナリズムのプロジェクトのひとつに、Andrew Garcia Phillips （アンドリュー）の作品で <ulink url="http://www.chartball.com/">Chartball</ulink> （チャートボール） というものがある。アンドリューはかなりのスポーツファンで、貪欲なまでにデータを欲していて、デザインについてはヤバいくらい目利きで、プログラムだって書くことができた。 チャートボールで彼が可視化したのは歴史の流れだけではなく、個々のプレイヤーやチームの成功や失敗の詳細だった。できごとの背景を描き出し、魅力的なグラフィックスを産み、その作品は深みがあって楽しくて面白いのだ。対してスポーツに興味のない私でさえそう思ってしまうのである！</simpara>
<simpara>&mdash; <emphasis>Sarah Slobin, Wall Street Journal</emphasis></simpara>
<figure id="FIG019"><title>勝敗の図示 (チャートボール)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-JJ.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-JJ.png</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_データジャーナリズムの展望">
<title>データジャーナリズムの展望</title>
<simpara>2010年の８月、私とヨーロッパ・ジャーナリズム・センターの数人の同僚たちは、<ulink url="http://bit.ly/ddj-conf">おそらく世界で初めてのデータ・ジャーナリズム会議</ulink>をアムステルダムで主催した。当時このトピックに関してさほど多くの議論がなされていない状態で、この分野で広く仕事を知られた組織はたったの２つしかなかった。</simpara>
<simpara>データジャーナリズムという言葉を知らしめた大きな一歩の一つに、ガーディアンやニューヨークタイムズといった報道機関がウィリークスによって公開された大量のデータを扱ったことがある。当時データジャーナリズムという言葉は、ジャーナリストがデータを活用して取材範囲を拡充し、特定の話題についての掘り下げた調査を補う手法を説明するのに、「コンピューター支援報道（computer-assisted reporting）」という言葉ともに以前より広く使われ出した。</simpara>
<?dbfo-need height="1in"?>
<simpara>経験豊かなデータジャーナリストやジャーナリズムの研究者に <ulink url="https://twitter.com/smfrogers/status/108238296685096961">Twitterで</ulink> 話しかけてみたところ、今我々がデータジャーナリズムとして認識するものを最初期に定義したものの一つが、2006年にEveryBlockの創始者であるエイドリアン・ホロヴァッティによってであるらしい。それは、ユーザがある地域、街区で起きていることを調べられるようにする情報サービス、というものだった。 <ulink url="http://www.holovaty.com/writing/fundamental-change/">「新聞サイトは根本的に変わるべきだ」</ulink> という短いエッセイにおいて、ジャーナリストは従来の「大きな文章の塊」だけでなく、構造化され、機械可読なデータを公開すべきだと彼は以下のように論じる。</simpara>
<blockquote>
<simpara>例えば、新聞が地方の火事の記事を書く場合を考える。携帯電話でその記事を読めるのは結構なことだ。テクノロジー万歳！ でも本当にできてほしいのは、何層もの属性を積み重ねたその記事の未加工な事実を一つずつ探ることであり、その火事の詳細――日付、時刻、場所、犠牲者、消防署の番号、消防署からの距離、かけつけた消防士の名前や勤続年数、消防士の到着にかかった時間――を過去に起きた火事の詳細と比較する基盤が欲しいのだ。それからは火事がいつ起きてもそれができる。</simpara>
</blockquote>
<simpara>しかし、何をもってデータベースやコンピュータを用いた他の形のジャーナリズムと区別できるのだろう？どのように、そして、どの程度、データ・ジャーナリズムは過去のジャーナリズムの形から異なっているのだろう？</simpara>
<simpara>====「コンピューター支援報道」と「精度ジャーナリズム」</simpara>
<simpara>データを活用して報道記事の質を高め、一般に公開されている（機械可読ではないにせよ）構造化された情報を伝えることには長い歴史がある。我々が今データジャーナリズムと呼ぶものとおそらくもっとも直接関連があるのは、「コンピューター支援報道（computer-assisted reporting、CAR）」である。これは、コンピュータを使ってデータを収集、分析して報道の質を高める最初の系統的で秩序だったアプローチだった。</simpara>
<simpara>CARという言葉は、1952年に大統領選挙の結果を予測するのにCBSによって初めて使われた。1960年代以降、（主に調査に携わる、主に米国を基盤とする）ジャーナリストが公文書のデータベースを科学的手法で分析し、自主的に権力を監視しようとしてきた。これは「公共ジャーナリズム」としても知られるが、こうしたコンピューター支援技術の支持者はトレンドを明らかにし、一般に広まっている知識の誤りを暴き、公共機関や民間会社により行われた不正行為を明るみにしようとしてきた。例えば、フィリップ・メイヤーは、1967年にデトロイトで起きた暴動に関する一般的な見解の誤りを暴こうとした――暴動に参加していたのが教育水準の低い南部人だけではないのを示したのだ。1980年代におけるビル・デッドマンの「The Color of Money」の記事は、主要金融機関の融資方針に広まる人種偏見を暴露した。スティーヴ・ドイグは「What Went Wrong」において、1990年代初期のハリケーン・アンドリューによる被害の分布を分析し、欠陥のある都市開発政策やその運用の影響を知ろうとした。データ駆動型の報道は有益な公共サービスをもたらし、高名なジャーナリストの賞を獲得した。</simpara>
<?dbfo-need height="1in"?>
<simpara>1970年代初期、「社会科学や行動科学の研究手法をジャーナリズムの実践に応用する」取材方法を表現するのに「精度ジャーナリズム（precision journalism）」という言葉が発明された。精度ジャーナリズムは、ジャーナリズムや社会科学の教育を受けた専門家によって、メインストリームの報道機関で実践されることを想定したものである。精度ジャーナリズムは「ニュージャーナリズム」に応えて生まれたものだが、ニュージャーナリズムとは創作のテクニックを報道に応用したジャーナリズム形態である。メイヤーは、客観性や真実の探求を成し遂げるには、文学技法ではなくデータを集め分析する科学的技法こそがジャーナリズムに必要なものなのだと語る。</simpara>
<simpara>精度ジャーナリズムは、ジャーナリズムの欠点や弱点としてよく言われるものの一部に対する答えと考えられる。それは報道発表への依存（後に「チャーナリズム（churnalism）」と言われるようになる）、権威筋寄りの姿勢などである。これらをメイヤーは、世論調査や公文書などへの情報科学技術や科学的手法の応用が足らないことから生じていると見ている。1960年代に予想されたように、精度ジャーナリズムは社会の周縁にいる人たち、そして彼らの話を伝えるのに使われた。 <ulink url="http://bit.ly/p-meyer">メイヤー</ulink> は以下のように語る。</simpara>
<blockquote>
<simpara>精度ジャーナリズムは、ジャーナリズムの調査に関して、それ以前は手が届かなかったかほとんどアクセスできなかった話題を作り出すために記者のツールキットを拡張する手段だった。それは権利を求めて闘っていたマイノリティや反体制派に意見表明の機会を与えるのに特に有用だった。</simpara>
</blockquote>
<simpara>1980年代に出版されたジャーナリズムと社会科学の関係についての <ulink url="http://bit.ly/oxford-influential">影響力の大きな記事</ulink> は、現在のデータジャーナリズムを巡る話を先取りしている。記事の著者である二人のアメリカ人のジャーナリズムが専門の教授は、1970年代と1980年代、大衆が考えるニュースは、狭義の「ニュースとなる出来事」から「状況に対応した報道」や社会的傾向に関する報道まで広がっていることを示唆している。例えば、国勢調査データのデータベースを活用して、ジャーナリストは「特定、単独の出来事の報道からあるコンテキストに意味を与えるところまで進む」ことができるわけだ。</simpara>
<simpara>お分かりの通り、報道の質を高めることを目的とするデータの活用は、「データ」の歴史まで遡るのだ。サイモン・ロジャースが指摘するように、ガーディアンにおけるデータジャーナリズムの最初の実例は1821年に遡る。それはマンチェスターの学校における出席した生徒数と学校あたりの経費を記載した表が漏洩したものである。ロジャースによると、これが無償で教育を受けている生徒の実数を初めて明らかにし、それが公表されている数字よりずっと多いことが分かる助けとなったというのだ。</simpara>
<figure id="FIG0110"><title>1821年におけるガーディアンのデータジャーナリズム（ガーディアン）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-LL.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-LL.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>もう一つヨーロッパにおける初期の例に、フローレンス・ナイチンゲールと1858年に公開された彼女の重要なレポート <ulink url="http://bit.ly/mortality-army">「英国陸軍の死亡率」</ulink> がある。議会に向けたレポートで彼女は、グラフを用いて英国陸軍における医療サービスの改善を訴えている。最も有名なのは彼女が「鶏のとさか」と呼ぶ円グラフで、これは月毎の死者数を示しており、その死の大部分が銃弾ではなく避けられたはずの病気によるものであることを強調するものだった。</simpara>
<figure id="FIG0111"><title>フローレンス・ナイチンゲール「英国陸軍の死亡率」（画像はWikipediaより）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/01-MM.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/01-MM.jpg</phrase></textobject>
</mediaobject>
</figure>
<section id="_データジャーナリズムとコンピュータ支援報道">
<title>データジャーナリズムとコンピュータ支援報道</title>
<simpara>現在、「データジャーナリズム」という標語と、コンピュータ技術を用いてデータセットを分析する以前からあるジャーナリズムの実践とデータジャーナリズムとの関係をめぐり、それが「過去から続くものか変化したものか」の論争が続いている。</simpara>
<simpara>CARとデータジャーナリズムの間には違いがあると主張する人たちもいる。彼らによれば、CARは（通常、調査）報道を強化する手段としてデータを集め分析する技術なのに対し、データジャーナリズムはデータがジャーナリズムのワークフロー全体に入り込む手法に留意しているというのだ。この意味においてデータジャーナリズムは、ストーリーを見つけたり強化したりする一手段としてだけデータを利用するのではなく、データそのものにストーリーと同じくらい――時にはストーリーより――気を配っている。だから、ガーディアンのDatablogやテキサス・トリビューンは、記事とともにデータセットを公開するのであって、人々が分析して探求できるようデータセットだけ公開することさえある。</simpara>
<simpara>それ以外にも異なる点がある。今までの調査報道のジャーナリストは、答えようとしている問いや取り組もうとしている事柄に関する情報不足に悩まされていた。その事自体は今でも変わっていないものの、ジャーナリストがどう扱ってよいかわからなくなりそうなほど圧倒的に豊富な情報も存在するようになった。彼らはデータからどうやって価値を引き出せばよいか分からないのだ。最近の例を挙げると、Combined Online Information System （統合オンライン情報システム）というイギリスで最大の消費情報のデータベースがある。このデータベースは情報公開を唱える人々にとって長年の夢だったわけだが、公開と共に多くのジャーナリストを当惑させ、困らせた。フィリップ・メイヤーは最近私に次のような言葉を書いてよこした: 「情報が不足している時には、私たちの努力のほとんどは情報を狩り、集めることに費やされていたものだよ。いまや、情報は溢れかえり、処理が一番大事になった。」</simpara>
<simpara>一方で、データジャーナリズムとコンピュータ支援報道には大した違いはないと主張する向きもある。最も最近のメディアにおける実践にさえ歴史があるのは、その中に何かしら新しいものがあるのと同じくらい今では常識である。データジャーナリズムがまったく新しいものかどうかを議論するよりも、それが歴史のある伝統の一部なのか、新しい環境や条件に対する反応なのか考えるほうがより実がある姿勢だろう。たとえ目標や技術に違いがなくとも、今世紀はじめに「データジャーナリズム」という標語が生まれたのは、洗練されたユーザ中心のツール、自主出版やクラウドソースのツールとともにオンラインで無料で公開される膨大な量のデータにより、より多くの人たちがかつてよりもずっと容易により多くのデータに取り組める新しいフェーズに入っていることを示している。</simpara>
</section>
<section id="_データジャーナリズムには大量データリテラシーが必要">
<title>データジャーナリズムには大量データリテラシーが必要</title>
<simpara>デジタル技術とウェブは、情報が公開されるあり方を根本的に変えつつある。データジャーナリズムは、データサイトとサービスの周りで生まれてきたツールや実践のエコシステムの一部である。源資料の引用、共有は、ウェブのハイパーリンク構造の本質だし、我々が今日情報のナビゲートを常習的に行うやり方でもある。さらに掘り下げると、ウェブのハイパーリンク構造の土台にあるのは、アカデミズムの世界で採用されている引用の原則である。源資料の引用、共有や記事の背景にあるデータは、ウィキリークスの創始者ジュリアン・アサンジが「科学的ジャーナリズム」と呼ぶ、データジャーナリズムがジャーナリズムを向上させうる基本的な方法の一つなのだ。</simpara>
<simpara>誰もがデータソースを掘り下げ、それに関連する情報を見つけられるようにし、主張を検証して一般に受け入れられている前提を疑えるようにするという意味で、データジャーナリズムはかつては専門家――事件記者、社会科学者、統計学者など――に利用された情報源、ツール、テクニック、方法論の大衆民主化を象徴するものである。現状ではデータソースの引用やリンクがデータジャーナリズムを特徴づけているが、我々はデータがメディアの仕組みにシームレスに統合された世界に向かって進んでいるのだ。データジャーナリストは、データを理解し詮索する障壁を下げるのを助け、世界的に読者のデータリテラシーを高めるという重要な役割を担っている。</simpara>
<simpara>今のところ、データ・ジャーナリストを自称する人々の萌芽的コミュニティは、より成熟した CAR のコミュニティとほとんど重複していない。願わくは、将来的には、ProPublica や  Bureau of Investigative Journalism （調査報道事務局） のような 市民メディア組織 や 新しい NGO が調査において伝統的なニュースメディアと手を取り合って協働しているのと同じような形で、これら２つのコミュニティの間に強い結びつきができればよいと思う。データ・ジャーナリズムのコミュニティはデータを届けストーリーを描き出すのにより革新的な方法をもっているかもしれないが、CAR のコミュニティが持っている深い分析や批判的なアプローチはデータ・ジャーナリズム側が学べる部分だ。</simpara>
<simpara>&mdash; <emphasis>リリアナ・ボーネグル, ヨーロッパ・ジャーナリズム・センター</emphasis></simpara>
</section>
</section>
</section>
<section id="_ニュースルームにて">
<title>ニュースルームにて</title>
<informalfigure role="informal">
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-00-cover.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-00-cover.png</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>世界のニュースルームで、データ・ジャーナリズムはどのように位置づけられているだろうか？先進的なデータ・ジャーナリスト達はデータセットを公開したりデータドリブンなニュースアプリをローンチすることが良いアイデアであると、どうやって同僚達を説得したのだろうか？ジャーナリストはコードの書き方を学ぶべきか、それとも能力のある開発者と二人でペアを組んで働くべきだろうか？このセクションでは、我々はデータとデータジャーナリズムの役割について、オーストラリア放送協会（ABC）、BBC、シカゴ・トリビューン、ガーディアン、テキサス・トリビューン、そしてツァイト・オンラインでの事例を見て行く。我々は、よい開発者を見つけて雇う方法、ハッカソンやその他のイベントを通じてトピックの周辺にいる人とつながる方法、異なる領域のコラボレーションを実現する方法、そしてデータジャーナリズムのビジネスモデルについて学ぶ。</simpara>
<section id="_abcでのデータジャーナリズムの実践">
<title>ABCでのデータジャーナリズムの実践</title>
<simpara>オーストラリア放送協会は、オーストラリアの国営公共放送です。年間10億オーストラリアドルを投じて、７つのラジオネットワークと、60のローカルラジオ局、３つのデジタルテレビ局、国際テレビサービス、拡大を続けるユーザーが投稿したコンテンツを配信するオンラインプラットフォームを運営しています。ABCには4500人のフルタイムのスタッフがいて、約70%がコンテンツの制作に関わっています。</simpara>
<simpara>ABCは、政府によって資金が提供されていますが、独立性を非常に重視しています。ABCの伝統は独立した公共のジャーナリズムを提供することで、オーストラリアにおいて最も信用できるニュース組織と見なされています。</simpara>
<simpara>マネージングディレクターであり、前職では新聞社のエグゼクティブをつとめていたマークスコットの元で、ABCのコンテンツ制作は「アジャイル」になることを推奨されました。</simpara>
<simpara>もちろん、言うはやすし行うは難しです。</simpara>
<simpara>このことを推進するために、組織横断プロジェクトをはじめるための予算獲得をするためのスタッフ間のコンペが開催されました。</simpara>
<simpara>こうして、ABCの最初のデータジャーナリズムプロジェクトが生まれました。</simpara>
<simpara>2010年のはじめに、私は３人の「アイデア」担当の重役とのコンペに私の提案をもって参加しました。</simpara>
<simpara>私はしばらくの間、その提案の事を良く考えていました。いまでは伝説となったガーディアンのデータ・ブログが提供する記事を、むさぼるように読みました。</simpara>
<simpara>私の論点は、5年以内にABCが独自のデータジャーナリズムチームを持つ事は疑いないという事でした。それは避けがたい事だと私は考えていました。問題は、どうやってそれを実現するのか、誰がそれをはじめるのかということでした。</simpara>
<simpara>ABCについて良く知らない読者の方々は、70年以上をかけて構築された強固な官僚主義について考えてみてください。ABCはずっと、ラジオとテレビを主に提供してきました。ここ10年でのオンラインの勃興により、コンテンツの範囲はテキスト・写真、そしてかつて想像した事の無かったインタラクティブなものに広がりました。ウェブの世界によって、ABCはどうやってケーキ(お金)を切り分けて、どんなケーキ(コンテンツ)を焼くのかを考えさせられているのです。</simpara>
<simpara>これは、もちろんまだ発展途上です。</simpara>
<simpara>しかし、データジャーナリズムによって、また別の事が起り始めています。ガバメント2.0(我々はオーストラリアで、このことが頻繁に矢面にたたされていることを発見しました)が、これまで数字の中にすっかり埋もれていたストーリーを語る新しい方法を提供しはじめています。</simpara>
<simpara>これが、コンペの間に私が重役達に語ったことです。私はまた我々が新しいスキルセットを知り、ジャーナリスト達に新しいツールのトレーニングをする必要があると伝えました。我々は、これらを実行するプロジェクトを必要としていました。</simpara>
<simpara>そして、彼らは私に予算を与えたのです。</simpara>
<simpara>2011年の11月24日に、ABCの社内横断プロジェクトと「数字で見る炭層ガス」のサイトがABCニュースオンラインでローンチされました。</simpara>
<figure id="FIG021"><title>数字で見る炭層ガス (ABCニュースオンライン)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-01.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>それは、5ページのインタラクティブな地図と、データのビジュアライゼーション、それにテキストから構成されていた。</simpara>
<simpara>これは単にデータジャーナリズムであっただけではなく、制作チームとそのストーリーに関わる人々から生まれた異なる種類のジャーナリズムのハイブリッドで、オーストラリアの一番ホットな問題の一つになりました。</simpara>
<simpara>素晴らしかったのは、オーストラリアの炭層ガスの鉱脈と採鉱権を示したインタラクティブマップでした。ユーザーは、場所で検索を行い、鉱脈と採鉱権のモードを切り替えて見る事が出来ました。ズームインをすることで、ユーザーは採掘者が誰であるかを知り、鉱脈の状況や採掘の日程を知る事ができました。もう一つの地図は、オーストラリアの炭層ガスの活動と地下水の場所を比較するものでした。</simpara>
<figure id="FIG023"><title>オーストラリアのガス鉱脈と採掘権のインタラクティブ地図</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-02.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-02.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>我々のデータビジュアライゼーションにより、塩の無駄とその時のシナリオによって起こる水の問題が明らかになりました。</simpara>
<simpara>プロジェクトのもう一つのセクションは、化学物質の河川への流出を調査しました。</simpara>
<section id="_我々のチーム">
<title>我々のチーム</title>
<itemizedlist>
<listitem>
<simpara>
ウェブデベロッパーとデザイナー
</simpara>
</listitem>
<listitem>
<simpara>
リードジャーナリスト
</simpara>
</listitem>
<listitem>
<simpara>
データの取り出し、エクセルスプレッドシートとデータのクリーニングを専門にした、パートタイムのリサーチャー
</simpara>
</listitem>
<listitem>
<simpara>
パートタイムの経験の浅いジャーナリスト
</simpara>
</listitem>
<listitem>
<simpara>
コンサルタントエグゼクティブプロデューサー
</simpara>
</listitem>
<listitem>
<simpara>
データマイニング、ビジュアライゼーション、高度なリサーチ能力に精通したアカデミックコンサルタント
</simpara>
</listitem>
<listitem>
<simpara>
プロジェクトマネージャーとABCのマルチプラットフォームユニットのアシスタント
</simpara>
</listitem>
<listitem>
<simpara>
重要な事は、我々が必要に応じて相談をするジャーナリストのグループがいた事です。
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_どこからデータを入手したのか">
<title>どこからデータを入手したのか？</title>
<simpara>インタラクティブマップのためのデータは、政府のウェブサイトからダウンロードした汎用の地理データからスクレイピングで取得しました。</simpara>
<simpara>塩と水に関する他のデータは、様々なレポートから取得しました。</simpara>
<simpara>化学物質の放出についてのデータは、政府の環境に関する許認可から取得されました。</simpara>
</section>
<section id="_我々が学んだ事">
<title>我々が学んだ事</title>
<simpara>'数字で見る炭層ガス'は、コンテンツとスケールの点で野心的なプロジェクトでした。私の中で最も重要だった事は、私達が何を学んだのか、そして次にやるときにどれだけ違ったやり方を実践できるかという事でした。</simpara>
<simpara>このデータジャーナリズムプロジェクトによって、ABCで普段会わないような多くの人がニュース編集室にやってきました。つまりハックとハッカー達です。我々の多くは同じ言葉を話さなかったし、他の人がやっていることを理解してすらいませんでした。データジャーナリズムは、破壊的なのです！</simpara>
<simpara>実践的なこと:</simpara>
<itemizedlist>
<listitem>
<simpara>
チームが同じ場所にいる事は不可欠です。我々のデベロッパーとデザイナーは同じ建物におらず、ミーティングの度にやってきていました。これは、まったく理想的ではありません！ ジャーナリストと同じ部屋にいてもらうべきです。
</simpara>
</listitem>
<listitem>
<simpara>
我々のコンサルタントエグゼクティブプロデューサーは、同じ建物の違う階にいました。立ち寄りのために、我々はもっと近くにいる必要がありました。
</simpara>
</listitem>
<listitem>
<simpara>
データにのみ基づくストーリーを選ぶ事。
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_全体像_いくつかのアイデア">
<title>全体像: いくつかのアイデア</title>
<simpara>大きなメディアの組織は、データジャーナリズムの用件を満たすためにある程度の広さのビルにいる必要があります。私の直感では、メディアの技術部門に隠れていて外に出る事を熱望しているハッカーやギークがたくさんいます。だから、我々は"ハックとハッカーの出会い"のワークショップを行い、秘密のギークや若いジャーナリスト、ウェブデベロッパーとデザイナーが集まって経験を積んだジャーナリストと作業を行い、スキルのシェアと指導を受けさせる必要があります。</simpara>
<simpara>事実それ自体によって、ジャーナリズムは学際的なものです。データジャーナリズムチームは、いまだかつて一緒に働いた事の無い人たちからなります。デジタルスペースが、境界線を曖昧にしたのです。</simpara>
<simpara>私たちは、分裂して不信に満ちた国に住んでいます。以前プロフェッショナルな独立ジャーナリズム - 完全ではないが - を提供してきたビジネスモデルは崩壊の危機に瀕しています。私たちは、- もうすでにそうなっていますが - 持続可能な言論界が無かったら、世界はどうなってしまうのか、自分自身に尋ねる必要があります。アメリカのジャーナリストで知識人であるウォルターリップマンは1920年代にこう言いました。"ニュースへのアクセスなしにパブリックな意見は存在し得ない"。この発言はいままさに真実となりました。21世紀、人々はブロゴスフィアでくつろぎます。スピナーと嘘つき、偽善者、既得権者のグループとプロフェッショナルなジャーナリストを区別する事は難しくなっています。どんなサイトも、信頼でき真摯であるように見せかける事ができます。信頼できる発行人はどぶの溝で死んでいます。そして、この新しいジャンクジャーナリズムの空間で、ハイパーリンクは読者をもっと役にたたない、しかし素晴らしいみかけのソースに永遠に導き、そしてハイパーリンクがデジタルな鏡に戻りつづけるのです。専門用語で言うとこうです: デタラメ困惑脳。</simpara>
<simpara>デジタルスペースでは、いまや誰もがストーリーテラーです。本当でしょうか？いえ、そうではありません。もしプロフェッショナルジャーナリズム - 私が意味するのは倫理とバランスと勇気を持った真実を求めるストーリーテリングです - が生き残るなら、同業者たちはデジタルスペースでの存在感を強く主張する必要があります。データジャーナリズムは、デジタルスペースを進むためのひとつのツールに過ぎません。０と１の中で、マッピングを行い、ひっくり返して、並べ直して、フィルターをして、ストーリーを見いだすのです。将来、我々は机を並べてハッカー達やデベロッパーたち、デザイナーやコーダーと働く事になるでしょう。この変革は、本当に広い建物を必要とします。我々は、デジタルとジャーナリズムのつながりを理解できるニュースマネージャーに、創造のための投資をしてもらう必要があります。</simpara>
<simpara>&mdash; <emphasis>ウェンディ・カーライル, オーストラリア放送協会</emphasis></simpara>
</section>
</section>
<section id="_bbcにおけるデータ_ジャーナリズム">
<title>BBCにおけるデータ・ジャーナリズム</title>
<simpara>「データ・ジャーナリズム」という用語は、幅広い分野をカバーしており、報道機関においては様々な意味で用いられる。よって、BBCにおいて「データ・ジャーナリズム」という用語で我々が何を言わんとしているか定義するのが良いだろう。広い意味において、この語は以下のうち1つ以上と関連したデータを利用するプロジェクトをカバーしている。</simpara>
<itemizedlist>
<listitem>
<simpara>
読者自身に関係ある情報を発見することを可能にする
</simpara>
</listitem>
<listitem>
<simpara>
注目に値する未知のストーリーを明らかにする
</simpara>
</listitem>
<listitem>
<simpara>
複雑な問題に対し、読者にとってより良い理解への手助けとなる
</simpara>
</listitem>
</itemizedlist>
<simpara>これらのカテゴリーは重複するかもしれない。また、オンライン環境において、これらは一定のレベルのビジュアライゼーションによって恩恵を受けるものである。</simpara>
<section id="_パーソナルな問題に">
<title>パーソナルな問題に</title>
<simpara>BBCニュースのウェブサイトにおいては、読者にサービスやツールを提供するため、10年以上に渡ってデータを利用している。</simpara>
<simpara>BBCが1999年に初回公開した、政府が年に1度公開するデータを使用した <ulink url="http://bbc.in/school-league-tables">school League Tables（学校のリーグテーブル）</ulink>が最も一貫している実例である。郵便番号を入力すれば、地域の学校を表示し、様々な指標で比較することができる。教育ジャーナリストたちは公開に先駆けて、記事に関わるデータを収集するために開発チームとも提携した。</simpara>
<simpara>このプロジェクトを始めた当初、一般人がデータを探す方法を提供する公的なサイトは存在していなかった。しかし今や、相当するサービスを国自体が持っており、BBCから提供されるのはデータから導き出されるストーリーへと焦点が移動している。</simpara>
<simpara>一般市民がはっきりと関心を持っているデータについて、入手の手段を提供することこそがこの領域の挑戦である。世間一般に対し、通常、広く公開されていない巨大なデータセットを紹介したプロジェクトにおける最近の例としては、<ulink url="http://bbc.in/road-deaths">Every. death on every road（すべての道路におけるすべての死亡事故）</ulink>.  があった。英国の過去10年間で死亡者が出た交通事故の地域をユーザーが郵便番号から検索できるシステムを提供した。</simpara>
<simpara>治安に冠するデータから現れる主な事実や数字をBBCはビジュアル化<ulink url="http://bbc.in/police-data">visualized</ulink> した。また、よりダイナミックな印象や人間味をプロジェクトに与える目的で、我々はロンドン全域で起こる事故を逐一監視しようとロンドンの救急車協会とBBCロンドンのラジオ・テレビと提携した。ハッシュタグ #crash24 と併せて、オンラインで24時間体制でレポート<ulink url="http://bbc.in/road-deaths-feed">live online</ulink>され、衝突が報告されるたびに地図上にマッピング<ulink url="http://bbc.in/road-deaths-map">mapped</ulink> された。</simpara>
</section>
<section id="_シンプルなツール">
<title>シンプルなツール</title>
<simpara>膨大なデータセットを探索する手段を提供するのと同様に、BBCは読者個人に関連する情報の断片を提供するシンプルなツールを作ることにも成功している。こういったツールは長々とした解析データの探索を好まず、時間のない人々に訴求するものである。私的な事実を簡単にシェアする機能は、我々が標準的に取り入れ始めたものである。</simpara>
<simpara>世界の人口が70億を突破した正式な日に合わせて公開された、BBCの特集記事 <ulink url="http://bbc.in/KQsSzB">"The world at 7 billion: What&#8217;s your number?（70億の人々の世界: あなたは何番？）</ulink>はこの手法における面白い例である。誕生日を入力することで、生まれた日と世界の人口に応じた自分の「番号」を知ることができ、TwitterやFacebookを通じて番号をシェアすることができる。このアプリケーションでは、国連人口開発基金によって提供されたデータを利用した。非常に人気を集め、2011年英国において最もFacebookでシェアされたリンクとなった。</simpara>
<figure><title>The world at 7 billion: What&#8217;s your number?（70億の人々の世界: あなたは何番？）(BBC)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-05.png"/>
  </imageobject>
  <textobject><phrase>[図024]</phrase></textobject>
</mediaobject>
</figure>
<simpara>もうひとつ最近の例として、BBC <ulink url="http://bbc.in/JepssY">budget calculator（生活費計算機）</ulink>がある。これは大臣の予算が施行されたら、どれほど暮らし向きがよくなるのか、また悪くなるのか、読者に理解させ、その図をシェアさせるものである。我々は会計事務所KPMG LLPと提携し、彼らから年間予算に基づく試算を提供していただいた。その後、ユーザーが使いやすい魅力的なインターフェースを提供できるよう、我々は熱心に取り組んだ。</simpara>
</section>
<section id="_データ_マイニング">
<title>データ・マイニング</title>
<simpara>しかし、このどこにジャーナリズムがあるのだろうか。データにストーリーを見出すことが、データ・ジャーナリズムの従来の定義である。データベースの中に埋もれている唯一の情報はあるか？数字は正確か？データは問題を証明しているのか、もしくは反証しているのか？これらの質問を、データ・ジャーナリストやコンピューターを用いる記者が、自らに問いかけなければならない。しかし、価値ある発見に向けて希望を持ち、膨大なデータをふるいにかける作業にはかなりの時間を必要とするだろう。</simpara>
<simpara>この領域において生産的であるのは、ストーリーの調査に対して専門性と時間を持った調査チームや調査プログラムとパートナーとして組むことである、と我々は考えている。BBCの時事番組Panoramaは調査ジャーナリズムセンターと数ヶ月協業し、公的機関の給料についてデータを収集した。その結果であるテレビのドキュメンタリー番組とオンラインの特集記事 <ulink url="http://bbc.in/IKPrL2">"Public Sector pay: The numbers"（公的機関の給与）</ulink>は、機関ごとの分析から、すべてのデータをビジュアル化して公開したものである。</simpara>
<simpara>調査ジャーナリストと提携するのと同様、専門知識を持った数多くのジャーナリストを抱えておくことも欠かせない。チーム内のあるメンバーが政府の歳出見直しのデータを分析した際、実際の数字よりも大げさに感じられる、という結論に至った。その結果は独占記事 Making sense of the data（データを読み解く）で、明解なビジュアルによって補完されたその記事は王立統計学会賞を受賞した。</simpara>
</section>
<section id="_問題を理解する">
<title>問題を理解する</title>
<simpara>しかし、データ・ジャーナリズムは、他の誰も気づいていない排他的な内容になっている必要はない。データ・ビジュアライゼーションのチームの仕事は、読者に説得力のある体験をさせるために、素晴らしいデザインと編集における語り口を結びつけることである。正しいデータのビジュアル化は、問題や物語のより良い理解のために行われることであり、我々はしばしばこのアプローチをBBCのストーリーテリングにおいて行う。英国における失業給付受給者のカウントに用いられるひとつのテクニックは、時間における変化をわかりやすく伝えるためのものである。</simpara>
<simpara>データ特集Eurozone debt web（EU圏での借金）は、国家間の融資のややこしさを調査しているものである。これは明解なテキストに加え、色と矢印の太さを用いて、視覚的なやり方で小難しい問題を説明するものである。重要なのは、数字によって圧倒されることなく、読者が特集内を見て回ったり語り口を追いかけることである。</simpara>
</section>
<section id="_チームの概要">
<title>チームの概要</title>
<simpara>BBCニュースのウェブサイトのデータ・ジャーナリズムを担当するのはおよそ20人で構成されたジャーナリスト、デザイナー、開発者である。</simpara>
<simpara>データのプロジェクトやビジュアル化と同様、このチームはウェブサイト上のニュースにおけるインフォグラフィックスやインタラクティブなマルチメディアの特集をすべて担当する。同時に、我々が_ビジュアル・ジャーナリズム_と呼んでいる一連のストーリーテリングの手法をも作る。明確にデータ・ジャーナリストというメンバーは存在していないが、チーム内のすべての編集スタッフが、ExcelやGoogleドキュメントのようなデータ分析のための基本的なスプレッドシートのアプリケーションに熟達していなくてはならない。</simpara>
<simpara>あらゆるデータ・プロジェクトにおいて、中心となるのは、開発者たちの専門的スキルやアドバイス、デザイナーたちのビジュアル化におけるスキルである。我々が第一義的にジャーナリストであり、デザイナーであり、開発者である一方で、互いの専門領域に対する理解や熟練を高めるために努力せねばならない。</simpara>
<simpara>データを調査するための主な製品はExcel、Googleドキュメント、またFusion Tablesである。それらほど頻繁ではないが、もっと大きなデータセットを調査する際には、MySQLやAccessデータベース、Soirをも使用してきた。出来事をどのようにLinked Dataの技術を用いてモデル化するか見極めるため、RDFやSPARQLも使用した。開発者たちはActionScript、Python、Perlなど、取り組むデータセットの扱い、分析等においてそれぞれの選ぶプログラミング言語をも使用する。Perlは公開の一部に利用される。</simpara>
<simpara>地理的データを調査したり、ビジュアル化する際にはEsriのArcMAPに加え、Googleマップ、Bingマップ、Google Earthを使う。</simpara>
<simpara>グラフィックにはAfter Effect、Illustrator、Photoshop、Flashを含むAdobe Suiteを利用する。最近では、我々のデータのビジュアル化要件を満たしているJavaScript、特にJQueryや、Highcharts、Raphael、D3のようなJavaScriptライブラリを使うことが多く、サイト上でFlashを公開することはほとんどない。</simpara>
<simpara>&mdash; <emphasis>Bella Hurrell and Andrew Leimdorfer, BBC</emphasis></simpara>
</section>
</section>
<section id="_シカゴ_トリビューン紙のニュースアプリチームはどのように働いているか">
<title>シカゴ・トリビューン紙のニュースアプリチームはどのように働いているか</title>
<simpara>シカゴ・トリビューンのニュースアプリケーションチームは幸せなハッカー達でニューズルームに参加していた。我々は編集者や記者を援助するため、親密になり一緒に働いている。援助内容は（1） ストーリーの調査と報告すること（2）ストーリーをオンラインで描写すること（3）シカゴ在住の人々のため常に新鮮なウェブ資源を築くことである。</simpara>
<simpara>ニュースアプリチームがニューズルームにいることは重要だ。我々は常に記者とコミュニケーションを取り合うことで仕事を見つけている。ニュースアプリチームは政府の安っぽいウェブサイトのため人が読みやすい形で出力した結果からデータを抽出するためのコーディングを援助したり、大量のPDFをボロボロに解体し、機械判読性を向上させたり、他にはデータがないものを分析したりしていることを楽しんでいる。ニュースアプリチームがそれらの作業を楽しんでいることを記者たちは知っている。ニュースアプリチームはリーダーがいない集団である。そしてこのことから、初期の段階でデータプロジェクトのポテンシャルを我々は理解したのであった。</simpara>
<simpara>このデータプロジェクトの分野では我々以外にも多くのチームが存在している。我々のチームはジャーナリズムを経験した後に転職した技術者集団によって立ち上げられた。我々の中の多くにはジャーナリズムの修士号を持っているものがいる。その後何年かに渡り、仕事でコーディングをしていた。他のメンバーはオープンガバメントのコミュニティから連れて来られた人たちだ。</simpara>
<simpara>我々は日々刻々と変わっていく流れの中で働いている。確かなことは、我々は常に「シンクロ」しているということである。毎朝は5分間の立った状態でのミーティングから始まる。我々は頻繁にペアでプログラムを作る。それは2人の開発者がひとつのキーボードで開発するほうが、2人の開発者がふたつのキーボードで開発するより生産性が上がるからである。ほとんどのプロジェクトが開発に1週間かからない。しかしプロジェクト自体は1週間以上続き、長い期間繰り返され、毎週ステークホルダー（関係者）である記者や編集者の間で我々の成果を披露している。"Fail fast（早目に失敗することを経験しろ）"はスローガンである。もしやっていることが間違いであれば、なるべく早く「失敗すること」を知っておく必要がある。特に締め切りにコーディングをしているなら尚更である。</simpara>
<simpara>反復してハッキングをすることにはものすごく良い面がある。締め切りの時、我々はいつもツールキットをアップデートしている。毎週、我々はひとつかふたつのアプリをお披露目している。そして、普通のソフトウェア店とは違い、ニュースアプリチームの考えをフェードバックし、次のプロジェクトに活かしていく。記者たちとその楽しさを共有し、毎週なにかしら新しいことを学ぶのである。</simpara>
<simpara id="FIG025">シカゴ・トリビューン紙のニュースアプリチーム （photo by Heather Billings）
<inlinemediaobject>
  <imageobject>
  <imagedata fileref=":figs/incoming/02-00.jpg"/>
  </imageobject>
  <textobject><phrase>:figs/incoming/02-00.jpg</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>すべてのアプリのアイディアはニューズルームの記者や編集者たちからもたらされている。二ューズルームでは頻繁にアイディアが生まれているのに、他のニューズルームではアプリ開発チームが切り離されていることがあるように思う。我々は堅く尚且つプロ意識ある関係をニューズルームで構築している。ニューズルームらはデータを手に入れた時、そのデータはニュースアプリチームの貢献によってもたらされていることをきちんと把握している。</simpara>
<simpara>ニューズルームでの我々の仕事の多くは記者のサポートである。我々はデータを掘り起こし、PDFをスプレッドシートへと変換したり、ウェブサイトをブラッシュアップしたりするなど、記者たちを支援している。記者たちにデータを提供したいと思い、それらのことをやっている。なぜならニューズルームでのデータワークにおいてそれが早いからだ。ニュースアプリチームの作業がニュースアプリになっている。それは地図、テーブル、時には大きなウェブサイトにもなる。</simpara>
<simpara>それ以前に、ニュースアプリチームは記者たちによって書かれたストーリーからアプリへとリンクされている。それは多くのトラフィックを残している訳ではない。昨今、アプリは我々のウェブサイトのトップ近くで動いている。そしてそのアプリはストーリーを介してリンクしていて、ちょうどいい具合にアプリとストーリーの双方で働いている。我々の仕事のためのウェブサイト部門がある。しかしその部門のトラフィックもよろしくなかった。しかしトラフィックの悪さは驚くべきことではなかった。「やぁ、今日いくつかデータほしいんだけど」という会話はよく交わされるものではないからだ。</simpara>
<simpara>我々はページビューと同僚からの褒められることが大好きだ。しかしそれは面白みにかけてしまう。モチベーションは常にインパクトがあるべきである。例えば、そのインパクトとは生活であったり、法律上であったり、政治家の説明責任などである。そのインパクトが断片的に書かれたものは流行や叙情的な逸話として流布されやすい。しかし読み手は何をするのか、いつそのストーリーを終わらせるのだろうか。彼らの家族は安全なのか。彼らの子供は適切に教育されているのか。データの中に読者である彼や彼女のたち自身のストーリーを見つける援助をしているまさにその時、我々の仕事は機能している。インパクトにあふれた例として、パーソナライズされた我々のアプリにはNursing Home Safety Reports（家庭における育児の安全レポート）やSchool Report Card（学校検索レポートカード）がある。</simpara>
<simpara>ブライアン・ボイヤー, シカゴ・トリビューン紙</simpara>
</section>
<section id="_behind_the_scenes_at_the_guardian_datablog_ガーディアンのデータブログの裏側">
<title>Behind the Scenes at the Guardian Datablog（ガーディアンのデータブログの裏側）</title>
<simpara>我々がデータブログを立ち上げたとき、未加工データや統計、ヴィジュアライゼーションに誰が興味を持つのかわからなかった。私のオフィスのやや年配のある人は「どうして誰かがそれを欲しがるだろうか」と言った。</simpara>
<simpara><ulink url="http://www.guardian.co.uk/datablog">ガーディアン・データブログ</ulink>は、私が編集しているのだが、我々のニュース記事の裏側にある全てのデータ・セットを提供する小さなブログになるはずだった。現在それ<ulink url="http://guardian.co.uk/data">フロントページ</ulink> は、世界中の政府やグローバルな発展のデータの調査、すなわちガーディアンのグラフィック・アーティストによって作成されたりやウェブ上からの集められたりしたデータ・ヴィジュアライゼーションと、公共支出データの検索ツールからなる。毎日我々は、記事の背後にあるすべてのデータを共有するためにグーグル・スプレッドシートを使う。我々はデータを視覚化し、分析し、そして新聞やサイトに記事を供給するために用いる。</simpara>
<simpara>グラフィックに関わるニュース編集者・ジャーナリストとして、現在関心が持たれているニュース記事を理解するために新しいデータ・セットを集めてそれと格闘することは、私がすでにしてきた仕事の論理的な拡張であった。</simpara>
<simpara>私が尋ねられた質問は、我々のために答えられてきた。公共データにとって、信じられないほどの数年間だった。オバマは彼の最初の立法として米国政府のデータ保管庫を解放した。そしてこの例はすぐにオーストラリアやニュージーランド、イギリス政府のData.gov.ukといった世界中の政府のデータ・サイトがそれに倣った。</simpara>
<simpara>議員の経費スキャンダルの例は、イギリスのもっとも思いがけないデータジャーナリズムの一つであった。結果的に生じた副産物として、ウェストミンスターは現在、毎年膨大な量のデータを公表することを誓っている。</simpara>
<simpara>総選挙が行われたときには、主要政党のどちらもがデータの透明性、我々自身のデータの保管庫を世界に公開することを誓った。我々には貴重な紙幅を大蔵省のCOINSデータベースに割く新聞がある。</simpara>
<simpara>同時に、ウェブからは次から次へとデータが溢れ出し、世界中の読者は以前よりもニュースの背後にある未加工の事実に興味を持つようになった。我々がデータブログを立ち上げたとき、読者はアプリケーションの開発者であるだろうと考えていた。実際のところそれは、炭素放出、西ヨーロッパの移民、アフガニスタンでの死の詳細、ビートルズが彼らの曲のなかで何回「LOVE」という単語を使ったのか(613回だ)ということまでーーを知りたいという人々であった。</simpara>
<figure><title>ガーディアン・データブログの製作過程の視覚化（ガーディアン）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-ZZ.jpg"/>
  </imageobject>
  <textobject><phrase>[図026]</phrase></textobject>
</mediaobject>
</figure>
<?dbfo-need height="1in"?>
<simpara>次第に、データブログの働きは我々が直面した記事を反映し、深めてきた。我々は議員の経費に関する458,000の文書をクラウドソーシングし、議員が何を請求したかついてのデータの詳細を分析した。我々はユーザーが大蔵省の支出データベースを検索するのを助け、ニュースの背後にあるデータを公表した。</simpara>
<simpara>しかし、データ・ジャーナリズムを大きく変える出来事が、2010年の春に起こった。それぞれがアフガニスタンでの軍事行動の詳細な分析を含む、92,201行の1枚のスプレッドシートによって始まった。それはウィキリークスの戦争記録であった。それがパート1であった。さらに2つのエピソードが続いていた。イラクとthe cablesである。はじめの2つのパートの正式な用語はSIGACTS：the US military Significant Actions （アメリカ軍の重大行動）のデータベースであった。</simpara>
<simpara>ニュース組織とは地政学——ニュース・デスクとの近さがすべてである。もし近ければ、記事を提案しそのプロセスの一部を担うことは容易だし、反対にデスクの視線の外にいることは、文字通り、心の外にいることを意味する。ウィキリークス以前は、我々はデスクと違うフロアにいて、グラフィックと一緒だった。ウィキリークス以降は、同じフロアで、ニュース・デスクの隣に座っている。それは、我々がより簡単にデスクにアイデアを提案できること、編集室のジャーナリストが、我々が記事を支援していると考えることを意味する。</simpara>
<simpara>ジャーナリストが公的なデータの門番であったのはそう昔のことではない。我々はそうした数字についての記事を書いて公開し、大衆はそれに感謝した。彼らは未加工の統計に興味を示していなかった。未加工の情報を新聞に取り入れるという我々の考えは呪われたものであった。</simpara>
<simpara>今や認識を越えたダイナミックな変化が生じた。我々の役割は翻訳者になることである。人々によるデータの理解を助け、それ自体が面白いからという理由でそれをただ公表しさえするのである。</simpara>
<simpara>しかし、分析なき数字は単なる数字にすぎない。それが我々の考えだ。イギリスの首相が2011年8月の暴動が貧困についてのものではないと主張したとき、我々は、その主張の背後にある真実を示すために、暴動参加者の住所を貧困の指標とともにマッピングすることができた。</simpara>
<simpara>我々のすべてのデータ・ジャーナリズムの記事の背後にあるのはプロセスである。それはいつも、我々が新しいツールとテクノロジーを使うたびに変化する。ある種のスーパー・ハッカーになり、コードを書き、SQLに没頭することが正解なのだという人もいる。そのようなアプローチを選択することもできる。しかし、我々がする仕事の多くはただExcelで行われている。</simpara>
<simpara>はじめに、我々は、速報のニュース記事や、政府のデータ、ジャーナリストによる調査などのさまざまな情報源からデータを探し出したり受け取ったりする。そして、そのデータで何ができるかを探り始める。他のデータ・セットと混ぜ合わせる必要があるだろうか？経時的な変化をどう示せるだろうか？それらのスプレッドシートはしばしば真剣に整理する必要があるーーそれらすべての本質的ではない列や奇妙ににまとめられたセルは本当に役に立たない。また、それがPDF、すなわち人類の知る最悪のデータのフォーマットではないことが前提になる。</simpara>
<simpara>しばしば公的なデータには公的なコードが組み込まれている。学校や病院、選挙区、地方自治体はいずれも独自の識別コードを持っている。</simpara>
<?dbfo-need height="1in"?>
<simpara>国家もまたそうしたコードを持っている(例えばイギリスのコードはGBだ)。それらは使いやすい（使いにくい）。データ・セットを組み合わせようとしたとき、どれほど多くの綴りや文字配列の違いがそれを妨げうるかということは驚くほどである。ビルマとミャンマー、アメリカのファイエット郡(ジョージア州からウェストヴァージニア州には11の同名の郡がある)といった例が挙げられる。コードは、我々に（動詞の？）likeと（前置詞の？）likeを比べることを強いる。</simpara>
<simpara>プロセスの最後にあるのがアウトプットだ。ストーリーやグラフィックやヴィジュアライゼーションという選択肢があったとき、我々はどのツールを使うべきだろうか？我々の最も頻繁に使うツールはあるものを素早く作ることのできる無料のものである。より洗練されたグラフィックは我々の開発チームによって作られる。</simpara>
<simpara>これは我々が通常は簡素な折れ線グラフや円グラフを作るときにグーグル・チャートを使い、地図を素早く簡単に作成するときにグーグル・フュージョン・テーブルを使うということを意味する。</simpara>
<simpara>それは新しいもののようにみえるが、実際はそうではない。</simpara>
<simpara>マンチェスター・ガーディアンの創刊号(1821年5月5日土曜日)では、現在のすべての新聞と同様に、ニュースは裏ページにある。第１面に載った最初のものは迷子のラブラドールについての広告であった。</simpara>
<simpara>記事や詩の引用に囲まれて、裏ページの３つめは、そう、事実で占められている。その地域の学校の費用の包括的な表はそれまで「公衆の面前に晒された」ことはなかったと「NH」は書く。</simpara>
<simpara>NH はかれのデータが公表されることを望んでいた。なぜなら、さもなければその事実が未熟な聖職者が報告することに託されてしまう。かれのモチベーションは「そのような情報は、それが含んでいるもの自体価値がある。なぜなら、教育がどれほどの費用がかかるのか知らずにいれば、社会の状況と将来の進歩によって形作られる最良の意見は必ず誤ったものになるだろうということが明らかになるからだ」というものだ。言い換えれば、もし人々がいま起こっていることを知らなければ、どうして社会はより良くなりうるだろうか?</simpara>
<simpara>私は我々がいま取り組んでいることに対する理論的根拠を思いつくことはできない。かつて裏ページの記事であったものは今や、第一面のニュースになりうる。</simpara>
<simpara>&mdash; <emphasis>サイモン・ロジャース, ガーディアン</emphasis></simpara>
</section>
<section id="_zeit_onlineでのデータジャーナリズム">
<title>Zeit Onlineでのデータジャーナリズム</title>
<simpara>OECD生徒の学習到達度調査（PISA）プロジェクト The <ulink url="http://bit.ly/Pisa_Wealth">PISA based Wealth Comparison</ulink> は、各国の生活水準を比較できるinratarctibe bisualizationです。これは、2010年12月に出版されたOECDの包括的な世界の教育ランキングレポートのデータが使われています。<ulink url="http://bit.ly/Pisa_2009">PISA 2009</ulink>　このレポートは、14歳の生徒達への生活状況についてのアンケート調査に基づいています。</simpara>
<simpara>このアイディアは各国の生活水準を比較するユニークな方法を提供するために、このデータを分析し、視覚化することでした。</simpara>
<figure id="FIG027"><title>PISA based Wealth Comparison (Zeit Online)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-03-AA.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-03-AA.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>まず、社内の編集チームは、事実は生活水準を比較する事ができ、かつ可視化される事も含めて有用でありそうだという事を決定した。</simpara>
<itemizedlist>
<listitem>
<simpara>
富 (テレビや車、家のトイレの数など）
</simpara>
</listitem>
<listitem>
<simpara>
家族構成 (祖父母と同居しているか、1人っ子の家族の割合、親の失業、母の勤務状況など）
</simpara>
</listitem>
<listitem>
<simpara>
情報源 (家でのネット環境、電子メールの頻度や所有する書籍の量)
</simpara>
</listitem>
<listitem>
<simpara>
それぞれの国の発展のレベルを示す 3つの追加指標
</simpara>
</listitem>
</itemizedlist>
<simpara>内部設計チームの助けを借りて、これらの事実は、一目瞭然のアイコンに翻訳されました。フロントエンドは、まるでカードゲームをしているように見えるように、各国の比較ができるような設計を施しました。</simpara>
<simpara>次に、プロジェクトを助けることができる開発者を見つけるためにドイツの人々<ulink url="http://opendata-network.org/">Open Data Network</ulink> に連絡を取った。非常に意欲的な人達が集まるこのコミュニティは、私たちの夢を叶える事ができるであろうアプリケーションのコードが書ける（しかも私たちにとってもとっても重要だったフラッシュを使わずに！）非常に才能のある情報でデザイナー、Gregor Aischを紹介しました。グレゴールは<ulink url="http://raphaeljs.com/">ラファエル·Javascriptのライブラリ</ulink>に基づいて、美しいバブルスタイルで非常に高品質でインタラクティブなビジュアライゼーションを作成しました。</simpara>
<simpara>私たちの共同作業の結果は、多くのトラフィックを得てとてもsuccessful interactiveでした。任意の二カ国を比較するのは簡単で、参照ツールとしても有用なツールになります。これは私たちの日々の編集作業でも再利用できることを意味します。例えば、私たちはインドネシアでの生活状況に関連するものを対象としている場合、私たちは迅速かつ容易に[インドネシアとドイツでの生活状況を比較する]グラフィックhttp://bit.ly/Pisa_Indonesia_Germanyを埋め込むことができます。社内のチームに伝達したノウハウは、将来のプロジェクトのための素晴らしい投資でした。</simpara>
<simpara>ツァイトオンラインでは、我々の <ulink url="http://www.zeit.de/datenjournalismus">http://www.zeit.de/datenjournalismus</ulink> [当社のデータジャーナリズムのプロジェクト]が、私たちに多くのトラフィックをもたらし、また新しい方法でユーザーと関係性をもたらすという事が分かりました。例えば、日本での津波の後に福島の原子力発電所の状況についての報道がたくさんあり​​ました。放射性物質が発電所から漏れた後、発電所から30キロ以内にいた人は皆避難しました。人々は避難について多くを読み、見ることができました。ツァイト·オンラインは、私たちドイツの聴衆にこのインパクトを説明するための革新的な方法を見つけました。私たちは尋ねました：ドイツの原子力発電所の近くに何人の人達が住んでいるのか？ 半径30キロ以内には何人の人達が住んでいるのか？マップでは、[ドイツで福島と似たような状況の場合に何人の人達が避難しなければならないのか〕http://bit.ly/near_nuclear を示しています。結果：それはもう大量のトラフィックです。実際、このプロジェクトはソーシャルメディアで一気に広がりました。データジャーナリズムのプロジェクトは、比較的容易に他の言語でも適合させやすいのです。我々はアメリカにある原子力発電所の近接性について英語バージョンを作成し、そのサイトも素晴らしいトラフィックを稼ぐ原動力になりました。報道機関は、読者の中で、信頼され、権威ある情報源として認められたいと考えています。私たちは、データジャーナリズムのプロジェクトが、読者が生データを見たり再利用する事ができる事と連携する事によって、高い信頼性をもたらすということが分かりました。</simpara>
<simpara>2年間R&amp;D部門やツァイトオンラインの編集長を勤めたヴォルフガング·ブラウは、データジャーナリズムがストーリーを伝えるのに重要な方法である事を提唱し続けていました。透明性、信頼性、そしてユーザーとのつながりは我々の哲学の重要な要素の一つです。それゆえ、データジャーナリズムは私たちの現在および将来の仕事のナチュラルな1つなのです。データ視覚化は、物語の反応に価値をもたらす事ができ、そしてそれは彼らのコンテンツを公開する編集チーム全体にとって魅力的な方法です。</simpara>
<simpara>例えば、2011年11月9日、ドイツ銀行は、クラスター爆弾の製造業者への融資停止を約束した。しかし、財政に直面する非営利団体の調査によると、銀行はその約束がなされた後にもクラスター爆弾の生産者への融資を承認し続けた。<ulink url="http://zeit.de/wirtschaft/cluster-munition">私たちの視覚化</ulink>のデータは、様々なお金の流れを私たち読者に示している。ドイツ銀行会社の別の部署では、下部層でクラスター爆弾を構築する上で関与したと非難された企業と一緒に、上層部で調整もされていた。合間に、個々のローンは時系列で表される。その輪を転がしてみると、各取引の詳細を示している。もちろんその物語は書かれた記事のように伝えていた可能性がある。しかしこの可視化は、読者にとってより直感的な方法で、金融の依存関係を理解し探求する事を可能にする。</simpara>
<figure id="FIG028"><title>爆弾のビジネス (Zeit Online)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-03-DD.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-03-DD.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>別の例を見てみよう：<ulink url="https://www.destatis.de/EN/Homepage.html">ドイツ連邦統計庁</ulink>は、<ulink url="http://bit.ly/German_Federal_Statistics">2060までの様々な人口統計モデル</ulink>を含むドイツの人口統計に基づく素晴らしいデータを公開した。これらを表現する一般的な方法は、<ulink url="https://www.destatis.de/bevoelkerungspyramide/">連邦統計庁から一部抜粋</ulink>などの人口ピラミッドだ。</simpara>
<simpara>科学部からの私達の同僚と、私達は私達の読者に私たちの未来社会について投影人口統計データを探索するためのより良い方法を提供しようとした。 <ulink url="http://www.zeit.de/wissen/altersstruktur">http://www.zeit.de/wissen/altersstruktur</ulink> [私たちの視覚化]で、我々は、1950年から2060年までのそれぞれの時代の統計学的に典型的な40人のグループを公開した。彼等は8つの異なるグループで構成される。これは、異なる時点でのドイツ社会の集合写真のように見える。伝統的な人口ピラミッドで同じ視覚化されたデータは、その上児湯についてとても抽象的な感じのみを与えるが、しかしながら、子供たち、若い人、大人、高齢者というグループは、我々の読者がより簡単にデータに関連することができる。あなたはは10年の間にただ再生ボタンを押し旅を始める事ができる。何十年も、あなた自身の平均寿命を通して、あなたの人口統計の旅を見て：あなたはまた、集合写真の一部になるように、出生や性別の自分の年を入力することができる。</simpara>
<simpara>&mdash; <emphasis>Sascha Venohr, Zeit Online</emphasis></simpara>
<figure id="FIG0210"><title>Visualizing demographic data (Zeit Online)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-03-CC.png" scale="94"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-03-CC.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_どうやってハッカーを雇えばいいの">
<title>どうやってハッカーを雇えばいいの？</title>
<simpara>私はジャーナリストたちによって定期的に「私のプロジェクトを手伝ってもらうためにどのようにして私はコーダーを雇えばいいのでしょうか？」と尋ねられることがある。思い込みにだまされちゃいけない、これはひとつのプロセス方法であって、公共心のあるハッカーやデータ論争者はよく熱心にジャーナリストたちと連絡をとっている。</simpara>
<simpara>ジャーナリストはデータ駆動型ツールやサービスのパワーユーザーである。ディベロッパーの視点から、ジャーナリストはデータツールをコンテクストにおいて使用することを既成概念にとらわれずに考えていて、ディベロッパーはいつも事前に考慮することなどない。(フィードバックは価値のないものだ！)彼らはまたコンテクストを立ち上げる手助けをし、プロジェクト周辺でバズらせ、関連性が生まれるように寄与している。それは相互関係性である。</simpara>
<simpara>幸運なことに、ハッカーを雇おうと探していたり、乏しい予算でのコラボレーションの可能性を模索していよう。すると、前述の可能性があなたを助けることに興味を持って、それは協働してくれる誰か(ディベロッパー)がいるということを意味しているのだ。</simpara>
<simpara>ではどのようにして見つければいいのだろうか？ニューヨークタイムズのAron Pilhoferはこう述べている:</simpara>
<blockquote>
<simpara>あなたの組織には既にあなたが必要としているすべてのスキルを持ち合わせた人がいることをわかっているだろう、しかし彼らはあなたのニュースルーム内で既に必要とされていないのだ。探しまわって、テクノロジーやIT部門を訪れると、素晴らしい人材を見つけるであろう。コーダー文化のよさがわかることも重要で、そこで理想の人と出くわすでしょう&#8230; <xref linkend="FIG0211"/> &#8230;そしてたぶん勝者になるのです。</simpara>
</blockquote>
<figure id="FIG0211"><title>名誉の証として：ハッカーにとって見つけることは日常茶飯事であり簡単である。(photo by Lucy Chambers)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-04.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-04.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>もういくつかアイディアがある:</simpara>
<variablelist>
<varlistentry>
<term>
ジョブウェブサイトに投稿する
</term>
<listitem>
<simpara>
  自分の身分を明かした上で、異なるプログラミング言語を使って働いているディベロッパーに向けてウェブサイトに投稿する。例えば、Python Job Boardである。<ulink url="http://www.python.org/community/jobs/">Python Job Board</ulink>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
関係性があるメーリングリストにコンタクトをとる
</term>
<listitem>
<simpara>
  例えば、NICAR-L や Data Driven Journalism のメーリングリストである。<ulink url="http://bit.ly/nicar-subscribe">NICAR-L</ulink> and <ulink url="http://bit.ly/ddj-list">Data Driven Journalism</ulink>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
関係性がある団体にコンタクトをとる
</term>
<listitem>
<simpara>
  例えば、ウェブからのデータのクリーンアップやスクラップをしたければ、Scraperwiki　<ulink url="https://scraperwiki.com/">Scraperwiki </ulink>,　のような素晴らしい信頼性と意志あるコーダーが載った機関にコンタクトをとることができるであろう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
関係あるグループやネットワークに参加する
</term>
<listitem>
<simpara>
  Hacks/Hackers  <ulink url="http://hackshackers.com/">Hacks/Hackers</ulink> のようなジャーナリストと技術者が一緒になる独創力あるところを訪ねる。Hacks/Hackersのグループは現在世界中で盛り上がっている。あなたはjobs newsletter <ulink url="http://bit.ly/hacks-hackers-jobs">jobs newsletter</ulink> に投稿してみることもできるでしょう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
局所的で面白そうなコミュニティ
</term>
<listitem>
<simpara>
  あなたは自分の地域で気軽に専門技術に関する分野を検索することができるでしょう。(例えば、Javascript＋ロンドン) Meetup.comのようなサイトはスタートするのにもってこいの場所でもある。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ハッカソンとコンペ
</term>
<listitem>
<simpara>
  賞金があろうとなかろうと、アプリやビジュアライジングコンペやディベロップメントデイはよくコラボレーションやコネを作る機会として有益である。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
「オタク」な人に聞いてみる
</term>
<listitem>
<simpara>
  オタクは他のオタクとつるんでいる。口コミは常に優秀な人と一緒に働く機会を見つけるのに素晴らしい方法である。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>&mdash; <emphasis>ルーシー・チェンバース, オープンナレッジ財団</emphasis></simpara>
<sidebar>
<title>ハッカーのスキル</title>
<simpara>ひとたびハッカーを見つけると、もし彼らに優れた面がある場合、どのようにしてあなたはそれを知るのだろうか？我々はガーディアンのリードインタラクティブテクノロジストであるAlastair Dantに尋ねたところ、彼の視点から目をつける良い方法をあげてもらった:</simpara>
<variablelist>
<varlistentry>
<term>
大量のコーディングを行う
</term>
<listitem>
<simpara>
  締め切りを対応する時、ひとつをマスターしてるよりはよろず屋であるほうがよい。 ニュースアプリはデータや動画の取り扱いや思い切った心が必要である。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
全体を見る
</term>
<listitem>
<simpara>
  全体論的思考は技術的細部に物語的価値を植えつけることができる。私は曖昧な物差しで 絶え間ない妙技より、むしろある音色の感情こもった演奏を聞くであろう。デザイナーの 横で働くことがこんなに幸せなのか！とわかる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
優れたストーリーを伝える
</term>
<listitem>
<simpara>
  物語的プレゼンテーションは空間と時間内で物事をまとめる必要がある。彼らはどの計画にもっとも誇りを持っているのか？であったり、その計画が構築された順を追って説明できるか？という問いがわかっている。つまりこれは彼らの技術的理解力と同じように彼ら のコミュニケーション能力が明らかになるであろう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
通して話す
</term>
<listitem>
<simpara>
  物事を素早く構築することは混合されたチームの共通の目的を越えた働きが必要とされる。それぞれの参加者は仲間同士を尊敬すべきかつ意思疎通をしっかり図るべきである。見えない曖昧な部分は素早い再計画と妥協案の集積が必要とされる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
互いに教え合う
</term>
<listitem>
<simpara>
  テクノロジーの進歩は早い。遅れないでついていこうと努力するであろう。様々な背景から、優秀なディベロッパーにもっとも共通する特徴は、要求に応じて快く新しいものを学ぼうとすることである。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>&mdash; <emphasis>ルーシー・チェンバース（オープンナレッジ財団）による Alastair Dant（ガーディアン、主任 <phrase role='keep-together'>インタラクティブ</phrase> 技術者）へのインタビュー</emphasis></simpara>
</sidebar>
<?dbfo-need height="1in"?>
<sidebar>
<title>夢のようなディベロッパーの見つけ方</title>
<simpara>良いディベロッパーと素晴らしいディベロッパーの生産性の違いは線形でなく、指数関数的なものである。良き雇用は非常に重要である。不運なことに、良き雇用は難しくもある。もしあなたが経験を積んだテクニカルマネージャーでない場合、候補者を十分に精査することは難しい。加えて、新しい機関は給与を支払う余裕があり、あなたは十分にチャレンジできる。</simpara>
<simpara>シカゴトリビューンにて、我々は2つの観点から雇用を行なっている。それは感情的な面と技術的な面である。ここで働き、そして世界を変えられるのである。技術的には、我々はどれだけあなたが学ぶのかを助長します。我々のプロジェクトは小さく、素早く、反復性あるものである。それぞれのプロジェクトが新たなツールのセット、新たな言語、新たなトピック(火災安全や年金制度)で、あなたはそれらを学ばなければいけない。ニューズルームは坩堝である。我々のチームのように、多くかつ素早く学んだチームを厳粛に管理することなど決してしないのである。</simpara>
<simpara>どこを見るのかということに関しては、我々はオープンガバメントコミュニティで優秀なハッカーを見つけることができるという非常に素晴らしい運を持っていた。サンライトラボのメーリングリストにはくだらない。その日の仕事に夜出かける空想的考えの慈善家的オタクたちが入っている。もうひとつの潜在的な資源にはCode for Americaの存在がある。毎年、CfAから現れるフェローグループが次のビッグプロジェクトを探している。そして、そのボーナスとして、CfAには厳格なインタビュープロセスがある。それは彼らは既に自分自身についてとことん調べていることが終わっているかということである。現在、プログラミングに興味を示しているジャーナリストはジャーナリズムスクールにも現れ始めている。彼らは青二才であるが、大いなる可能性も秘めている。</simpara>
<simpara>最後に、ただディベロッパーを雇うだけでは十分でない。あなたは技術的な管理も必要なのだ。拳銃一丁のディベロッパー(特にジャーナリズムスクールからの新人で産業的仕事経験のない)は多くの誤った決定を下してしまうであろう。優秀なプログラマーでさえ、彼女の計画を任された時は、技術的な興味深い仕事はもっとも聴衆に重要なことはなにかということを徹底的に調べ、吟味するであろう。</simpara>
<simpara>いつでもニュースアプリケーション編集者やプロジェクトマネージャーを雇おうと言うのだ。記者やプログラマーが編集者を必要としていいて、さながらそれは、良き指導者と誰かが締め切りまでにソフトウェアを開発するために論争するようなものである。</simpara>
<simpara>&mdash; <emphasis>ブライアン・ボイヤー, シカゴ・トリビューン</emphasis></simpara>
</sidebar>
</section>
<section id="_外部の専門家を活用する">
<title>外部の専門家を活用する</title>
<simpara>2010年3年月、オランダのユトレヒトで活動するデジタルカルチャーの法人SETUPが「ジャーナリズムをハックする」と題したイベントを開催しました。イベントを通じて、ディベロッパーとジャーナリストとのコラボレーションを促進させるためです。</simpara>
<simpara>参加したプログラマは「かっこいいアピリケーションをつくるためにハッカソンを開くことがほとんどですが、データが含有する面白いストーリーについて私たちはなかなか気づくことができません。つくったモノに社会的な文脈がないのです」と通常のハッカソンについて話し、一方でジャーナリストは「データジャーナリズムの重要性は認識しているものの、技術的なスキルが十分にないのでつくりたいものをつくることができないのです」と自身の認識を話していました。</simpara>
<simpara id="FIG0212">ハッカソン：ジャーナリストとディベロッパーの協業 (photo by Heinze Havinga)
<inlinemediaobject>
  <imageobject>
  <imagedata fileref=":figs/incoming/02-XY.jpg"/>
  </imageobject>
  <textobject><phrase>:figs/incoming/02-XY.jpg</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>私の働く地域の新聞社では、ニューズルームにプログラマを雇う資金やインセンティブがありません。このころのオランダにとって、「データジャーナリズム」はまだまだ見知らぬ存在でした。</simpara>
<simpara>ハッカソン式のイベントは大成功でした。コラボレーションにぴったりのリラックスした雰囲気で、会場にはピザや栄養ドリンクもたくさんありました。RegioHack (“地方ハック”の意)は、私の勤めている地域の新聞社De Stentor が主催し、siter publicationの TC Tubantia と Saxion Hogescholen Enschede が会場を提供してくれました。</simpara>
<simpara>イベントの環境は以下のようなものでした： 30時間のハッカソンである。誰でも参加できる。食べ物の飲み物を支給。参加人数30人を目標にし、それぞれを6つのグループに分ける。グループごと、犯罪、健康、輸送、安全、加齢とパワーなどのトピックを設定し、それに焦点を当てて取り組んでもらう。主催したわたしたちは特に以下のような目標を設定しました</simpara>
<variablelist>
<varlistentry>
<term>
ストーリーを見つける
</term>
<listitem>
<simpara>
  私たちにとってデータジャーナリズムは新しくて未知のものです。そこでその有用性を証明するためには、上手に組み立てられたストーリーを通じて伝える必要があります。データを用いた少なくとも3つのストーリー、生み出す計画にしました。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<?dbfo-need height="1in"?>
<variablelist>
<varlistentry>
<term>
人々をつなげる
</term>
<listitem>
<simpara>
  私たちジャーナリストはデータジャーナリズムの仕掛けはわかりません。また、わかったふりをするのも適切ではないでしょう。何よりもジャーナリスト、学生とプログラマの3人を30時間同じ部屋に居座らせ、知識やインサイトを共有してもらうことが大事なのです。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ソーシャルなイベントを開く
</term>
<listitem>
<simpara>
  新聞社はハッカソンはもちろんのこと、あまり社会に開いたイベントを催しません。実際にソーシャルなイベントがどのような結果を生み出せるか実験したかったのです。ともすれば、非常に密度の高い時間―30時間他人と専門用語の通じない者同士が話し合う時間―をピザや栄養ドリンク、ソーシャルな雰囲気づくりによって、ジャーナリストとプログラマが快適でコラボレーションしやすい環境をつくりたかったのです。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>イベントの前、TC Tubantiaは警官だった夫をなくした未亡人とのインタビューをしたばかりでした。夫人はかつて夫が働いていたころについて本を書き、夫が管理していた1945年以来のオランダ東部のすべての殺人事件の登録記録文書を持っていました。通常であれば、文書をウェブサイトで公開するだけになってしまうのですが、今回は<ulink url="http://bit.ly/tableau-dashboard">Tableau softwareを使ってダッシュボードをつくりました</ulink>。このソフトウェアを使ってどんなものが生まれたか、RegioHackのサイトに<ulink url="http://bit.ly/regiohack-blog">bloggedブログをかきました</ulink>。</simpara>
<simpara>ハッカソンで、あるプロジェクトグループは地域の学校の開発と高齢化をテーマに取り組みました。<ulink url="http://bit.ly/tableau-workbook">将来を投影するビジュアライゼーションをつくる</ulink>ことで、数年後に入学者の減少で困る町がどこなのか理解することができました。私たちはこうしたインサイトを元に、地域の学校に起きる影響について記事を書きました。200個のツイートという意味の「De Tweehonderd van Twente 」という野心的なプロジェクトをスタートさせ、地域のツイッターユーザーで最も影響力の大きいユーザーを判定し、データベースをつくりました。</simpara>
<simpara>天文学的な数の計算を経て、影響力のある組織との関係が強いのは誰かを示したリストを作りました。これは今後記事を書くいい材料になるだけでなく、（このリストを通じて記事の執筆を生み出すことができるだけでなく、）ジャーナリストにとっても強力なツールとなります。誰と誰が関係性をもっているか、データベースでその答えを見つけ、日常的に使うことができます。また、このデータベースは文化的な価値も持ち合わせています。芸術家から、このデータベースを使ったインスタレーションアートをつくりたい、との問い合わせもありました。</simpara>
<figure id="FIG0213"><title>データジャーナリズムを通じて出会った人々が新しいコミュニティをつくる　（写真: Heinze Havinga)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-YY.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-YY.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>RegioHackのあと、ジャーナリスト達はこれまでの伝統的なジャーナリズムにデータジャーナリズムを付け加え生かすことができるものだと考えるようになりました。私の同僚たちは、このイベントで学んだことを生かし、さらに野心的で技術的なプロジェクトを作り始めました。たとえば、住宅の管理コストについてのデータベースなどです。私はこのデータを元に、Google のFusion Tableを使って、 <ulink url="http://bit.ly/stentor-map">インタラクティブな地図</ulink>をつくりました。読者がデータを操作でき、その結果をクラウドソーシングしたのです。<ulink url="http://bit.ly/scratchbook-crowdsourcing">(事例はこちら)</ulink>。Fusion Tablesをつかって、どうやって地図を使ったのかたくさん質問があったので <ulink url="http://bit.ly/vermanen-video">解説のビデオ</ulink>も用意しました。</simpara>
<?dbfo-need height="1in"?>
<simpara>私たちが得た学びはなにか？たくさんあります。同時に障壁もたくさんありました。4つの気づきがありました。</simpara>
<variablelist>
<varlistentry>
<term>
どこから始めるか：問いか、データか
</term>
<listitem>
<simpara>
  どのプロジェクトを情報を探そうとするとそこで失速してしまいました。ほとんどの場合、ジャーナリスティックな質問から始めるのですがそのあとが問題です。データがあるのか？どこで見つけられるか？　こうしたデータを見つけたら、質問に答えることができるでしょう。ジャーナリストは記事のために調査をするときはどこで情報を手にいることができるか基本的には知っているのですが、データジャーナリズムとなると、どこでその情報を入手できるかほとんどの人が知りませんでした。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Little technical knowledge
</term>
<listitem>
<simpara>
  データジャーナリズムはとても技術的な学問です。情報を集めたり、結果をビジュアライズするためにプログラミングをしなければいけません。素晴らしいデータジャーナリズムのために必要なことは二つ：ジャーナリスティックな経験と洞察力、そしてあらゆるデジタルに関する技術的なノウハウ。RegioHackでは、なかなかこれらを持ち合わせた人物はいませんでした。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ニュース価値があるか
</term>
<listitem>
<simpara>
  参加者は様々なソースの相関関係からニュースを見つけるというより、ひとつのデータセットを使って、ニュースを見つけようとする傾向にありました。その理由は、データジャーナリズムには統計学的な知識を元に、ニュースを確定する必要があるからです。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
毎回繰り返すことは何か？（データジャーナリズムの型とは？）
</term>
<listitem>
<simpara>
  上記すべてを踏まえると、毎回繰り返す決まった型（ルーティン）は存在しないのです。参加者はそれぞれにスキルを持っていますが、ただいつどのように使えばいいのかわからないのです。あるジャーナリストは「ケーキを焼くようなもの」と言い表しました。「材料は全部そろっているんだ。小麦粉、卵、牛乳など。それを一緒くたにして混ぜ、ケーキができるといいなあ、と願う。まるでそんな状態だ。」と話したのですが全くその通りで、材料は揃っているけれどレシピがわからないのです。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>では、これからどうするか？私たちの行った初のデータジャーナリズムの経験は、この分野で頑張ろうとしているプログラマやジャーナリストに役立つと思います。これをレポートにする予定です。</simpara>
<simpara>また、RegioHackをハッカソンの形で続ける方向性で考えています。楽しくて、為になって、生産的な形でデータジャーナリズムの紹介をできるのですから。</simpara>
<simpara>仕事の現場でのジャーナリズムについては、ニューズルームとの統合をしなければなりません。ジャーナリストはデータ思考を養うことを、これまでの引用やプレスリリース、理事会に加えてしていかなければいけません。RegioHackを通じて、データジャーナリズムが単なる流行ではなく、より情報に満ちた、特徴的な記事を書くことができ、読者に紙とオンラインで異なる記事を提供することができるのだと示すことができたと思います。</simpara>
<simpara>&mdash; <emphasis>Jerry Vermanen, NU.nl</emphasis></simpara>
</section>
<section id="_その金を追え_データジャーナリズムとクロスボーダーコラボレーション">
<title>その金を追え！: データジャーナリズムとクロスボーダーコラボレーション</title>
<simpara>世界の多くの人々の生活に影響を与える組織犯罪や汚職を暴くことに興味のある調査ジャーナリストと多くの市民は、日を追うごとに、これまでになかった情報へアクセスすることができるようになった。膨大なデータが政府や他の機関によって公開されたオンラインで利用できるようになり、そして、すべての人に必要な情報が入手可能になった。しかし、同時に、政府の汚職に係わる役人や組織犯罪グループは悪行を隠すために、最善を尽くして情報を隠している。彼らはすべての社会レベルにおいて紛争、​​飢餓、またはその他の危機による混乱を引き起こし人々を暗闇の中に陥れる努力をしている。</simpara>
<simpara>そのような悪行を暴き、汚職や犯罪のメカニズムを防ぐのは調査ジャーナリストの義務である。</simpara>
<figure id="FIG0214"><title>The Investigative Dashboard (OCCRP)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-RR.png" scale="92"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-RR.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>たとえ、最も厳しい環境にあっても、ジャーナリズムを通じて犯罪や汚職の主要な活動を調査するにあたってによい方向へと導いてくれる主要なガイドラインが3つ存在する。</simpara>
<variablelist>
<varlistentry>
<term>
国外に目を向ける
</term>
<listitem>
<simpara>
  多くの場合、調査ジャーナリストが対象としている国外からの情報の入手の方が、その国の情報の入手するより容易である。他国の情報へのアクセスに関する法律に基づく、あるいは国外において収集された情報データベースこそ、まさにあたなが扱っている問題に追加する必要があるものである。その上、汚職をしている役人と犯罪者は自身が盗んだ金を手元に置いておこうとはせず、海外の銀行や外国に投資しようとする。そう、犯罪はグローバルである。インターネット上には国際的に移動するそのような金を追跡する上で調査ジャーナリストをアシストするデータベースは多く存在する。例えば、<ulink url="http://www.investigativedashboard.org/category/wwd/">Investigative Dashboard</ulink> はジャーナリストが国境を超えた金の追跡するのを可能にしてくれる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
調査ジャーナリストのネットワークを活用する
</term>
<listitem>
<simpara>
  世界の調査ジャーナリストはグループを作っている。
例えば、<ulink url="http://www.reportingproject.net/">The Organized Crime and Corruption Reporting Project</ulink>,<ulink url="http://www.fairreporters.org/">The African Forum for Investigative Reporting</ulink>, <ulink url="http://arij.net/">The Arab Reporters for Investigative Reporting</ulink>, <ulink url="http://arij.net/">The Arab Reporters for Investigative Journalism</ulink>, and <ulink url="http://www.gijn.org/">The Global investigative Journalism Network</ulink>のようなグループである。
　
ジャーナリストは日々の国際的ジャーナリズム情報が交換されているIJNetのようなプロのジャーリズムプラットフォームを活用することも出来る。同じような問題や状況に直面している記者たちがグループを形成しているため、情報や手法の交換が有効である。また、これらのネットワークはメーリングリストやSNS上のグループを活用しているので、仲間のジャーナリストにアドバイスを求めたり、相談することは非常に容易である。また調査ストーリーのアイデアはこれらのフォーラムやメーリングリストから収集することが可能である。　＜要削除：http://www.gijn.org＞
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
テクノロジーを用い、ハッカーとコラボする
</term>
<listitem>
<simpara>
  ソフトウェアは調査ジャーナリストの情報へのアクセスとその処理を助けてくれる。多様な種類のソフトが、調査におけるノイズを除去したり、大量のデータから意味を掘り下げること、あるいはストーリー作るために必要なドキュメントを発見することを助けてくれる。情報を解析するための既成のソフトが多く存在すること、さらに重要な事に、ジャーナリストは多くのプログラマーが相談すれば助けてくれることについて知っておく必要がある。これらのプログラマーやハッカーはどのように情報を入手して、どのようにデータを扱うべきか知っている。そして彼等は調査のために多くの協力を行ってくれる。これらのプログラマー達（その多くはオープンデータ運動のメンバーでもある）は犯罪や汚職との戦いにおいて大きな仲間となってくれると共にジャーナリストを情報を分析するための手助けもしてくれるだろう。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>プログラマーと市民のよいインターフェースの例は<ulink url="https://scraperwiki.com/">ScraperWiki</ulink>である。
これはジャーナリストがプログラマーにWebサイトからデータを入手するために助けを求めることの出来るサイトである。調査ダッシュボード<ulink url="http://bit.ly/dashboard-resources">maintains a list of ready-made tools</ulink>もまた、ジャーナリストがデータを処理、分析するのを助けてくれる。</simpara>
<simpara>これらのガイドラインのよい例は多くの事例で見つける事が出来る。例えば、Khadija Ismayilovaの例がそうである。経験のあるアゼルバイジャン人の彼女は情報の入手に関して、厳格な環境にある調査報道記者である。Ismayilovaはアゼルバイジャンのより良い信頼できる公共の情報を作成するために日々の困難を克服した。2011年の6月、 Radio Free Europe/Radio Liberty&#8217;s (RFE/RL) の調査報道記者、Khadija Ismayilovaはアゼルバイジャン大統領の娘Ilham Aliyevが秘かに、<ulink url="http://bit.ly/rferl-azerfon">a fast-rising telecom company, Azerfon</ulink> をパナマのオフショア企業を経由して経営していた事を伝えた。それは170万人近い登録者や、国土の80%をカバーしていること、当時アゼルバイジャン唯一の３Gサービスの提供者であることを誇っていた。Ismayilovaはその企業のオーナーが誰であるかを見つけることに3年を費やしたが、政府は企業の所有者が誰であるかを公開することを断わり、何度も企業の所有権について嘘をつき続けてきた。彼らは企業がドイツに本社を置くSiemens AGによって所有されているとさえ主張した。その主張はSiemensによってきっぱりと否定された。アゼルバイジャンの記者はなんとかしてAzerfonが数少ないパナマの指摘企業によって所有されていることを見つけ出そうとしていた。彼女が外部に助けを求めるまで、この試みは行き詰まりになっていた。2011年の初頭、Ismayilovaは、調査ダッシュボードを通じて、パナマに籍を置く企業はプログラマであり活動家であるDan O&#8217;Huiginnによって開発された<ulink url="http://ohuiginn.net/panama/">アプリケーション</ulink> によって追跡できることを知った。このツールを用いて、彼女は終に大統領の2人の娘がパナマに籍を置くビジネスを通じて通信企業に係わっていることを明らかにした。</simpara>
<simpara>実際には、O&#8217;Huiginnはオフショア天国として広く知られ、いくるかの不正を働く公務員によって金を隠す場所として用いられている（前エジプト大統領Hosni Mubarakの取り巻きから、南米やバルカン諸国の不正を行う公務員まで）パナマにおける汚職について報告を行うためにジャーナリストを助けるツールを作った。プログラマーかつ活動家が行ったことはWebスクレイピングと呼ばれている。調査を行うものによって使えるように、情報の抽出と再形成を可能にする手法である。O&#8217;Huiginnは <ulink url="http://www.registro-publico.gob.pa/">パナマの企業登録</ulink>をスクレイピングした、このレジストリはオープンであるにも関わらず、調査報道者が探している企業の名前を知ることを可能にしている。これは、資産の動きを追跡するために記者は一般に個人の名前を探し求めているので、調査の可能性を限定しているといえる。彼はデータを抽出して、新たなWebサイトを作成して、個人名で検索を可能にした。新たなWebサイトは多くの国の調査記者に情報を探し求めることを可能にし、政府や議会の公務員達の名前を探すことや彼らが秘密裏に企業をパナマにおいて所有しているかどうかをチェックすることを可能にする（ちょうどアゼルバイジャンの大統領家族がしたように）。</simpara>
<simpara>より良い情報へのアクセス以外にも上記に強調したガイドラインを使用する長所が存在する。一つには敵対的な環境下において働く調査記者を保護することおよび、損害を最小限に食い止める事である。これはあるネットワークにおいて働くとき、ジャーナリストは孤立しているわけではないという事実に基づく、調査報道記者は外国の多くの同僚と働いているため、犯罪者にとって彼らのさらされている悪事に責任のある人たちをさけることが難しくなる。結果として、政府や汚職を働く役人にとって報復を成し遂げる事が難しくなる。</simpara>
<simpara>もう1つ心にとどめておくべきことは、情報はある地域においてとても価値があるように見えないものが他の地域に致命的に重要であることである。調査ネットワーク間の情報の交換はとても重要なストーリーを明らかにすることを導くことができる。例えばルーマニア人がコロンビアにおいて1キログラムのコカインとともに逮捕されたという事実はおそらくボゴタにおいてはフロントニュースにはならないが、もし現地のレポーターが逮捕された人間がブカレストで政府に勤める人間であるということを見つけ出せば、ルーマニアの大衆にとってはとても重要なものになりうる</simpara>
<simpara>効率的な調査報道は調査ジャーナリスト、プログラマー、その他のよりグローバルで公平で綺麗な社会を実現するのに貢献するためにデータを使用したい人達の協力作業の結果である。</simpara>
<simpara>&mdash; <emphasis>Paul Radu, Organized Crime and Corruption Reporting Project</emphasis></simpara>
</section>
<section id="_コードとして生まれるストーリー">
<title>コードとして生まれるストーリー</title>
<simpara>OpenDataCityは2010年の終わりに設立された。同時期にドイツにおいてデータジャーナリズムと呼べるようなものは全くもってなかった。</simpara>
<simpara>なぜ私たちはこれにとりかかったの。何度となく私たちは新聞社や放送局で働く人たちから聞かされてきたことがある。それは「ダメ！私たちはニューズルームでデータジャーナリズムユニットに専念し始める準備ができてないの。でもこれを外部委託できればハッピーになれるだろうね。」ということであった。</simpara>
<simpara>私たちの知る限りでは、ドイツにおいてデータジャーナリズムを専門的かつ独占的に行っている唯一の会社です。現在、3人で活動をしていて、2人はジャーナリズムのバックグラウンドを持っていて、もう1人はコードと可視化を深く理解しているメンバーで構成されています。私たちは少人数のフリーランスハッカーやデザイナー、そしてジャーナリストと活動を共にしています。</simpara>
<simpara>12ヶ月前、我々は新聞社との4つのデータジャーナリズム·プロジェクトを請け負っていました。そこで、メディア労働者、科学者、ジャーナリズムの学校に研修とコンサルティングを提案してきました。我々が行った最初のアプリは、ベルリンで新しく空港の近くに建設されたばかりの「TAZ」であった。<ulink url="http://bit.ly/taz-airport-noise">interactive tool on airport noise</ulink> 私たちの次の注目すべきプロジェクトはZEITオンラインにおけるドイツの政治家の携帯電話の利用調査であった​​。<ulink url="http://bit.ly/zeit-telephone">application about data retention</ulink> この調査で、我々はGrimme Online Award <ulink url="http://bit.ly/grimme-award">Grimme Online Award</ulink> とドイツのLead Award、米国でのオンラインジャーナリズムアワード<ulink url="http://bit.ly/online-news-award">Online Journalism Association</ulink> を受賞しました。書いている時点で、我々はより簡単なインタラクティブなインフォグラフィックから、設計とデータジャーナリズムミドルウェアのようなものを開発するまでのパイプラインのような、複数のプロジェクトを担っている。</simpara>
<figure id="FIG0215"><title>Airport noise map (Taz.de)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-TT.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-TT.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>もちろん、賞を受賞すると、評判を積み上げることができる。賞を勝ち取るためにデータジャーナリズムへの投資をしてもらうのではないと、プロジェクトを承認しなければならないパブリッシャーと話をする。むしろそれは、持続可能な方法で長期間にわたって注目を得ることである。スクープのためではない長期間のインパクトを作り上げていく調査報道は得てして多くの場合、数日後に忘れられてしまう。</simpara>
<simpara>ここに3つの論点がある。それは長い期間をかけるプロジェクトを実施するパブリッシューを励ますことでよく使われる。</simpara>
<?dbfo-need height="1in"?>
<variablelist>
<varlistentry>
<term>
データプロジェクトはデータにあらず
</term>
<listitem>
<simpara>
  デザインによって、新たなデータはデータジャーナリズムのアプリケーションに取り込まれることができるであろう。そして、それは単にユーザーのためだけではなく、報道と分析のために内部的に使われることもあるであろう。競争相手があなたからの投資によって利益を得るかもしれないことを心配しているかもしれません。その時は、記事を守り、データは内部利用のみにしましょう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
過去に取り組んだ仕事から創造することができる
</term>
<listitem>
<simpara>
  データを用いたプロジェクトを行っている時、あなたは頻繁に再利用やアップデート可能な一部のコードを作るであろう。次のプロジェクトは半分の時間になります。なぜならば、なにをすればいいのかということを前回より熟知しているからである。そして、あなたは自分で一部を作ることができるであろう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
データジャーナリズムはそれ自身のために支払いをする
</term>
<listitem>
<simpara>
  データ駆動型プロジェクトはこれまでの伝統的なマーケティングキャンペーンより安価で済む。オンラインニュース市場は頻繁に検索エンジン最適化(SEO)や検索エンジンから自社Webサイトへの訪問者を増やすマーケティング手法であるサーチエンジンマーケティング(SEM)のようなものに投資する。実際に行なわれるデータプロジェクトでは普通、多くのクリックやバズが生まれるので、バイラル化しがちである。パブリッシューはクリック数やSEMを介したリンク作りによって同程度のアテンションを引こうとしているが、典型的にバイラル化することに注意を払うことを怠っている。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>私たちの仕事は他の新しいメディア企業と特段違うことをしている訳ではない。ニュース市場にアプリケーションやサービスを提供しているにすぎない。ただ、私たちと他との違いをあげるとすると、それは私たちが、ジャーナリストとして、何よりもまず、自分自身について考えていることである。私たちの目には、私たちが提供する製品とは、コードで提供される記事やストーリーである。この記事やストーリーはこれまで伝えるために必要であった言葉や写真、音声またはビデオではなく、コードで構成されているのである。私たちがデータジャーナリズムについて話す時、私たちはテクノロジー、ソフトウェア、デバイス(デジタル機器)、そしてそれらによってどのようにしてストーリーを描くのかということを同時に語らねばならない。</simpara>
<simpara>例をあげると、私たちはちょうどアプリケーション作成の仕事を終えたところであった。そのアプリケーションはドイツの鉄道サイトからリアルタイムデータをスクレイピングして引き出すものであった。<ulink url="http://zugmonitor.sueddeutsche.de/">Train Monitor for Süddeutsche Zeitung</ulink>, このように対話的に開発することが可能になり、長距離電車の遅延情報をリアルタイムに見せることができるようになった。このアプリケーションデータは1分ごとにアップデートされ、そのためのAPIを提供している。私たちは数ヶ月前にこれを開始し、これまで毎時間ごとに増幅していく巨大なデータセットを収集した。今では、数百から数千のデータ列になっている。このプロジェクトによってユーザーはリアルタイムデータを検索することができるようになり、数ヶ月間のアーカイブを調査することも可能になった。最後に、私たちが描いているストーリーはユーザーの個々の活動によって顕著なほど明確になってきた。</simpara>
<simpara>伝統的なジャーナリズムでは、紙や放送メディアの特徴が原因で、我々は最初、終わり、ストーリーアーク、私たちのピースの長さと角度を考える必要があります。データジャーナリズムとこれまでのジャーナリズムには違いがある。始まりがある。人々はウェブサイトに訪問し、インターフェイスの直感を得る。しかし、彼らは彼ら自身である。おそらく、彼らは1分間の滞在かもしれないし、30分かもしれない。</simpara>
<?dbfo-need height="1in"?>
<simpara>データジャーナリストとしての私たちの仕事はフレームワークの提供とデータジャーナリズムのための環境提供である。コーディングや一部のデータマネジメントはもちろん、経験を設計するクレバーな方法を考える必要がある。ユーザー体験(UX)は主にグラフィカルユーザーインターフェイス(GUI)から得られる。最後に、これは作るか中断するか決断する箇所である。刺激的なデータセットを扱っているバックグラウンドの中で最高のコードは活躍する。しかし、フロント部分がダメであると、バックグラウンドで素晴らしいコードが動いていることなど誰も気にしないのである。</simpara>
<simpara>まだ経験の中で学ばなければいけないことがある。しかし、幸運なことに、ゲーム産業が存在する。ゲーム産業は数十年にわたるデジタル物語、生態系、およびインタフェースに関して革新されている。データジャーナリズムのアプリケーションが発展した時、私たちは密接にどのようにゲームデザインの作品とどのようにストーリーがゲームで語られているのか注視する必要がある。</simpara>
<simpara>私たちは今一度ここでデータジャーナリズムに関して考えるところにきている。数年間で、データジャーナリズムのワークフローはごく自然にニューズルームの中へと組み込まれるだろう。なぜならば、ニュースウェブサイトは変わらねばならないからである。公的に利用可能なデータの総計は増え続けるだろう。しかし、幸運なことに、新たなテクノロジーはストーリーを描くための新たな方法を見つけることを可能にしてくれ続けるだろう。それらのストーリーには、データによって書かれるもので、多くのアプリケーションやサービスはジャーナリスティックな特性を帯びてくるだろう。興味深い質問がある。それは、どのような戦略がニューズルームのこれらのプロセスが促進することを発展させるのだろうかというものだ。チームを作るのか、はたまたデータジャーナリストを既存のニューズルームに組み込むのか。R&amp;D部門のような存在にするのか、会社所属のスタートアップのようなものにするのか。もしくは外部企業に一部を委託するのか。私たちは未だに始まりにいるので、時間のみがその疑問に答えてくれるだろう。</simpara>
<simpara>&mdash; <emphasis>Lorenz Matzat, OpenDataCity</emphasis></simpara>
</section>
<section id="_kaas_amp_mulvad_semi_finished_content_for_stakeholder_groups">
<title>Kaas &amp; Mulvad: Semi-Finished Content for Stakeholder Groups</title>
<simpara>ステークホルダーのメディアは、主に、潜在的に、オンラインネットワークを介してか、ニュースメディアにコンテンツを提供することで、多大な影響を与える可能性を持ち、メディア理論家によってたいてい見過ごされる新興分野である。これは、特定の興味やコミュニティを前進させるために使用されている組織や制度上の利害関係者によってコントロールされるメディア（通常はオンライン）として定義することができる。消費者団体、専門団体、労働組合などを行うNGOは、概してそのようなメディアをつくるものだ。世論や他の利害関係者に影響を与える能力に重要な制限は、小型化のニュースメディアよりも、重要な情報の発見に取りかかる能力を欠いていることが多い。非営利デンマークの企業のカース＆ムルバドは、これらの利害関係者の市場に専門的能力を提供する最初の調査メディア企業の一つです。</simpara>
<simpara>同社はコンピュータ支援レポーティングのための非営利デンマーク研究所（ジカルボン）のスピンオフとして2007年に始まり、データ分析の訓練を受けたメディアやジャーナリストに調査報告書を販売した。その創設者、トミー·カースとニルスMulvadは、以前は、ニュース業界の記者だった。彼らの新会社は、``データとジャーナリズム<emphasis>'（未完成で更に編集か書き換えが必要だ）をニュースリリースかストーリに完成させ、ニュースメディアと彼ら自身の販路（例えばウェブサイトなど）に配信するステークホルダーメディアにたいてい配布している。直接のクライアントは、政府機関、PR会社、労働組合、およびこのようなEUの透明性と世界自然保護基金などのNGOが含まれる。NGOの仕事は監視ファームと漁業補助金、および関連ウェブサイトの``きれはし</emphasis>'を通じて生成されたEUのロビイスト活動の定期的な更新が含まれている。間接的なクライアントは、NGOのプロジェクトに出資する財団を含む。同社はまた、例えば有名人のモニタリングサービスを購入したタブロイド新聞、といったようなニュース産業とも一緒に活動している。</simpara>
<figure id="FIG0216"><title>Stakeholder media companies (Fagblaget3F)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/02-MM.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/02-MM.png</phrase></textobject>
</mediaobject>
</figure>
<?dbfo-need height="1in"?>
<simpara>彼らのポートフォリオを含むデータジャーナリズムプロジェクト:</simpara>
<variablelist>
<varlistentry>
<term>
<ulink url="http://bit.ly/3F-unemployment">Unemployment Map for 3F</ulink>
</term>
<listitem>
<simpara>
  デンマークの未熟練労働組合である3Fのために行われたデンマークの失業率に関する重要な数値とデータの可視化。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://bit.ly/3F-living">Living Conditions for 3F</ulink>
</term>
<listitem>
<simpara>
  3Fのための別のプロジェクトは、デンマークの異なる各地域によって生活条件がどのように異なるのかを示したものである。マップは24種類の指標を使用している。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://bit.ly/3F-debt-index">Debt for &#8220;Ugebrevet A4&#8221;</ulink>
</term>
<listitem>
<simpara>
  これは、&#8216;`債務指数&#8217;'を計算し、民間経済の違いを可視化するプロジェクトだ。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://bit.ly/3F-dangerous-facilities">Dangerous Facilities in Denmark</ulink>
</term>
<listitem>
<simpara>
  このプロジェクトは、幼稚園や他の保育機関との危険な施設の近接性を地図表示し分析するプロジェクトで、幼児と青少年教育のデンマーク連合、BUPLによって出版された「Børn&amp;Unge」のために請け負った。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://data.vestas.com">Corporate Responsibility Data for Vestas</ulink>
</term>
<listitem>
<simpara>
  自動生成されたテキストを持つデンマークの風力タービン企業ヴェスタスのための、データ可視化した5エリアのCRデータ。世界規模のデータからシングルプロダクションユニットまで400ウェブページ、四半期ごとに自動的に更新されています。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://xpoint.experian.dk/navnekort">Name Map for Experian</ulink>
</term>
<listitem>
<simpara>
  あなたの姓を入力し、デンマークの異なる地理的領域の周囲に、その名前の分布を見てみよう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://ekstrabladet.dk/kup/fodevarer">Smiley Map for Ekstra Bladet</ulink>
</term>
<listitem>
<simpara>
  毎日カース＆Mulvadはすべての悪い食品検査を抽出し、デンマークのタブロイド、エクストラ·ブラデットが（ウェブサイトの中ほどの地図を参照）のすべての最新情報をマップします。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>カース＆Mulvadはステークホルダーメディアと連携した最初のジャーナリストではない。グリーンピースは、例えば、定期的にそのレポートのための協力者として、ジャーナリストを雇っています。しかし、我々が知っているステークホルーダーメディアに依頼している他にはない会社が、データドリブンであり、ジャーナリストが記者、編集者、あるいは作家としてのNGOと連携することがはるかに一般的だ。コンピュータ支援ニュースメディアの現在の焦点は、検索と発見（ウィキリークスを考える）だ。ここで再び、カース＆ムルバドは、データ分析に焦点を当て革新する。彼らのアプローチは、プログラミングのスキルだけでなく、インパクトのあるストーリーを作ることができる情報の種類を理解することも求められている。彼らのサービスを模倣しようとする誰もが、おそらく個々はほとんど両方持っていないため、この2つのスキルをパートナーシップを通じて設定し取得しなければならないと問題なくいうことができる。</simpara>
<section id="_プロセス_itと分析の革新性">
<title>プロセス:　ITと分析の革新性</title>
<simpara>同社は、数時間から数ヶ月の期間に至る、年間約100のプロジェクトを行っています。また、継続的にその能力と雇用拡大プロジェクトに投資しています。有名人の監視サービスは、1つのそのような実験であった。またもう一つは、自宅の差し押さえのネットニュースを集め、またこのイベントのマップの作成に関与した。パートナーたちは、彼らの最初の基準は、そこから学びまた仕事を楽しむかどうかが重要であると言う。新しいサービスが定義された後、市場が求められている。彼らはそれを明確に報道業界では、彼らはそれが困難な新しい方法と新しいビジネスを開発するために見つけたことを確認します。ニュース業界の中で、彼らがあ新しいビジネスや方法を開発するのは難しいと彼らも考えておる。</simpara>
<simpara>ムルバドは以下のようにコメントしている:</simpara>
<blockquote>
<simpara>我々は、私たちができるプロジェクトを決意したり、買う事ができるソフトやハードウェアを決定したりする編集者や上司を持っていない。我々は、テキストのクリッピングやマイニングのためのベストソリューションのようなプロジェクトニーズのために、それらのツールを買う事ができる。私たちの目標は、これらの分野で最先端であることだ。我々は支払うことを喜んでいる顧客を得ようとするか、もしくはプロジェクトが楽しみである場合、我々はより低い料金のためにそれを行う。</simpara>
</blockquote>
</section>
<section id="_value_created_personal_and_firm_brands_and_revenue">
<title>Value Created: Personal and Firm Brands and Revenue</title>
<simpara>2009年の売上高は約250万デンマーククローネ、€336,000だった。また、ジャーナリストたちへの教育や会話サービスを要求し続ける鋭いジャーナリストを分断する事によって、パートナーの評判を維持した。彼らの公の体裁は順次に会社のブランドをサポートしている。</simpara>
</section>
<section id="_key_insights_of_this_example">
<title>Key Insights of This Example</title>
<itemizedlist>
<listitem>
<simpara>
報道業界の体力減少の危機はまた、体力の未活用の危機でもある。カースとムルバドは彼らが評価された作業を行うために、ニュース業界を残し、また支払っている。何も、その価値の占領から報道機関を防いではいない。
</simpara>
</listitem>
<listitem>
<simpara>
少なくともいくつかの市場では、利害関係者グループの利益を提供することができる&#8216;`半完成&#8217;'コンテンツのための収益性の高い市場が存在する。
</simpara>
</listitem>
<listitem>
<simpara>
しかしながらこの機会は、どのくらいジャーナリストが彼らの仕事のプレゼンテーションに影響を及ぼす事ができ、第三者によって彼等の仕事に利用する事ができるかの問題を引き起こす。私たちは、この問題はすでに（編集者がジャーナリストの製品に変更を課すことができる場所）、ニュース業界内で存在することを思い出して、それがこのような映画産業のような既にディレクターとスタジオ間の“最終カット”での衝突が他のメディア産業はほとんどまれである。それは、ステークホルダーメディアの特定のモラルハザードではないが、消えることはないし、更なる注意がこの成長している現実と市場の倫理に必要とされている。
</simpara>
</listitem>
<listitem>
<simpara>
収益の観点からは、単一の製品またはサービスが十分ではありません。成功したウォッチドッグ·企業は、ポートフォリオ·アプローチを採用したコンサルティング、教育、スピーキング、およびその他のサービスは、余分な収入をもたらすとウォッチドッグ·ブランドをサポートするために、より良いを行うだろう。
</simpara>
</listitem>
</itemizedlist>
<simpara>&mdash; <emphasis>Mark Lee Hunter と Luk N. Van Wassenhove による &#8216;`ニュース技術の黒船：ステークホルダーメディアと未来の番人ジャーナリズムビジネスモデル&#8217;'（INSEADワーキングペーパー、2010 ）から抜粋し編集</emphasis></simpara>
</section>
</section>
<section id="_データジャーナリズムのためのビジネスモデル">
<title>データジャーナリズムのためのビジネスモデル</title>
<simpara>データ駆動型のジャーナリズムに関するすべての関心と期待の真っ只中、ニューズルームは常に「どんなビジネスモデルでやっていくのか？」という疑問を知りたがっていた。</simpara>
<simpara>我々は予測をすることに関して十分注意を払わなければならないと同時に、最近の歴史を見て、現在のメディア産業状態はいくつかの見識をデータジャーナリズムのビジネスモデルにもたらすことができる。今日、多くのニュース機関は新たなアプローチ方法を採用することで利益を得ている。</simpara>
<simpara>「データジャーナリズム」と呼ばれるようなものや最新のバズワードである「データサイエンス」はある新しい事物を描写するようである。しかし厳密に言えば正しくない。代わりに、それらの新たな「ワード」は数十年にわたって強みを増している変化を特徴付けるだけの方法なのである。</simpara>
<simpara>多くのジャーナリストたちはデータ集積やデータ分析、データ可視化を既に生み出していた収益の規模知らないであろう。これは洗練された情報のビジネスである。データツールとテクノロジーを用いることで、それは高度複雑化した問題、例えば国際財政、債務、人口統計学、教育などに向けて希望の光を放つ可能性が上昇している。「ビジネスインテリジェンス」と呼ばれるものは、営利企業の内で今何が起きているかの視野を明確に提供する目的があるITのコンセプトの価値を説明している。マクドナルド、Zara、H&amp;Mを含む、巨大で儲けの多い企業における我々の時間は、コンスタントにデータ追跡をし、利益に還元させることに費やしている。そしてその費やしたことはそれら企業に対してとても見事に機能している。</simpara>
<simpara>現在なにが変化しているか？という問いの答えは、この空間のために発展したツールがメディアを含む他の分野にも使用可能になっているということである。また加えてツールを使うことのできるジャーナリストがいる。タブローを使おうじゃないか！タブローは企業が提供している可視化ツールとしてふさわしいものである。あるいは「ビッグデータ」ムーブメント、つまりはデータの山を掘り出すことや識見を瞬時に解凍するためのソフトウェアパッケージ(たいていオープンソースである)をテクノロジー企業は使っている。</simpara>
<simpara>それらの技術は現在ジャーナリズムに応用させることができる。ガーディアンやニューヨークタイムズのチームはコンスタントにこの手の新興分野を押し進めている。そして今我々が見ているものは氷山の一角にすぎない。</simpara>
<simpara>しかしどのようにしてこの手法はジャーナリズムにお金を生み出すのだろうか？現在開放されている巨大な世界的な市場は我々が処理することができる公的に利用可能なデータの変化についてのすべてであり、つまりは、データを可視化し、人間的にするのである。我々が日々ニュースの中で聞く大量の数のことを我々は関連付けたがっている。それは数百万や数十億のことが我々のこととして意味するのである。</simpara>
<simpara>とても有益なデータ駆動型メディア企業があり、その企業の人たちは他の企業より素早くこの仕組みを簡潔に応用している。彼らは健全な成長と素晴らしい利益に恵まれている。1つの例としてブルームバーグがあげられる。ブルームバーグは約300,000(30万)の端末が働き、ユーザーに財務データを届けている。もしあなたがお金に関する仕事をしていたら、これはとても役に立つツールになるでしょう。それぞれの端末には色がコード化されたキーボードがあり、30,000(3万)にものぼるオプションを調べたり、比較したり、分析したり、次に自分がなにをするのかを決めるのに役立ったりする。このコアビジネスは推定年間6,3ビリオン(63億)ドルを生み出し、少なくともその一部が2008年ニューヨークタイムズによって評価された。<ulink url="http://nyti.ms/IQcRgY">a 2008 piece by The New York Times</ulink>. 結果として、ブルームバーグは左派、右派、中道派のジャーナリストを雇い続けていて、彼らは尊敬の念を信じたのであった。しかし「ビジネスウィーク」などが赤字になってしまった。</simpara>
<simpara>もうひとつの理由はカナダのメディア複合企業として今日知られているトムソン・ロイターである。彼らはひとつの新聞からスタートし、イギリスで著名な権利を買収し、20年後新聞業界から退くことを決めた。代わりに、彼らは情報サービスを基礎に育て上げた、それには多くの産業での顧客のより深い視点を提供する目的があった。もしあなたが特別な情報を用いて稼ぐ方法に関して心配しているのであるなら、アドバイスはウィキペディアで会社の歴史を読んでみてほしい。<ulink url="http://en.wikipedia.org/wiki/The_Thomson_Corporation">read about the company&#8217;s history on Wikipedia</ulink>.</simpara>
<simpara>エコノミストを見てみよう。エコノミストは素晴らしいものを築き上げ、メディアサイドに大きな影響を及ぼして刻み込んだ。同じ頃「エコノミストインテリジェンスユニット」は今よりコンサルタントのような仕事で、関連ある流行やほぼ世界中の動向予測に関することをレポーティングしていた。彼らは数百人のジャーナリストを雇い、世界中約1.5ミリオン(150万)人もの顧客が支えてくれていることを主張した。</simpara>
<simpara>また、インスピレーションを与えてくれるような役に立つ多くのニッチなデータ駆動サービスがある。例えばそれはアメリカの「eMarketer」で、比較提供を行ったり、インターネット市場に興味がある人に対してチャートを作ったり、アドバイスをしたりしている。ドイツのStiftung Warentestは製品の品質とサービスを研究している。もうひとつドイツから、Statista社は公的に利用可能な情報の可視化のスタートアップとして役に立っている。</simpara>
<simpara>世界中この手の分野に現在スタートアップの波があり、自然と幅広い分野をカバーしている。例えば、Timetricは「再生ビジネス調査」を目的にしていて、OpenCorporates、Kasabi、Infochimps、Data Marketも同様のサービスを提供している。それらの多くはおそらく実験的であるが、しかし一緒になり、それらは変化の重要な兆候であるとされている。</simpara>
<simpara>その時には公的なメディアもあり、それはデータ駆動型ジャーナリズムと呼ばれるもので眠れる巨人である。ドイツで年間7.2ビリオン(72億)ユーロもの額がこの分野に投資されている。ジャーナリズムは特別な製品であり、つまり、もしうまく運営して、利益を上げることはなくとも、重要な役割を社会においてになっているのである。一度でもデータジャーナリズムがより良い報道ができることが明確であれば、より信頼できる見識がより簡単になり、このお金はニューズルームで新たな仕事へ使われることができたであろう。</simpara>
<simpara>データジャーナリズムを用いることが始まりなのではなく、信頼されている情報源足り得ることが本来の目的である。この多チャンネルな世界で、注目されるものは大量に生み出されるが、信頼性はますます希少資源になっている。データジャーナリストは校合することや統合することへの助けになる。現在の多様かつしばしば違った情報源はある意味で、聴衆の本当の洞察を複雑化した問題の中にもたらすであろう。むしろ、どこかよそで聞かれた、ただ使い回されるプレスリリースやストーリーの書き直しにすぎなく、データジャーナリストは読み手に対して鮮明かつ包括的でなるべくカスタマイズできる対話型グラフィックスを用いた視点と元のソースへのダイレクトアクセスを提供することができる。それは些細な事ではなく、確かに価値あることなのだ。</simpara>
<simpara>ではこの分野を探求し、革新的なプロジェクトを支援するための管理を納得させる意欲的なデータジャーナリストのための最善のアプローチはなんだろうか？</simpara>
<?dbfo-need height="1in"?>
<simpara>最初の一歩はすぐに身近な機会を探すべきである、つまり、それは簡単に成果が出るものである。例えば、構築されたテキストと利用可能なデータの集積をあなたは既に持っているであろう。ロサンゼルスタイムズの「殺人データセット」がこれの主な例である。ここのデータとビジュアライゼーションは核になっていて、補足ではない。編集者たちはすべての犯罪を収集し、発見して、その時初めて、彼らはこれらをベースにして記事を書くのである。それらの集積は時間を重ねることでより良く、より深く、より価値あるものになっている。</simpara>
<simpara>初めはうまくいかないだろう。しかし時間を重ねるのだ。テキサストリビューンとプロパブリカはここのとても希望に満ちたインディケーターであり、そしてどちらの企業もおそらく次世代の出版メディア会社であり、彼ら非営利ジャーナリズム団体のための資金は予定よりかなり早い時期に目標を超えたことを報告している。</simpara>
<simpara>すべてのもののデータを熟練したら、ジェネラリストであろうと食物連鎖データをフォーカスしたスペシャリストでなかろうと、ジャーナリズムを信頼しれくれる人々に価値ある視点を提供するのである。あるドイツでよく知られている発行者が最近インタビューで「彼らをデータジャーナリストと呼ぶ新たなグループがある。そしてもはや彼らは僅かな賃金で働くことをしないのである」と語った。</simpara>
<simpara>&mdash; <emphasis>ミルコ・ローレンツ, ドイチェ・ヴェレ</emphasis></simpara>
</section>
</section>
<section id="_ケーススタディ">
<title>ケーススタディ</title>
<informalfigure role="informal">
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-00-cover.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-00-cover.png</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>このセクションでは、さまざまなデータジャーナリズムプロジェクトの舞台裏を、一日で開発されるアプリケーションから9ヶ月にわたる調査まで、もっと詳しく見てみよう。選挙から支出まで、暴動から汚職まで、学校の能力から水の値段まで、すべてに対してカバレッジを拡大、改善するために、データソースがどのように使われてきたか学ぶのだ。ここではBBC、Chicago Tribune、Guardian、Financial Times、Helsingin Sanomat、La Nación、Wall Street Journal、Zeit Onlineといった大きなメディア組織からも、California Watch、<phrase role='keep-together'>Hack/Hackers</phrase>Buenos Aires、Propublica、そしてブラジルの市民ジャーナリストグループFriends of Januáriaのような比較的小さな団体からも学んでいく。</simpara>
<section id="_the_opportunity_gap">
<title>The Opportunity Gap</title>
<simpara><ulink url="http://projects.propublica.org/schools">The Opportunity Gap</ulink>（機会格差）は、それまで公開されたことがなかった合衆国教育省の公民権データを使い、フロリダのように機会均等を進めて富裕層と貧困層の学生にほとんど同等の高等教育アクセスを提供する州もあれば、カンザス、メリーランド、オクラホマのように貧困家庭の多い地区で機会が少ない州もあることを示したウエブサイトだ。</simpara>
<figure id="FIG031"><title>The Opportunity Gap project (ProPublica)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-YY.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-YY.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>データは3000人以上の学生がいる地区の全公立校をカバーしている。公立校の全学生のうち3/4以上が代表されることになる。データは我々のレポーターの一人が入手し、コンピュータ支援取材（CAR/Computer Assisted Reporting）ディレクターが非常に広範にクリーンアップしたものだ。</simpara>
<simpara>およそ3ヶ月というプロジェクトだった。ストーリーとニュースアプリケーションに取り組んだのは全部で6名。エディター2名、レポーター1名、コンピュータ支援取材者1名、そして2名の開発者だ。ただしこの期間を通じてかかりきりだった者はほとんど居ない。</simpara>
<simpara>プロジェクトでは、我々のスキルが総合的に必要だった---分野の深い知識、データの扱い方の理解、デザインとコーディングのスキル、その他もろもろだ。さらに重要なのは、データの中にストーリーを見つける能力が要求されることだ。また、語られるストーリーだけでなくニュースアプリケーションそのものに対しても、編集の能力が必要だった。</simpara>
<simpara>データのクリーニングと分析には主としてExcelおよびクリーニング用スクリプト群と、MS Accessも使った。ニュースアプリケーションはRuby on Railsで書いて、JavaScriptをかなり広範に使った。</simpara>
<simpara>全体のストーリーに加えてカバレッジに含めた対話型ニュースアプリケーションは、読者が自分たちに関わるこの国家的巨大データセットの中で、実例を見出し理解するためのものだ。読者は地元の学校を---たとえば<ulink url="http://goo.gl/HJVCf">Central High School in Newark, N.J.</ulink>&mdash;など---を見つけ、さまざまな分野でどの程度の状態にあるか、すぐ見ることができる。続いて <ulink url="http://goo.gl/WrAIi">"Compare to High and Low Poverty Schools"</ulink>（高貧困校や低貧困校との比較）"というボタンを押せば、他の高校について相対貧困度、上級の数学やAP（Advanced Placement、大学で単位換算される高度な授業）など、重要なコースをどの程度提供しているかが、すぐに表示される。たとえば上のCentral Highには横並びでMillburn Sr. Highの情報が表示される。Millburnではランチが無料または割引になる生徒は1%だけだが、その72％はAP科目を取っていると出る。反対のカラムに表示されるInternational Highでは85％の生徒が無料/割引ランチを得ており、AP科目を取るのは1%にすぎない。</simpara>
<simpara>これを使うことで、読者は知っていること---地元の高校---から知らないこと--教育機会の分布の様子と、それを示す指標として貧困度がどのくらい使えるのか--を理解できるのだ。</simpara>
<simpara>アプリケーションはFacebookとも統合してあるので、Facebookにログインして使えば、興味があるであろう学校を自動的に通知するようになっている。</simpara>
<simpara>ニュースアプリケーション全体へのトラフィックは目覚しいものがあるが、我々が特に誇らしいのは、このアプリケーションが複雑なストーリーを語っている手法だ---そしてこれが、読者に自分のストーリーを語らせる助けになることだ。</simpara>
<simpara>政府データから始めるプロジェクトの常として、データにはかなりの掃除が必要だった。たとえばAP科目のクラスは30程度しかありえないのに、一部の学校は数百を報告していた。だから手作業でチェックしたり、電話で学校に確認、訂正する作業が非常にたくさん必要だった。</simpara>
<simpara>「遠い」ストーリーと「近い」ストーリーを両方ちゃんと語るアプリケーションにするということにも、本気で取り組んだ。つまり、読者に広く抽象的な国全体の様子を提示する、特に教育機会についての各州の行いを相対比較する方法によりそれをすることは必要であるが、こうした抽象化がデータの意味するところを不明瞭にしがちなので、地元の学校を見つけて地域の高貧困・低貧困校と比較できるようにもしたかった、ということだ。</simpara>
<simpara>この種のプロジェクトに取り組みたいデータジャーナリスト志望者にアドバイスするとすれば、自分の材料をよく知り、かつ探究的になれ！と言うところだ。他の種類のジャーナリズムに適用されるルールはここにもすべて適用される。個々のファクトはどれも正しいものでなければならず、ストーリーがちゃんと語られていなければならない。そして--特に--注意すべきは、アプリケーションがストーリーに反したものになっていないかということだ。もし反していたら、どちらかが間違っているということであるから。</simpara>
<simpara>また、コーディングを学びたいと思うなら、一番重要なのは始めることである。授業や本や動画で学びたいと思っているかもしれないが---そしてどれについても非常に優れた教材があるがプロジェクトにまつわる本当に良いアイディアと完成までの締切を必ず持っていること。ニュースアプリケーションでなければうまく表現できないストーリーが頭にあるなら、いまプログラミングを知らないことは障害にならないのだ！</simpara>
<simpara>&mdash; <emphasis>Scott Klein, ProPublica</emphasis></simpara>
</section>
<section id="_欧州構造基金に対する九ヶ月の分析">
<title>欧州構造基金に対する九ヶ月の分析</title>
<simpara>2010年、<ulink url="http://www.ft.com/intl/eu-funds">Financial Times</ulink>と<ulink url="http://bit.ly/bureau-billions">Bureau of Investigative Journalism (BIJ / 分析ジャーナリズム事務局)</ulink>は、EU構成ファンドの分析で力を合わせることにした。ファンドの受益者は誰であるかをレビューして、資金が良いことに使われているかチェックするという意図があった。構造基金は7年以上で3470億ユーロ、EUで2番目に大きい助成プログラムである。プログラム自体は何十年も存在したが、大まかで一般的な総覧を除けば、誰が受益者かについて透明性がほとんど無かった。現行の資金提供ラウンドで規則の一部が変わったため、関係当局は受益者のリストをおおやけにする義務が生じた。このリストにはプロジェクトについての記載とEUおよび国から受け取った支援金額を含む必要があるのだ。</simpara>
<figure id="FIG032"><title>EU構造基金分析 (Financial Times と The Bureau of Investigative Journalism)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-OO-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-OO-01.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>プロジェクトチームはジャーナリスト12人とフルタイムのコーダー1人が9ヶ月間協働するというものだった。データ収集だけでも数ヶ月かかった。</simpara>
<simpara>プロジェクトの成果はフィナンシャル・タイムズとBIJで5日間取り上げられ、BBCラジオドキュメンタリーや複数のテレビドキュメンタリーにもなった。</simpara>
<simpara>これほどのレベルの努力を要求するプロジェクトに取り組むには、発見がオリジナルなものになること、独自の優れたストーリーにたどり着くことを確信していなければならない。</simpara>
<simpara>作業は独立したステップとして分割した:</simpara>
<section id="_1_データの保持者と保持方法を確認する">
<title>1. データの保持者と保持方法を確認する</title>
<simpara>欧州委員会の地域政策総局はデータをパブリッシュする各地区当局のサイトへの<ulink url="http://bit.ly/ec-portal">ポータルサイト</ulink>を持つ。欧州委員会はプロジェクトデータのデータベースを持っているはずで、直接アクセスできるか情報公開法に基づく請求で入手できるものと我々は信じていた。そのようなデータベースは、必要な詳細さのものは、存在しなかった。そして欧州委員会が出しているリンクは多くがちゃんとしたものでないこと、出している当局のほとんどが、データ形式として分析フレンドリーなCSVやXMLでなく、PDFで公表していることもすぐに判明した。</simpara>
<simpara>最新のデータを見つけ、共同作業用の巨大スプレッドシートのリンクを確認する作業に、最大で12人のメンバーがチームで取り組んだ。データフィールドの形式も統一されていなかったので（たとえばヘッダには様々な言語が使われていたし、違う通貨が使われていたり、EUと国家助成の内訳のあるデータセットもあった）、翻訳や変換、各データセットで使えるデータフィールドの記述により、可能な限り明確にしていく必要があった。</simpara>
</section>
<section id="_2_データのダウンロードと下準備">
<title>2. データのダウンロードと下準備</title>
<simpara>次のステップはダウンロードで、すべてのスプレッドシート、PDF、場合によってはオリジナルデータのスクレーピングをおこなった。</simpara>
<simpara>それからすべてのデータセットを標準化した。全作業で最大のタスクが、ときに数百ページにもなるPDFから、データを抽出することだった。この作業のほとんどは、データを抽出してCSVやExcel形式に変換するUnPDFとABBYY FineReaderを使って行った。</simpara>
<simpara>これにはさらに、PDF抽出ツールがデータを正しく取っているかのチェック、そしてダブルチェックがともなった。これにはフィルタ、並び替え、集計をおこなうツール群を使った（PDFに表示されているものと突き合わせるのだ）。</simpara>
</section>
<section id="_3_データベースの作成">
<title>3. データベースの作成</title>
<simpara>チームのコーダーがSQLデータベースをセットアップした。下処理したそれぞれのファイルを、SQLデータベースの構成要素として使うのだ。1日1度の処理として、個々のデータファイルを全部アップロードして単一の巨大SQLデータベースにまとめるというものがあった。フロントエンドからのクエリーを実際に受け付けられるようなデータベースである。</simpara>
</section>
<section id="_4_ダブルチェックと分析">
<title>4. ダブルチェックと分析</title>
<simpara>チームは主として以下の2つの方法でデータを分析した:</simpara>
<variablelist>
<varlistentry>
<term>
データベースフロントエンドを通じて
</term>
<listitem>
<simpara>
  これは調べたいキーワードを実際に入力することによる（サーチエンジンに「タバコ」「ホテル」「A社」などと入れるということ。データベースの検索機能にプラグインしたGoogle Translateによってこれらのキーワードは21ヶ国語に翻訳され、適切な結果が返る。これはダウンロード可能で、レポーターは興味のあるプロジェクトそれぞれについて、さらに調べることができる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
データベース全体を使ったマクロ分析により
</term>
<listitem>
<simpara>
  ときにはデータセット全体をダウンロードして、キーワードを使ったり、国ごと、地域ごと、支出の種類ごと、受益者のプロジェクト数ごとのデータをまとめるような分析をおこなうことがあった。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>ストーリーはこの両方の分析手法で筋を作ったが、実地や机上でのリサーチにもよっていた。</simpara>
<simpara>データの一貫性を（各当局の声明を集計してこれと突き合わせることで）ダブルチェックするには相当な時間がかかった。主として問題だったのは、各当局がほとんどの場合に「EUおよび国家による助成」の総額しか漏らさないことだ。EUの法制下では、各プログラムは総費用に対して所定のパーセンテージでEU助成を利用できる。EU助成のレベルは、いわゆる共同出資率を見ることで、プログラムレベルで確定できる。各プログラム（たとえば地域競争力強化プログラムなど）は複数のプロジェクトで構成されている。プロジェクトレベルで言えば、あるプログラムのあるプロジェクトは100％の助成を受け、別のプロジェクトは0%ということもテクニカルにはあり得るため、プログラムレベルのEU助成額とは認定されている共同出資率以上のものではない。</simpara>
<simpara>このことは、ストーリーで問題にする受益企業のEU助成額は個々にチェックする必要があるということを意味している。</simpara>
<simpara>&mdash; <emphasis>Cynthia O&#8217;Murchu, Financial Times</emphasis></simpara>
</section>
</section>
<section id="_フィンランド議会選挙と運動資金">
<title>フィンランド議会選挙と運動資金</title>
<simpara>我々は <ulink url="http://on.wsj.com/tYM82O">covering the Eurozone meltdown</ulink> ユーロ圏崩壊をカバーしている。あらゆる詳細まで。これは政府間の衝突とセーフティネットの消失、世界中の指導者からの反応、緊縮策とそれに対する抗議といったドラマだ。ウオールストリートジャーナルには失われた雇用、低下するGDP、金利、世界市場の冷え込みのチャートが毎日載っている。それは増大していく。麻痺の感覚をもたらす。</simpara>
<simpara>Page Oneのエディターたちは年末特集のアイディアを話し合うミーティングを開いたが、その終わり頃には疑問が出てきた。この状況の中を生きていくということは、どんな感じになるだろうか。</simpara>
<simpara>自分がレイオフされて暗いニュースが降り注いでいた2008年みたいなものだろうか。毎日夕飯の席で仕事やお金のことを話しあい、娘がどれほど心配しているかもほとんど気付かないほどだった。週末が最悪だった。首の後ろを掴まれたままのような感覚と胸を締め付けられるような不安を感じることを拒否しようと頑張った。いまギリシャの一家族であることは、どのような感じだろうか。スペインでは？</simpara>
<simpara>私は踵を返し、Page Oneの編集長Mike Allenの後を追って彼のオフィスに入り、この危機をユーロ圏の家族を通して語るというアイディアを売り込んだ。第一にデータに着目し、人口統計的なプロフィールを見て家族の構成を理解し、表面には写真、インタビュー、世代をあらわす音声を散りばめる。使うのは美しい人物描写と声---そしてデータだ。</simpara>
<simpara>デスクに戻った私は、概要とロゴをかきはじめた。</simpara>
<figure id="FIG033"><title>図29. The Eurozone Meltdownの概要（Wall Street Journal）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-ZZ-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-ZZ-01.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>続く三週間は数字を追った。結婚、死亡、家族規模、健康支出といった値である。生活様態と離婚率について読み、幸福度と貯蓄率に関する調査を見た。そして家族まわりの調査にキャリアを捧げた経済学者が見つかるまで各国の統計当局をブラウズしたり、UN population bureau, the IMF, Eurostat and the OECDに電話をかけ続けた。彼は家族構成の学者を紹介してくれた。そして彼女がこのトピックのさまざまな白書を教えてくれた。</simpara>
<simpara>対象国は私の担当編集者Sam Enriquezと一緒に絞った。我々はチームを招集し、ビジュアルなアプローチについて、誰がインタビューを、音声を、ストーリーを届けるかについて話しあった。Page Oneの写真編集者Matt Craigが撮影者を手配した。国際議員担当編集者Matt Murrayは報告者自身による補助を求める手紙をあちこちの当局の長に送付した。（これは重要なものだった。トップからのお墨付きというやつだから。）</simpara>
<simpara>とはいえ、第一にはデータだ。午前中はデータをエクスポートしてスプレッドシートに取り込み、トレンドを眺めるべくチャートを描いた。貯蓄は減り、年金は消え、母親たちは仕事に戻り、保健支出は政府負債や失業に歩調を合わせて上がっていった。午後はこうしたデータをまとめた状態で眺め、各国を並べてストーリーを見出そうとした。</simpara>
<simpara>雑草の中で迷子になるまでこれを一週間続けてから、自分を疑い始めた。これは間違ったアプローチではないのか。国についてのストーリーではなく、父親と母親の、子供たちと祖父母のストーリーではないのか。データは増え続けた。</simpara>
<simpara>減ることもあった。何時間も収集したあげく、それが何も、まったく何も言ってくれないものだとわかることもあったのだ。完全に間違ったデータセットを掘っていたのだ。データがただ古い場合もあった。</simpara>
<figure id="FIG034"><title>図30. データセットの有用性の判定は非常に時間を使うタスクになりうる（Sarah Slobin）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-ZZ-04.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-ZZ-04.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>データはまた増え始めた。自分の中にいまだに疑問があり、家族たちを理解していないということに気づいたからだ。</simpara>
<simpara>見る必要があった。形にする必要があった。それでIllustratorで簡単な図を並べ、アレンジしたり編集したりするようになった。</simpara>
<simpara>チャートが見えてくると、家族たちの像も固まってきた。</simpara>
<figure id="FIG035"><title>図31. グラフィックによる可視化: データセットに隠れたトレンドとパターンを理解する（Sarah Slobin）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-ZZ-06.png" scale="96"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-ZZ-06.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG036"><title>図32. 数字は人: データをそれが示すストーリーの間に配置した（Wall Street Journal）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-ZZ-07.png" scale="92"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-ZZ-07.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>我々は乗り出した。私は各レポーターを呼んだ。チャートとおおまかな計画を渡し、彼らが感じたことに意味を持たすストーリーを見つけることを強く促した。この危機を読者の身近なものとするのだ。アムステルダムの小家族が、スペインやイタリアの大家族が必要だった。さまざまな世代からの声を聞いて、個人の来歴によりさまざまな反応があらわれる様子が見たかった。</simpara>
<simpara>その頃から私はタイムゾーンギャップを考慮して、メールチェックのため早起きするようになった。レポーターたちは楽しい話題、まとめ、そして予期せぬ驚きとともに戻ってきた。</simpara>
<simpara>写真については、各世代のポートレートが必要なことは解っていた。Mattの理想はカメラマンが各家族構成員の生活を1日フォローするというものだった。そして世界を、ニュースを、戦争までカバーしているビジュアルジャーナリストたちを選んだ。撮影をディナーテーブルで締めるというのがMattの希望だった。Samは夕飯のメニューを入れようと提案した。</simpara>
<simpara>そこからは、写真が語りかけるものを待つという問題になった。その家族が何を言っているか見えるまで待つのだ。そしてインタラクティブな外観をデザインした。Tintinの小説から彩りを拝借してインタラクションを構築した。すべてまとめてストーリーボードができあがると、背景にいくつかオリジナルのチャートを、多過ぎないように加えた。ちょうどストーリーの句読点になる程度に、テーマを強化する程度に。データはストーリーを区切り、変速させるものとなった。</simpara>
<figure id="FIG037"><title>図33. Life in the Euro Zone （Wall Street Journal）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-ZZ-09.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-ZZ-09.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>最後には、データは人に、写真に、ストーリーになった。それは談話を構成する枠組みであり、国の間に緊張をもたらすものだった。</simpara>
<simpara>公開にいたる頃、水平線の向こうに見えてくるものを皆が注視した年の暮れには、私は取り上げた一人ひとりを名前でわかるようになっていた。今でも彼らがどうしているか気になる。これがデータプロジェクトじゃないように感じられるのであれば、私にはそれが素晴らしい。なぜならLife in the Eurozoneで切り取った時間たちは、夕飯の席で仕事と生活について話し合うストーリーは、読者とシェアできる何かであるということだからだ。データを理解することが、それを可能にするのである。</simpara>
<simpara>&mdash; <emphasis>Sarah Slobin, Wall Street Journal</emphasis></simpara>
</section>
<section id="_openspending_orgで国庫を見ていく">
<title>OpenSpending.orgで国庫を見ていく</title>
<simpara>2007年、Open Knowledge Foundationに、1ページのプロジェクト案を携えたJonathanがやってきた。それは<ulink url="http://www.wheredoesmymoneygo.org/"><emphasis>Where Does My Money Go?（ぼくのお金はどこに行くの？）</emphasis></ulink> というプロジェクトで、英国市民が政府予算の使い道を理解しやすくなるものだった。これは公共情報をビジュアルに提供するという、より大きなプロジェクトの実証を意図していた。1940年代のOttoおよびMarie Neurathによる先駆的な仕事、Isotype Instituteをベースにしていた。</simpara>
<figure id="FIG038"><title>税金はどこへ行った？(オープンナレッジファウンデーション)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-PP-02.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-PP-02.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>Where Does My Money Go?プロジェクトは、幅広いソースからの公共データを、直感的なオープンソースのツール群で探っていくことを可能にした。我々は賞を取ってプロトタイプの開発に援助をもらい、後にはChannel 4の4IPから完全な形のウェブアプリケーションにするための助けを得た。情報デザインのグル、David McCandless（  <ulink url="http://www.informationisbeautiful.net/">Information is Beautiful</ulink>の人）は、国内の各地域に予算がどのように配分されているかを見せる‘Country and Regional Analysis’（国と地方の分析）や、支払った税金の一日あたりの内訳をポンドとペンスを単位に示す <ulink url="http://wheredoesmymoneygo.org/dailybread.html"><emphasis>Daily Bread</emphasis></ulink> など、巨大な数たちを自分と関連付けやすくするさまざまなデータビューを作成した。</simpara>
<figure id="FIG039"><title>Where Does My Money Go?のDaily Bread税支出計算機 (Open Knowledge Foundation)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-PP-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-PP-01.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>当時のプロジェクトの聖杯はアクロニムで<ulink url="http://data.gov.uk/dataset/coins">Combined Online Information System</ulink>、COINSデータと称されていた、存在する中で最高の網羅度と詳細性をもつ英国政府財政データベースだった。Lisa Evanse（Guardian Datalogチームに入るまで）、Julian Todd、Francis Irving（今やScraperwikiで有名）、Martin Rosenbaum（BBC）ほかと共同で、われわれはこのデータの閲覧請求を何度も何度も出していた---ほとんどは成功しなかった。</simpara>
<?dbfo-need height="1in"?>
<simpara>2010年についにこのデータはリリースされ、透明性支持者にとっての革命であると広く捉えられた。我々はウエブアプリケーションにロードするためデータに先行してアクセスできるという状況にあり、そのことが公になったときはプレスに非常に注目された。このためリリース日には、リリースについて論じ、頼み、またそれをオープンして見ていく方法を尋ねるといったことのために（ファイルは数十Gバイトあった）、我々のIRCチャンネルに何ダースものジャーナリストがあらわれた。こうした超大規模のリリースは複雑過ぎて効果的な「透明性を通じた不明瞭」あると難ずる評論家も居たが、読者に公共財源の使途について前代未聞の解説をすべくデータに突っ込んだ勇敢なジャーナリストもたくさんいた。Guardianはこのリリースをライブブログ中継したし、他にも多くのメディアが取り上げ、データから読み取れることを分析した。</simpara>
<simpara>同様のプロジェクトを他の国でも走らせることについて世界中からリクエストや問い合わせを受けるようになるまで長くは掛からなかった。プロジェクトのドイツ版で連邦国予算を扱うOffenerHaushaltがFriedrich Lindenbergの作成でローンチされてすぐ、我々はプロジェクトの国際版であるOpenSpendingをローンチした。これは世界中のユーザーが公共支出をマッピングする助けとなるもので、場所の解説を入れる機能はちょっとOpenStreetMap的だ。天才Gregor Aischの助けを借り、部分的にはオリジナルのDavid McCandlessのデザインをベースにして、我々は新デザインを実装した。</simpara>
<figure id="FIG0310"><title>_Where Does My Money Go?_のドイツ版OffenerHaushalt (Open Knowledge Foundation)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-PP-03.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-PP-03.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>OpenSpendingプロジェクトでは、支出データの取得、記述、解釈、一般への提示においてジャーナリストと大々的に共同した。OpenSpendingは公共支出の---高レベルの予算情報から執行レベルの実際の支出までの---検索可能な大規模データベースとして重要な第一弾である。トップはツリーマップやバブルツリーといった一連のすぐ使える可視化ツールで構成されている。誰もが地元の議会データをロードして可視化できるのだ。</simpara>
<simpara>我々は当初、一部のより洗練された可視化ツールに大きな需要があると考えていたが、さまざまなニュース媒体と話してみて、最初に充足すべきより基本的な要望があることを理解した。つまり、ブログ記事に動的な表を埋め込む機能などである。ニュース媒体にはストーリーに添えてデータへのパブリックアクセスの提供を促したい---だからそうしたウイジェットも作成した。</simpara>
<simpara>我々が最初の大きなリリースをおこなったのは、ペルージャで行われた第一回のInternational Journalism Festivalがある頃だった。開発者、ジャーナリスト、公務員たちがイタリアのデータを共同でOpenSpendingプラットフォームにロードし、支出が中央、地域、地方政府に分割されていく様子のリッチな可視化を得た。それはIl Fatto Quotidiano、Il Post、La Stampa、Repubblica、Wired Italiaといったメディアで取り上げられ、Guardianにも出た。</simpara>
<figure id="FIG0311"><title>イタリア版のWhere Does My Money Go?（La Stampa）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-PP-04.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-PP-04.png</phrase></textobject>
</mediaobject>
</figure>
<?dbfo-need height="1in"?>
<simpara>2011年にはPublish What You FundやOverseas Development Instituteとの共同作業で、2003-2006年のウガンダへの援助資金をマッピングした。これは新しかった。援助資金の流れを国の予算と並べて見ることができる最初のものだったからだ---援助国の優先順位と地方政府の優先順位を並べて見ることまでできるのだ。興味深い結論がいくつも得られた。たとえばHIVプログラムや家族計画はほぼ完全に外部の援助でまかなわれていることがわかった。これはGuardianでカバーされた。</simpara>
<simpara>我々は、その他の情報ソースを元にした支出データを相互参照をするためにNGOや支持団体にも働きかけた。例えば、Privacy Internationalは調査技術企業の膨大なリストや口語表現では`wiretappers ball'として知られている国際的な調査トレードショーに参加している代理店のリストを持って、我々にアプローチしてきた。企業名を支出データセットとシステム的に相互参照することで，どの企業が政府と契約しているのかを特定することが可能になった。その企業は情報公開請求（FOI: freedom of information request）で追跡調査ができた。このことは<ulink url="http://bit.ly/guardian-surveillance">Guardian</ulink> で報道された。</simpara>
<simpara>現在我々はSpending Storiesというプロジェクトの一環として、ジャーナリストや公衆の財政リテラシーを高めることに取り組んでいる。このプロジェクトはユーザーが公共支出データと公共支出にまつわるストーリーをリンクすることができるようになるというもので、ニュースの裏にある数字を、数字にまつわるニュースを閲覧できるようになるのだ。</simpara>
<simpara>この分野でやってきたことを通じ、我々は以下のことを学んだ:</simpara>
<itemizedlist>
<listitem>
<simpara>
ジャーナリストは生データの扱いに慣れていないことが多く、自分の取材の不可欠な基礎であるとは考えない者が多数である。生の情報を論拠としたストーリーというのはいまも比較的新しいアイディアである。
</simpara>
</listitem>
<listitem>
<simpara>
データの分析と理解は時間のかかるプロセスであり、それは必要なスキルがあっても同じだ。これを短寿命のニュースサイクルに当てはめるのは大変なので、データジャーナリズムは比較的長期の分析的なプロジェクトに使われることが多い。
</simpara>
</listitem>
<listitem>
<simpara>
政府がリリースするデータは不完全なものや古いものが多い。公共向けのデータベースは、情報公開法に基づく請求で取られる具体的な情報のかけらで補ってやらなければ分析的な用途に使えないことが、本当に多い。
</simpara>
</listitem>
<listitem>
<simpara>
支援団体、学者、研究者は、ジャーナリストより大規模なデータ駆動研究を行うだけの時間やリソースを持っていることが多い。彼らと組み、チームとして働くと大きな成果が出ることがある。
</simpara>
</listitem>
</itemizedlist>
<simpara>&mdash; <emphasis>Lucy Chambers および Jonathan Gray、Open Knowledge Foundation</emphasis></simpara>
<?dbfo-need height="2in"?>
</section>
<section id="_フィンランド議会選挙と運動資金_2">
<title>フィンランド議会選挙と運動資金</title>
<simpara>ここ数ヶ月、2007年のフィンランド総選挙での選挙運動資金にまつわる一連の裁判が行われている。</simpara>
<simpara>2007年の選挙後、記者たちは運動資金公表法制が政治家には無効であることを発見した。運動資金は基本的に政治家からの支持を買うのに使われ、彼らはフィンランドの法で定められたように資金を報告しなかったのだ。</simpara>
<simpara>事件後に法は厳格化された。2011年3月の総選挙後、ヘルシンギン・サノマットでは運動資金にまつわる利用可能な全てのデータを精査することを決めた。新法では、選挙資金はすべて報告されねばならず、また1500ユーロ未満の寄付だけが匿名にできることを規定している。</simpara>
<section id="_1_データと開発者を探す">
<title>1. データと開発者を探す</title>
<simpara>ヘルシンギン・サノマットは2011年3月からHSオープンハッカソンを催している。フィンランドのコーダー、ジャーナリスト、グラフィックデザイナーを社屋の地下フロアに招待するのだ。参加者は3つのグループに分けられ、アプリケーションや可視化ツールの開発を促される。これまでの3回のイベントにはそれぞれ60人程度の参加者があった。運動資金データは2011年5月のHS Open #2でフォーカスすべきものとして定めた。</simpara>
<simpara>フィンランド会計監査局は運動資金の記録当局である。これは簡単な部分だ。最高情報責任者のヤーッコ・ハムネンが運動資金データベースにリアルタイムアクセスするウエブサイトを作った。監査局はこのデータベースを我々の要請からわずか2ヶ月で作り上げていた。</simpara>
<simpara>Webサイト <ulink url="http://www.vaalirahoitus.fi/">Vaalirahoitus.fi</ulink>は、今後すべての選挙の運動資金情報を報道や公衆に提供する。</simpara>
<figure id="FIG0312"><title>Election financing（選挙資金調達）(Helsingin Sanomat)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-DD.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-DD.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_2_アイディア出しのブレインストーム">
<title>2. アイディア出しのブレインストーム</title>
<simpara>HS Open 2の参加者たちは、このデータに何をするかについて20種類のプロトタイプを考えだした。プロトタイプはすべてWebサイトで見ることができる（テキストはフィンランド語）。</simpara>
<simpara>ジャンヌ・ペルトラというバイオインフォマティクスの研究者が指摘したのは、運動資金データは多くの相互依存があるという点で彼らの研究する遺伝子データに似ていることだった。バイオインフォマティックスの世界では、こうした相互依存をマッピングするのに使われるCytoscapeというオープンソースツールが存在する。データをCytoscapeにかけることで、非常に興味深いプロトタイプが得られた。</simpara>
</section>
<section id="_3_紙のアイディアをウェブに実装する">
<title>3. 紙のアイディアをウェブに実装する</title>
<simpara>運動資金にまつわる法は、選出された議員は選挙後2ヶ月以内に資金の報告を行わねばならないと定めている。これはつまり、実データが6月中旬まで揃わないということを意味する。HS Openでは締め切り前に提出した議員のデータしかなかったのだ。</simpara>
<simpara>また、データ形式にも問題があった。会計監査局はデータを2つのCSVファイルで提供していた。片方に運動経費の総額が、もう一方に全寄付者がリストアップされているのだ。これを結合し、寄付者、受領者、金額の3つのカラムから成るファイルを生成した。このデータ形式では、政治家が自己資金を使った場合、政治家Aが政治家AにXユーロ寄付した、と出ることになる。直感には反するが、Cytoscapeでは有効だった。</simpara>
<simpara>掃除と書式変換が終わったデータを、単純にCytoscapeに掛けた。会社のグラフィック部門がそれを元に全面サイズのグラフィックを作成した。</simpara>
<simpara>最後に美しいビジュアライゼーションを<ulink url="http://www.vaaliraha.com/">Webサイト</ulink> 上に構築した。これは単なるネットワーク分析グラフィックではない。どれだけの運動資金が存在し、誰がそれを与えたか簡単に見て回れる方法を提供したかったのだ。最初の画面は議員間での資金分布だ。議員の名前をクリックすると、彼または彼女の資金の内訳が表示される。さらにはここで表示される個々の寄付者について、良い、良くないを投票することもできる。このビジュアライゼーションはサトゥマという広告代理店のユハ・ロウビネンとユッカ・コッコが作成した。</simpara>
<simpara>運動資金ビジュアライゼーションのウェブバージョンで使っているデータは、ネットワーク分析と同じものである。</simpara>
</section>
<section id="_4_データのパブリッシュ">
<title>4. データのパブリッシュ</title>
<simpara>国の会計監査局はデータを既に公表しており、我々が再度公表する必要はもちろん無い。しかしながら、我々はデータの掃除をして、より良い構造を与えているということで、これを公表することにした。データは <ulink url="http://creativecommons.org/licenses/by/3.0/">クリエイティブ・コモンズ帰属ライセンス</ulink> で出している。後に独立の開発者が複数、このデータのビジュアライゼーションを作成しているが、我々がパブリッシュしたデータを使ったものもいくつかある。</simpara>
<simpara>プロジェクトで使用したツールは以下の通りだ: データのクリーニングと分析にExcelとGoogle Refine、ネットワーク分析にCytoscape、ビジュアライゼーションにIllustratorとFlashである。FlashはHTML5にすべきだったが、時間切れだった。</simpara>
<simpara>学んだことは？ おそらく一番重要な教訓は、データ構造とは大変なものである、ということだ。元データが適切なフォーマットになっていなければ、再計算と変換には多大な時間がかかるのだ。</simpara>
<simpara>&mdash; <emphasis>エサ・マキネン、ヘルシンギン・サノマット</emphasis></simpara>
</section>
</section>
<section id="_リアルタイム選挙ハック_hacks_hackers_buenos_aires">
<title>リアルタイム選挙ハック (Hacks/Hackers Buenos Aires)</title>
<figure id="FIG0313"><title>Elections 2011 (Hacks/Hackers Buenos Aires)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-FF.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-FF.png</phrase></textobject>
</mediaobject>
</figure>
<simpara><ulink url="http://elecciones.hhba.info">Electoral Hack</ulink> は、政治を分析するプロジェクトで、2011年のアルゼンチンの選挙の暫定票のデータをビジュアライズした。 このシステムでは前回の選挙結果と共に社会人口学的な統計データも扱っている。結果は、2011年のアルゼンチンでの選挙のデータを元にリアルタイムでアップデートされ、選挙結果の要約も行った。プロジェクトを主導したのは Hacks/Hackers Buenos Airesと政治アナリストの Andy Tow で、ジャーナリストや開発車、デザイナー、アナリスト、政治学者、そして Hack/Hackers の支部のメンバーが協力した。</simpara>
<section id="_どんなデータを利用したのか">
<title>どんなデータを利用したのか?</title>
<simpara>All data came from official sources: the National Electoral Bureau provided access to data of the provisional count by Indra; the Department of the Interior provided information about elected posts and candidates from different political parties; a <ulink url="http://yoquierosaber.org/">university project</ulink> provided biographical information and the policy platforms of each presidential ticket; while socio-demographic information came from the 2001 National Census of Population and Housing (INDEC), the 2010 Census (INDEC), and the Ministry of Health.</simpara>
</section>
<section id="_どのように開発されたのか">
<title>どのように開発されたのか？</title>
<simpara>アプリケーションは、Hacks/Hackers Buenos Airesによる2011 Election Hackathonで選挙の前日の2011年10月23日に作られた。ハッカソンには30人の様々なバックグラウンドを持つボランティアが参加した。Electoral Hackはオープンなプラットフォームとして開発され、その後も改善できるようになっていた。技術的には、Google Fusion Tables、Google Maps、そしてベクターグラフィックを扱うためのライブラリを使用した。</simpara>
<simpara>We worked on the construction of polygons for displaying geographic mapping and electoral demographics. Combining polygons in GIS software and geometries from public tables in Google Fusion Tables, we generated tables with keys corresponding to the electoral database of the Ministry of Interior, Indra, and sociodemographic data from INDEC. From this, we created visualizations in Google Maps.</simpara>
<simpara>Google Maps APIを使用して、異なる色を使って投票の空間分布を示す主題図を作成した。色の密度は、投票管理局や投票所ごとの投票先の分布を示している。特に、主要な都市での結果は強調してあった。ブエノスアイレス、ブエノスアイレスの都市圏の24の地域、コルドバ、ロザリオなどである。</simpara>
<simpara>同じテクニックを使って、これまでの選挙(すなわち2011年の予備選挙と2007年の選挙)の空間分布や、貧困・小児死亡率・生活環境などの社会人口学的データの分布も作成して分析や比較ができるようにした。さらにこのプロジェクトでは、10月の選挙と8月の大統領選挙の際にそれぞれの政党が獲得した投票の差についての空間分布も公開した。</simpara>
<simpara>その後、暫定投票結果のデータの一部を使って投票結果の分析を行うアニメーション地図を作成し、投票結果の進み具合を投票所がしまってから次の朝になるまでレポートした。</simpara>
</section>
<section id="_良かったこと">
<title>良かったこと</title>
<itemizedlist>
<listitem>
<simpara>
We set out to find and represent data and we were able to do that.  We had the <ulink url="http://infoargentina.unicef.org.ar/">UNICEF&#8217;s database of child sociodemographics</ulink> at hand, as well as the database of candidates created by the yoquierosaber.org group of Torcuato Di Tella University. During the hackathon we gathered a large volume of additional data that we did not end up including.
</simpara>
</listitem>
<listitem>
<simpara>
It was clear that the journalistic and programming work was enriched by scholarship. Without the contributions of Andy Tow and Hilario Moreno Campos, the project would have been impossible to achieve.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_cons">
<title>Cons</title>
<itemizedlist>
<listitem>
<simpara>
The sociodemographic data we could use was not up to date (most was from the 2001 census), and it was not very granular. For example, it did not include detail about local average GDP, main economic activity, education level, number of schools, doctors per capita, and lots of other things that it would have been great to have.
</simpara>
</listitem>
<listitem>
<simpara>
Originally the system was intended as a tool that could be used to combine and display any arbitrary data, so that journalists could easily display data that interested them on the Web. But we had to leave this for another time.
</simpara>
</listitem>
<listitem>
<simpara>
As the project was built by volunteers in a short time frame, it was impossible to do everything that we wanted to do. Nevertheless, we made a lot of progress in the right direction.
</simpara>
</listitem>
<listitem>
<simpara>
For the same reason, all the collaborative work of 30 people ended up condensed into a single programmer when the data offered by the government began to appear, and we ran into some problems importing data in real time. These were solved within hours.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_implications">
<title>Implications</title>
<simpara>The Electoral Hack platform had a big impact in the media, with television, radio, print and online coverage. Maps from the project were used by several media platforms during the elections and in subsequent days. As the days went by, the maps and visualizations were updated, increasing traffic even more. On Election Day, the site created that very day received about 20 thousand unique visitors and its maps were reproduced on the cover page of the newspaper Página/12 for two consecutive days, as well as in articles in La Nación. Some maps appeared in the print edition of the newspaper Clarín. It was the first time that an interactive display of real-time maps had been used in the history of Argentine journalism. In the central maps one could clearly see the overwhelming victory of Cristina Fernandez de Kirchner by 54 percent of the vote, broken up by color saturation. It also served to help users understand specific cases where local candidates had landslide victories in the provinces.</simpara>
<simpara>&mdash; <emphasis>Mariano Blejman, Mariana Berruezo, Sergio Sorín, Andy Tow, and Martín Sarsale from Hacks/Hackers Buenos Aires</emphasis></simpara>
</section>
</section>
<section id="_ニュースにおけるデータ_ウィキリークス">
<title>ニュースにおけるデータ: ウィキリークス</title>
<simpara>それは調査報道チームの質問から始まった。「表計算ソフトは使いこなせるだろう？」示された表はとてつもないものだった。92,201行ものデータがあり、それぞれの行にはアフガニスタンにおける軍事に関わるできごとの詳細な分析が含まれていた。<ulink url="http://bit.ly/guardian-warlogs">WikiLeaks war logs（ウィキリークスの戦争記録）</ulink> がそれだ。まずはこの話をする。それから、イラクと外交公電に関する２つのエピソードが続く。正式な用語では SIGACTS: the US military Significant Actions （アメリカ軍の重大行動）のデータベースと呼ばれるものだ。</simpara>
<simpara>ニューヨーク・タイムズやデア・シュピーゲルと共有されたアフガニスタンの戦争記録はデータジャーナリズムの実践例である。私たちがやりたかったのは、自分たちの抱える報道の専門チームが情報の中からすばらしい人間ドラマを引き出せるようにすることだった。また、私たち自身も、全体像をとらえ、実際に戦争がどのように進行しているかを示すためにその記録を分析したかった。</simpara>
<simpara>始まったばかりのころに取り組んだ重要なことは、データベース全体を公開しないようにすることだった。ウィキリークスは既にそうしようとしていたが、私たちは情報提供者の名前を明かさないことやNATOの部隊を不必要に危険にさらしたりしないことを保障したかった。同時に、デヴィッド・レイやニック・デイヴィス（ジュリアン・アサンジと交渉してデータを公開させたのは彼らだ）率いる我々の調査報道チームがデータを使いやすいようにする必要があった。また、鍵となる情報へのアクセスをよりシンプルにし、できる限り明瞭でオープンな形で白日の下にさらしたかった。</simpara>
<simpara>データは巨大なエクセルファイルの形で受け取った。92,201 行のデータの中には、中身が何もないデータもあればフォーマットが整っていないものもあった。ジャーナリストがデータの中からストーリーを引き出そうとするのに役立つものではなかったし、意味のある集計をするにはサイズが大きすぎた。</simpara>
<simpara>私たちのチームはシンプルな内部用のデータベースをSQLを使って構築した。ジャーナリストはそれによってストーリーの中のキーワードやできごとを検索することが出来るようになった。突如として、データセットはアクセス可能なものとなり、ストーリーを生み出すことが容易になったのである。</simpara>
<simpara>データはきちんと構造化された。それぞれのできごとには、時間、日時、説明、犠牲者数、―そしてこれがとても重要なものであるが―緯度経度といった鍵となるデータが付された。</simpara>
<figure id="FIG0314"><title>ウィキリークスの戦争記録（ガーディアン）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-GG.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-GG.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>私たちは、戦争における重要なストーリーの中の一つを語るのに役立つようにデータを絞り込むことにも取り組み始めた。IED (即席爆発装置、improvised explosive device)による攻撃の出現だ。これは、路上に仕掛けられる手作りの爆弾で、予想しづらく戦いにくい。データセットはそれでも巨大なものだったが、扱いやすくはなっていた。2004年から2009年にわたる約7,500件 の IED 爆発や待ち伏せ（待ち伏せは小火器やグレネードランチャーと組み合わせて行われる）が対象だった。さらに、8,000 の IED は発見され除去されていた。私たちは、そういったできごとの時系列変化を知り、どのように異なるかを知りたかった。このデータによって私たちは、イギリスとカナダの部隊が当時基地を置いていた南方の地域において多くの被害が出ていることを知ることができた。これは、戦争を取材していたジャーナリストたちが知っていたことを裏付けるものだった。</simpara>
<simpara>2010年の10月にイラクの戦争記録が公開されたことによって、イラクの戦争に関するさらに 391,000 件もの情報が衆目に晒された。</simpara>
<simpara>こちらはアフガニスタンの事例に比べると格段に良かった。このデータを根拠に、この戦争を歴史上最も文書化された戦争だと言っても差し支えないであろう。あらゆる詳細な記述が私たちの分析や説明を助けてくれた。しかし、ある点が際立っている。死者数の膨大さ、そしてそのほとんどが市民だという点だ。</simpara>
<simpara>アフガニスタンのデータと同様に、ガーディアンはデータベース全体を再公開しないことに決めた。それは主に、概要の項に情報提供者の秘密に関わるような詳細などが含まれていないということを保証できなかったからだ。</simpara>
<simpara>しかし、私たちは、誰かが死亡したあらゆるできごとに関する記録を含む表をユーザがダウンロードできるようにした。それは全部で 60,000 件近かった。概要の項が省かれているので、 軍事の見出し、死者数、地理的な詳細といった基本的なデータになっている。</simpara>
<simpara>私たちは誰かが死んだこれらすべてのできごとを <ulink url="http://bit.ly/guardian-iraq-map">Google Fusion tables を使って地図上に配置した</ulink>。完璧ではないが、イラクを蹂躙した破壊行為のパターンをマッピングする試みの端緒となった。</simpara>
<simpara>2010年の12月には外交公電の公開があった。これはまた全く異なるタイプのものであった。オフィシャルな文書の巨大なデータセットで、世界中 250 を超える米国の大使館や領事館から送信された 251,287 の公電だった。この中には現オバマ大統領の施政を含む 50,000 以上の文書も含まれており、米国の外交辞令 を映し出した他に例を見ない資料となっていた。ところで具体的には何がこのデータに含まれていたのだろうか？</simpara>
<simpara>外交公電自体は巨大な SIPRNet (Secret Internet Protocol Router Network、つまり機密IPルーターネットワークの略。シパーネットと読む。）から抜き出された。SIPRNet は世界規模の米軍インターネットシステムで、一般市民のインターネットから隔絶され、ワシントンの国防総省によって運用されている。
2001年9月の攻撃<footnote><simpara>9.11 のいわゆるアメリカ同時多発テロ事件を指している</simpara></footnote>以来、米国では政府情報のアーカイブをつなぎ合わせることで、重要情報を貯蔵庫や「煙突」に詰まったりすることがないようにしたいという動きがあった。大使館は過去十年間の間に次々と SIPRNet に接続され、それによって軍事や外交の情報が共有できるようになっていた。2002年までには、125の大使館が SIPRNet 上にあり、2005年にはその数は180にまで増加し、現在では米国の在外公館の大半がシステムに接続されている。漏洩した外交公電のほとんどが2008年および2009年のものであることは、こういった背景がある。デヴィッド・レイは次のように書いている:</simpara>
<blockquote>
<simpara>SIPDIS と記された大使館の公電は自動的に大使館限定のウェブサイトにダウンロードされる。そこから、国務省の人間だけでなく、米軍の中で「秘密」レベルまで閲覧を許可されている人間も、パスワードを入力することでコンピュータを SIPRNet に接続することができる。</simpara>
</blockquote>
<simpara>…ここに接続可能な人々は、驚くべきことに全部で 300万人以上にもなるのだ。米国以外の市民に見せてはならず、ヒラリー・クリントン国務長官以下ワシントンの役人が読むことを想定されているという意味を持つ <emphasis>SECRET NOFORN</emphasis> を最上位として、このデータはいくつかのランクに分けられている。これらの外交公電は一般的に現地の大使やその部下が起草する。「トップシークレット」やそれ以上の外国の情報文書は SIPRNet からアクセスすることはできない。</simpara>
<simpara>数量化されていたり同定可能なデータを伴ったりしていたこれまでの情報公開とは異なり、これは主に文書で構成されていた。何が含まれていたかというと:</simpara>
<variablelist>
<varlistentry>
<term>
送信元
</term>
<listitem>
<simpara>
  送信元となった大使館や組織。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
受信者のリスト
</term>
<listitem>
<simpara>
  外交公電は一般的に多くの他大使館や組織に送られていた。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
表題フィールド
</term>
<listitem>
<simpara>
  外交公電の要約。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
タグ
</term>
<listitem>
<simpara>
  それぞれの外交公電は多くのキーワードの略語でタグ付けされていた。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
本文
</term>
<listitem>
<simpara>
  外交公電それ自体。明白なセキュリティ上の都合により、私たちはこの全体を公開することはしなかった。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>この事例の中で面白い部分の一つに、外交公電がことあるごとにリークを生み出しているという点がある。外交公電が公開された直後数週間にわたってそれはニュースになり続けたが、現在に至っても、収賄や国際的スキャンダルに関するストーリーが見つかるたびに、この外交公電にアクセスすることでさらに新たなストーリーが見つけられるのだ。</simpara>
<simpara>外交公電の分析は膨大な作業で、完全に終わることはないであろう。</simpara>
<simpara>&mdash; <emphasis>これは、当初 "Facts are Sacred: The Power of Data"（「真実は神聖なり: データの力」） という題でガーディアンのサイモン・ロジャーによって Kindle 上に公開された章を編集したものである。</emphasis></simpara>
</section>
<section id="_mapa76_ハッカソン">
<title>Mapa76 ハッカソン</title>
<simpara>2011年4月、我々は <ulink url="http://www.meetup.com/HacksHackersBA/">Hacks/Hackersのブエノスアイレス支部</ulink>を立ち上げた。立ち上げに合わせ、2つのミーティングを開催した。どちらもジャーナリストとソフトウェア開発者がコラボレーションするためのイベントで、120人から150人の参加者がいた。3回目のミーティングでは、ブエノスアイレスから300キロ離れたロザリオという町にある、デジタルジャーナリズム協議会の8人メンバーと、30時間のハッカソンを行った。</simpara>
<simpara>3つのミーティングを通して掲げられたテーマは、ウェブから集めた大量のデータから余計なものを省き、目に見える形で表現することだった。データの抽出と、データの視覚的な表示。使ったデータの表示。その支援を行うため、Mapa76.infoと呼ばれるプロジェクトが発足したが、これは簡単な作業ではなかった。</simpara>
<figure id="FIG0315"><title>Mapa76 （Hacks/Hackers ブエノスアイレス）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-MM.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-MM.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>なぜMapa76というプロジェクトが始まったのか？　1976年3月24日、アルゼンチンでクーデターが発生した（訳注 : 汚い戦争と呼ばれるアルゼンチンの内戦。クーデターにより成立した軍事独裁政権が、知識層やジャーナリストへの弾圧を行った）。この戦争が終わる1983年までの間に、30,000人の行方不明者、何千人もの死者、そして500人の児童誘拐が行われた。30年以上たった今、たくさんのアルゼンチン国民が、この戦争で人道に対する罪が行われたと考えており、2011年9月現在、この犯罪に関わったとされた人物は262人に達している。現在は14の裁判が行われており、7つの裁判の開始日が決まっている。公開裁判にかけられているのは802人である。</simpara>
<simpara>これらの告発は、研究者、ジャーナリスト、人権組織、法廷、検事、あるいは他の手続きにより集められた、大量のデータによって行われた。データは分散して処理されたが、調査者達はソフトウェアを使わずにデータを調べることもあった。これはつまり、何かしら見落としが存在することや、データから導き出せる仮説の内容に限界があることを意味している。Mapa76は報道、法律、裁判や歴史に関する調査で、大量のデータにオープンアクセスするためのツールなのである。</simpara>
<simpara>ハッカソンに備え、ジャーナリストと開発者がコラボレーションできるプラットフォームを作成した。マーチン・サルサレが、テキストデータから構造化されたデータを抽出するための、基本的なアルゴリズムを作成した。幾つかのライブラリはDocumentCloud.orgプロジェクトでも使用されているものだが、大量に流用しているわけではない。プラットフォームは自動的に分析を行い、名前や日付、場所といった情報を抽出する。ユーザは様々な事件の重要な事実を調べていくことが可能となる（誕生日、逮捕された場所、行方不明になったとされる場所など）。</simpara>
<simpara>我々の目標は、アルゼンチンの軍事独裁政権に関する裁判のためのデータを自動で抽出することだ。文章になっている証拠や証言、判決内容から自動的（あるいは半自動的）に、1976年から1983年の間に起こった事件に関する、重要なデータを見つけられるようにしたいと思っている。抽出されたデータ（名前や場所、日付けは保存され、研究者が分析し、より良いデータにできるようになっている。データは、地図、年表、ネットワーク分析ツールを使って解析することも可能だ。</simpara>
<simpara>このプロジェクトによって、ジャーナリスト、調査者、検察官や証人は、ある個人の人生がどうであったかを知ることができるようになるだろう。そこには、誘拐や行方不明、解放などの出来事も含まれる。もし何か足りない情報があれば、ユーザは膨大な量のドキュメントから、事件に関係がありそうな情報を探し出すことができる。</simpara>
<simpara>ハッカソンのために <ulink url="http://www.meetup.com/HacksHackersBA/">Hacks/Hackersブエノスアイレス</ulink> で公示をした。当時は200人ほどのメンバーがいた（この記事を書いている時点では540人）。我々はたくさんの人権団体とも連絡を取り合っていて、このミーティングにはおよそ40人のジャーナリスト、支援団体、開発者やデザイナーなどが参加した。</simpara>
<simpara>ハッカソンの最中、いろいろな種類の参加者達が、それぞれに独立して取り組むことができるようにタスクを分割できることに気が付いた。そうすることで、作業を円滑に進めることができるのだ。例えば、デザイナーに地図と年表を一つにしたインタフェースを作るようにお願いし、開発者には構造化されたデータの抽出方法や、はっきりと名前を取ることができるアルゴリズムに関する調査をお願いし、ジャーナリストには特定の人達に関して考え得るストーリーについての比較検討や、特定の事件に関する資料の精査をお願いする、といったやり方だ。</simpara>
<simpara>ハッカソンを開催して気付いた、大きな問題がある。我々のプロジェクトがとても野心的であったこと、短い時間にたくさんの要求を出してしまったこと、そして、ボランティアのような緩いつながりを調整していくことの難しさだ。プロジェクトを手伝ってくれた人達のほとんどは仕事で忙しいうえ、他のイベントやプロジェクトにも関わっていた。Hacks/Hackersブエノスアイレスが2011年に行うことができたミーティングは9回だった。</simpara>
<simpara>プロジェクトは今でも開発を続けている。4人からなる、コアチームがあり、12人以上の協力者と活動をしている。<ulink url="http://groups.google.com/group/mapa76-dev/">公開メーリングリスト</ulink> と <ulink url="https://github.com/mapa76/">プログラムのGitHubリポジトリ</ulink> を通して、プロジェクトには誰でも参加することが可能だ。</simpara>
<simpara>&mdash; <emphasis>マリアーノ・ブレフマン, Hacks/Hackers ブエノスアイレス</emphasis></simpara>
</section>
<section id="_ガーディアンのデータブログによる_イギリス暴動の報道">
<title>ガーディアンのデータブログによる、イギリス暴動の報道</title>
<simpara>2011年の夏、イギリスは暴動の波に襲われた。当時、政治家たちはこうした暴動が貧困とは直接関係なく、単なる犯罪者たちによるものだとしていた。さらに、保守政権を指導する首相までもが、ソーシャルメディアによって暴動が引き起こされたと非難した。FacebookやTwitter、BlackBerryのメッセンジャーで暴動が組織され、扇動されたとしたのだ。一時的にソーシャルメディアをダウンさせるよう、指令が出された。政府は暴動がなぜ起きたかについて、問い合わせに応じなかったため、ガーディアンはロンドン・スクール・オブ・エコノミクスとコラボレーションし、画期的な試み、<ulink url="http://www.guardian.co.uk/uk/series/reading-the-riots">「Reading the Riots（暴動を読む）」</ulink> を立ち上げ、この問題に取り組んだ。</simpara>
<figure id="FIG0316"><title>ロンドン暴動：すべての事件を検証する（ガーディアン）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-ZZ.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-ZZ.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>ガーディアンは暴動について、誰が、なぜ略奪するのかをわかりやすく伝えるためにデータジャーナリズムを使っていた。マンチェスター大学のロブ・プロクター教授の研究チームと共同で研究し、ソーシャルメディアの役割をより理解するため、暴動の報道に徹底的にソーシャルメディアを活用した。「暴動を読む」のチームは、ガーディアンのスペシャル・プロジェクト・エディターであるポール・ルイスが率いた。彼は、暴動が起こっている間、イングランド中を飛び回って最前線でリポート（Twitterアカウント @paullewis を通じて報道）。セカンドチームが、260万におよぶ暴動関連のツイートをTwitter社から提供を受け、分析に取り組んだ。Twitterでどうやって噂が広まったのか、ユーザーが情報の拡散にどのような役割を果たしたのか、Twitterというプラットフォームが人を駆り立てたのか。そして、これまでとは違う組織のあり方の実験となるのかどうか。こうしたことを明らかにすることが、この取り組みの主な目的だった。</simpara>
<simpara>「データジャーナリズム」や「データビジュアライゼーション」という観点で見ると、2つの期間に分けるとわかりやすい。最初は暴動が起こっているまさにその最中に、データを記事作りに役立てた時期。そして次は、学術機関と共同でガーディアンが2つのチームを作り、より掘り下げて、データを集め、分析し、その知見を報道記事として書いた期間だ。最初のフェイズは2011年12月のはじめにおよそ一週間をかけて「暴動を読む」という形で特集された。この2つの期間に渡って、データジャーナリズムという手法の重要な事例が示されているので紹介しよう。</simpara>
<section id="_第1フェイズ_暴動の発生">
<title>第1フェイズ: 暴動の発生</title>
<simpara>シンプルな地図を使って、ガーディアンのデータチームは <ulink url="http://bit.ly/guardian-riots-map">locations of confirmed riots spots</ulink> and through <ulink url="http://bit.ly/guardian-riots-poverty">mashing up deprivation data with where the riots took place</ulink> <ulink url="http://bit.ly/guardian-riots-map">どこで暴動が起きたか</ulink> と、 <ulink url="http://bit.ly/guardian-riots-poverty">貧困のデータをマッシュアップして</ulink> 、暴動が貧困とは関係がない、とする政治家の発言の誤りを指摘した。 両方とも、市販のソフトウェアを使って作られており、マッシュアップに関しては、暴動の位置情報と他のデータを組み合わせて、新たな文脈を生み出している。</simpara>
<simpara>暴動の間、ソーシャルメディア（この場合、Twitterだが）がどのように使われていたかを、ガーディアンは <ulink url="http://bit.ly/guardian-riots-twitter">visualization of riot-related hashtags used during this period</ulink> <ulink url="http://bit.ly/guardian-riots-twitter">可視化した</ulink> 。これによって、Twitterは、暴動を組織化するより、主に暴動に対して何か反応するのに使われていることがわかった。暴動後に荒れた街を掃除しようという自主的なキャンペーンが、 #riotcleanup_ というハッシュタグで呼びかけられ、これが暴動期間中、一番拡散されている。</simpara>
</section>
<section id="_フェイズ2_暴動を読み解く">
<title>フェイズ2: 暴動を読み解く</title>
<simpara>研究機関との数カ月間に及ぶ調査の結果、ガーディアンがレポートを掲載すると、2つのビジュアリゼーションが注目され、議論を呼んだ。一つ目は短い動画で、暴動を起こした人たちの住所を示したもので、いわゆる「暴動への通勤」と呼ばれるものだ。 <ulink url="http://bit.ly/guardian-riots-commute">a short video</ulink>,交通地図の専門会社、ITO World が、暴動参加者がどのルートを使って移動した可能性が高いかをモデル化し、都市ごとにそれぞれのパターンがあることを示した。中には、長い距離を移動する者もいた。</simpara>
<simpara>2つ目は、Twitterで噂が拡散した経路を示したものだ。アカデミック・チームはTwitter上に流れた、7つの噂を分析対象とした。噂についてのすべてのデータを集め、ひたすらに噂を流して参加を呼びかけるもの、それを拒否するもの、問い合わせをするもの、単純にコメントするもの、という4つに分類、一覧表を作った。すべてのツイートは3通ずつ作られており、それがガーディアンのインタラクティブチームによってビジュアライズされている。<ulink url="http://bit.ly/guardian-riots">the results were visualized</ulink> そして、ガーディアンはどうやってそのビジュアライゼーションを作ったかを記事にしている。<ulink url="http://bit.ly/guardian-riots-twitter-interactive">written about how they built the visualization</ulink></simpara>
<?dbfo-need height="1in"?>
<simpara>このビジュアライゼーションの何が刺さったのか。それは、文章で記述するのが難しかった、噂の性質と、繰り返し増殖する様子をはっきりと表していたからだ。メインストリームなメディアの役割は、こうした噂の真偽を明らかにすること（たとえば、嘘であることを暴いたり、真実ならばそれを即座にニュースにすることだ）。Twitterは、そもそもがそうした噂の集合体でできている。このビジュアライゼーションは、単にストーリーテリングに役立つだけでなく、Twitter上でどう噂が機能したか、本物の洞察が得られるのだ。そしてそのことは、今後起こる出来事を考える上でも重要な情報になる。</simpara>
<simpara>この事例で明らかになったのは、260万（2.6million）ものツイートの分析が、ガーディアンとアカデミックチームの共同作業によって行われ、強力なシナジーを生んだということだ。アカデミックチームが分析ツールを作り、今やそれは、 <ulink url="http://www.analysingsocialmedia.org/">make these widely available to anyone who wishes to use them</ulink>として公開され、誰でも使うことができる。一方でガーディアンのチームはそのツールに、どう表現するかを結びつけた。当事者でない第三者が、ソーシャルメディアの分析とビジュアライゼーションによって、意味のある報道をしたことは、良い事例となることだろう。</simpara>
<simpara>&mdash; <emphasis>Farida Vis, University of Leicester</emphasis></simpara>
</section>
</section>
<section id="_イリノイ学校レポートカード">
<title>イリノイ学校レポートカード</title>
<simpara>毎年、イリノイ州の教育委員会は学校の"レポートカード”デモグラフィックスとパフォーマンスに関する全ての公立学校のデータをリリースしている。それは大量のデータセットであり、今年のリリースは9500もの列数になった。問題は大量のデータから表現するべき何を選ぶかである（すべてのソフトウェアプロジェクトと同様に、難しいのはソフトを作ることではなく、正しいソフトをつくることである。）。</simpara>
<simpara>我々は興味深いデータを選択するために教育チームから来た記者と編集者と共に作業にあたった（これ以外にも大量の興味深いデータが存在したが、記者がこれを元に伝えようとしていることは問題が存在したり、ミスリーディングである。）。</simpara>
<simpara>我々はニュースルームにて、学校に通う子供たちの関係者の方を調査、インタビューした。途中、我々は読者とかつての学校サイトのユーザビリティ（そこに欠けている！）について多くのことを知ることになった。</simpara>
<figure id="FIG0317"><title>2011 イリノイ学校レポートカード (Chicago Tribune)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-EE.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-EE.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>我々は特定のユーザーとそのユースケースについてデザインすることを目的とした：</simpara>
<simpara>*どのように学校が測定されているかを知りたい親たち
*どこに住むべきか選択しようとしている親たち：しばしば学校の質がそのような決定において大きな影響を持っているので。</simpara>
<simpara>第一回目においては、学校のサイトは6週間、2人の開発者のプロジェクトであった。2011年の更新においては、4週間、2人の開発者のプロジェクトであった。（最近のプロジェクトでは主に3人の人間が働いている。ただし誰もフルタイムではないので計2人程度である。）</simpara>
<?dbfo-need height="1in"?>
<simpara>このプロジェクトのカギとなるピースは情報デザインであった。我々は入手可能なデータのごく一部しか用いてないが、それでも、多くのデータであるといえるし、それをすべて理解可能にするのはチャレンジングである。幸運なことに、我々はグラフィックデスクから人材（複雑な情報を可視化することを専門とするデザイナー）を借りることができた。彼はチャートのデザインについて我々に多くのことを教えてくれた。また、彼は読み手の能力と数字を理解したいという気持ちを低く見積もることなく、プレゼンテーションを一般的に解読可能なものにするように導いてくれた。</simpara>
<simpara>サイトはPythonのDjangoを用いて構築された。データはMongoDBに格納されている。学校のデータは不均一であり、階層的であり、リレーショナルデータベースには適さない（しかしながら、我々はおそらくPostgreSQLは用いているようだ）。</simpara>
<simpara>我々は最初にこのプロジェクトにおいて、Twiiterブートストラップユーザーインタフェースを検証した。そしてその結果に満足した。チャートはFlotを用いて描かれた。</simpara>
<simpara>アプリケーションは我々の記した学校の能力についての記事にも近かった。それはある種のポータルのように、以下のような方法で機能した。新たな学校の能力についての記事が存在する時、それをアプリのトップに配置して、その記事と関連する学校のリストを横に置いた（そして、新たな記事が選択されるとwww.chicagotribune.comの読み手は記事ではなく、アプリに飛ばされる。）。</simpara>
<simpara>初期の報告では、読者はアプリを好んだ。我々の受け取ったフィードバックはおおむね好評であった（もしくは最低でも建設的であった）。ページビューは非常に高かった。おまけに、ホームページから学校に関する記事が消えると、データへのアクセスも消えると期待していたが、このデータは年間を通じて興味深いものであったようだ。我々の過去の検証では読者は年中このアプリを求めているようだ。</simpara>
<simpara>我々のこのプロジェクトから得られた数少ないカギとなるアイデアは、</simpara>
<simpara>*グラフィックデスクはあなたの仲間である。彼らは複雑な情報を消化可能な形にすることに長けている。</simpara>
<simpara>*ニュースルームに助けを求めなさい。これは我々がニュースルーム全体での調査とインタビューを行った2番目のプロジェクトにおいて、我々の購読者となりうるような、多様なバックグラウンドとであり、一般的にコンピューターに対して優れていない、考え深い人たちの意見を入手する素晴らしい方法である。</simpara>
<simpara>*あなたの仕事を見せなさい！我々のフィードバックの多くはアプリケーションで使用されるデータの要求であった。我々はこのデータを一般にAPIで入手可能にした。そして、我々は当初含めようと思っていなかったものを近々公開する予定である。</simpara>
<simpara>&mdash; <emphasis>Brian Boyer, Chicago Tribune</emphasis></simpara>
</section>
<section id="_hospital_billing_病院の請求">
<title>Hospital Billing （病院の請求）</title>
<simpara><ulink url="http://californiawatch.org/">カリフォルニア・ウォッチ</ulink>で調査報道に携わるジャーナリストがある通報を受け取った。それによると、カリフォルニアのある大手チェーン病院で、連邦政府のメディケア・プログラムの抜け穴を利用する行為が行われているかも知れない。メディケア・プログラムは65歳以上のアメリカ人の治療費を肩代わりするもの。疑われているぺてんは、_upcoding_と呼ばれるもので、患者が実際よりも複雑な病状にある、従ってより多額の医療費補助に値する、と報告するものだった。鍵となる情報提供者は病院チェーンの経営側と係争関係にある労働組合で、カリフォルニア・ウォッチのチームは、この話の信用性を担保するには独立した検証が必要だと理解していた。</simpara>
<simpara>幸運なことにカリフォルニア州の保健省は州の病院全てで扱われた患者についての非常に詳細な公的記録を持っていた。128の変数からなるこの記録は世界保健機構の「疾病及び関連保健問題の国際統計分類」マニュアル（一般にICD-9と呼ばれる）に準拠した25の診断コードを含んでいた。データの中では患者の名前は特定されていなかったが、他の変数から患者の年齢、どのように医療費が支払われたか、どの病院で治療を受けたか、などが含まれていた。ジャーナリストたちはこれらの記録があれば、件の病院チェーンが他の病院で見られるよりも有意に高い確率で特定の異常な病状を報告しているかどうかを見ることができると気がついた。</simpara>
<figure id="FIG0318"><title>クワシオルコル（カリフォルニア・ウォッチ）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-AA.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-AA.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>データベースは大規模だった&#8201;&#8212;&#8201;一年当たり400万件近い記録があった。ジャーナリストたちは、各種の傾向が年とともに変動しているかを見るために6年分の記録を分析したかった。彼らはこの記録を州の政府機関に注文した。データはCD-ROMで届けられ、デスクトップPCに簡単にコピーできた。実際のデータ分析を行うレポーターたちは、<ulink url="http://www.sas.com/">SAS</ulink>と呼ばれるシステムを使っていた。SASは非常に強力なツール（何百万件のデータの分析もできるもの）で、カリフォルニア州の保健省を含め多くの政府機関にも利用されていたが、高価だった。同じような分析はマイクロソフト・アクセスやオープンソースの<ulink url="http://www.mysql.com/">MySQL</ulink>などほかの様々なデータベースツールでも実施可能だった。</simpara>
<simpara>データを手にし、分析のためのプログラムを書くと、怪しい傾向を見つけ出すのは比較的シンプルだった。たとえば、告発のひとつは、さまざまな程度の栄養不良をこのチェーンが他の病院で見られるよりもかなり高い確率で報告しているというものだった。SASを使うことで、データアナリストはカリフォルニア州にある300以上の急性期の病院のそれぞれで、それぞれの年毎に何件の栄養不良が報告されているかの度数分布表を作成することができた。この度数分布表をマイクロソフト・エクセルにインポートして、各病院のパターンを詳細に調べた。エクセルのソート機能と、確率計算の機能を使えば、パターンを見ることは簡単だった。</simpara>
<simpara>特に衝撃的だったのは、クワシオルコルと呼ばれるたんぱく質欠乏症の一種で、これは、ほとんど飢饉に見舞われた途上国の飢えた乳幼児にだけ見られるものだ。ところが、このチェーンはクワシオルコルをカリフォルニアの高齢者について診断している率が<ulink url="http://bit.ly/californiawatch-malnutrition">州の全病院平均</ulink>の70倍の高率に上っていた。</simpara>
<simpara>他の記事のために、データ分析では似たようなテクニックを用いて<ulink url="http://bit.ly/californiawatch-rare">敗血症、 脳症、 悪性高血圧、 自律神経失調症のような病状</ulink>の診断率を検証した。そしてもうひとつの分析では、 緊急救命室から<ulink url="http://bit.ly/californiawatch-chains">異様に高い率のメディケアの対象患者</ulink>を受け入れているという告発について検証した。メディケアの対象患者は他の緊急救命室の患者と比べて治療費を支払えることがより確実だという事情がここにはある。</simpara>
<simpara>まとめると、このような記事は、固有の目的を持っているかも知れない情報提供者からの告発について、データを使うことで独自に検証するための証拠を生み出すことで可能になります。このような記事は、公的記録に関する強力な法律の必要性の好例にもなっています。政府がこのようなデータの報告を義務付けている理由は、これを政府なり、学者なり、調査官なり、市民ジャーナリストなりがこういった分析ができるようにすることにある。このような記事の扱う主題は、何百万ドルもの公的な資金がきちんと使われているかどうかを検討するものなので、重要である。</simpara>
<simpara>&mdash; <emphasis>スティーブ・ドイグ アリゾナ州立大学ウォルター・クロンカイト・ジャーナリズム・スクール</emphasis></simpara>
</section>
<section id="_ケアホームの危機">
<title>ケアホームの危機</title>
<simpara><ulink url="http://on.ft.com/care-home-crisis">フィナンシャルタイムの介護ホーム市場の調査</ulink>はどのように一部の投資家たちが老人介護を投資の機会に変え、良質な介護の元に投資回収可能なビジネスモデルとしての厳しい人件費について強調した。</simpara>
<simpara>その分析は、当時国内最大の介護ホーム事業屋であったSouthern Crossの財政問題が頂点に達していたため、とてもタイムリーなものであった。政府は十年間に渡って、介護事業の民営化を推し進め、私的企業の明敏なビジネス慣習を高く評価し続けてきた。</simpara>
<simpara>我々の調査は介護ホームの調査の責任を負う、イギリスの取り締まり当局から入手したデータを分析するところから始まった。情報は大矢加絵にされたいたが、データを使用可能な形式で入手するには多くの努力を必要とした。</simpara>
<simpara>データは個別のホームの能力の評価（現在は無効）とそれらが、民営のものか公的なものか、非営利であるかという詳細情報を含んでいた。CQC（Care Quality Commission）は2010年の6月まで介護ホームを評価していた（星０＝よくない、星３つ＝素晴らしい）。</simpara>
<simpara>CQCによって提供されていたデータは統一されていないカテゴリ情報を含んでいたため、最初のステップでは膨大なデータクリーニングを必要とした。これらは当初は、Excelで処理された。我々は机上であるいは電話調査で個別のホームｈが民営の投資グループによって所有されているかどうかを決定した。金融危機以前は、介護ホーム市場は私的な投資や資産投資家を引き付ける力を持っていた。しかしSouthern Crossのような、いくつかのホーム事業者は深刻な財政問題に陥り始めていた。我々は私的な資産の保有が介護の質にどのような影響を与えるのかを確立することを望んだ。</simpara>
<simpara>簡単なExcelの計算結果により我々は非営利や政府の運営するホームは私的なものに比べて平均で、大きな能力の差があることが立証可能であった。いくつかの民営の資産の保有による介護ホームグループは、平均してよいパフォーマンスを発揮していたし、残りのものは平均を下回っていた。</simpara>
<simpara>現場報告と比べて、支払い能力や離職率のデータのみならず、無視の事例や規則に反する問題の深い調査、我々の分析は高齢者介護の実態を描き出すことを可能にした。</simpara>
<simpara>Some tips:</simpara>
<itemizedlist>
<listitem>
<simpara>
あなたが元のデータをどのように操作したかたの注意書きをとることを守る。
</simpara>
</listitem>
<listitem>
<simpara>
オリジナルのデータを改変せず、元のデータのコピーを維持しておく。
</simpara>
</listitem>
<listitem>
<simpara>
データをダブルチェックする。何度も分析すること（必要であれば最初から）。
</simpara>
</listitem>
<listitem>
<simpara>
もし特定の企業や個人に言及するのであれば返答する権利を彼らに与えること。
</simpara>
</listitem>
</itemizedlist>
<simpara>&mdash; <emphasis>Cynthia O&#8217;Murchu, Financial Times</emphasis></simpara>
</section>
<section id="_the_tell_all_telephone_全てを語る電話">
<title>The Tell-All Telephone（全てを語る電話）</title>
<simpara>携帯電話の提供するデータで実際に何ができるかについてほとんどの人が持っている理解は理論的なものだ&#8201;&#8212;&#8201;現実の例は少ししか存在しない。ドイツの緑の党のMalte Spitzが自分のデータを公開することに決めた理由はそこにある。情報にアクセスするために、彼は巨大な通信会社であるドイチェ・テレコムを相手取って訴訟を起こさなければならなかった。巨大なエクセルのファイルに収納されたデータは、Zeit Onlineのインタラクティブなマップに付随するpassのベースになった。スプレッドシートの35,831行それぞれが、Spitzの携帯電話から半年の期間内に起こった情報の転送をあらわしている。</simpara>
<simpara>個別に見ると、これらの個々のデータはおおむね無害なものだ。だが、まとめて見ると、調査官がプロファイルと呼ぶものになる。個人の習慣や好み、それに彼の生活の、の鮮明な像を提供する。このプロファイルはSpitzがいつ通りを歩き、電車に乗り、飛行機に乗ったかを明らかにする。これはまた、彼が主にベルリンで勤務していることや、他にどの都市を訪問したかを明らかにする。彼がいつ目を覚ましていたか、いつ眠ったかも明らかにする。</simpara>
<figure id="FIG0320"><title>全てを語る電話 (Zeit Online)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-BB.png" scale="93"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-BB.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>ドイチェ・テレコムのデータセットはSpitzのデータ記録の一部を既に非公開にしていた。彼が誰に電話をかけ、誰から電話をもらったかの情報だ。この種の情報は、たとえ電話番号が暗号化されていたとしても、彼の生活に関わる多くの人のプライバシーを侵害する可能性があるだけではなく、Spitzに関してあまりにも多くのことを明らかにしてしまうだろう（だが、現実の世界の政府機関はこの情報へのアクセスができるだろう。）</simpara>
<simpara>われわれはオープン・データ・シティのLorenz Matzat とMichael Kreilに、このデータを扱ってビジュアルな表現方法を見つけてくれるように依頼した。「私たちは最初にエクセルやフュージョン・テーブルを使って、データについて理解を深めました。それから、受け手がデータとノンリニアな形でインタラクションができるようにと、地図インターフェースの開発に入りました。」とMatzatは言った。この保存されていたデータから、どれだけつぶさに彼の生活がマイニングできるかを具体的に示すため、更にここに彼の居場所について公開されている情報（ツイッター、ブログの書き込み、彼のサイトに掲載されている公開活動予定など党の情報）が付け加えられた。これは優秀な調査官であれば観察対象にしている人のプロファイルを得るために用いるような手法だ。 Zeit OnlineのグラフィックスとR&amp;Dチームと一緒になって、彼らはナビげーションのための素晴しいインターフェースを完成させた&#8201;&#8212;&#8201;再生ボタンを押すことで、Malte Spitzの生活を通じた移動を体験することができるようになった。</simpara>
<simpara>ドイツで大きな成功を収めたプロジェクト・ローンチの後、私たちは非常に大きなトラフィックがドイツ国外から来ていることに気がつき、アプリの英語版を作成することに決めました。ドイツ・Grimme・オンライン賞を受賞してから、2011年9月にはこのプロジェクトはドイツのニュース・サイトでは初めてONA賞を受けるという栄誉に浴した。</simpara>
<simpara>全てのデータは、<ulink url="http://bit.ly/zeitonline-data">Google Docsのスプレッドシート</ulink>で閲覧可能である。
この記事を <ulink url="http://www.zeit.de/datenschutz/malte-spitz-data-retention">Zeit Onlineで</ulink>読む。</simpara>
<simpara>&mdash; <emphasis>Sascha Venohr, Zeit Online</emphasis></simpara>
</section>
<section id="_mot不合格車はどのモデル">
<title>MOT不合格車はどのモデル？</title>
<simpara>2010年1月、BBCは異なる工場で生産された異なるモデルの車がMOTテストに合格か不合格かの割合についてのデータを入手した。MOTは、ある車が路上を安全に走行できるかを評価するテストだ。製造から3年以上経過している車は全て、毎年MOTテストを受けなければならない。</simpara>
<simpara>私たちはMOTシステムを監督している運輸省の機関であるVOSAとの長期間の争いの末に情報公開の権利に基づきこのデータをようやく入手した。VOSAはそれらの数字を公開することは業務上の機密保持に違反するかもしれないという理由で、私たちからの情報公開の要求を拒否していた。議論のポイントは、MOTテストに不合格になる割合が高い車の製造業者に「商業的なダメージを与える」かもしれないということだった。そこで私たちは、情報公開が公共の利益のためになるかを決定する情報コミッショナーに訴えた。するとVOSAはようやくデータを公開した。それは私たちが公開を要求してから実に18ヵ月後のことだった。</simpara>
<simpara>私たちは、最も人気のあるモデルの車に注目し製造から同じ年数がたっている車を比較しながらデータの数字を分析した。その結果、車によって大きな差異が見られた。例えば製造後3年以内の車では、ルノー・メガールの28％がMOTテストに不合格になっているが、トヨタ・カローラでは不合格になる割合は11％だった。このデータの数字はテレビ、ラジオ、オンラインで報告された。</simpara>
<figure id="FIG0321"><title>公表されたMOTテストの不合格率（BBC）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-CC.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-CC.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>私たちに与えられたデータは、PDFで1,200ページにおよんだ。私たちは分析のためにそれをスプレッドシートに変換しなければならなかった。そして結論と共に1万4,000行以上におよぶエクセル形式の表をBBCニュースのWebサイト  <ulink url="http://bbc.in/mot-failure-rates[along">http://bbc.in/mot-failure-rates[along</ulink> with our story に掲載した。これによって、誰もが利用しやすい形式のデータにアクセスすることができるようになった。</simpara>
<simpara>その結果、他の人たちがこのデータを使って自分なりの分析を行ってくれた。いち早くこの情報を公表するために、私たちにはそうした分析をする時間がなかった。こうした分析は、場合によっては私たちの技術力を拡張する役目もしてくれた。それには、製造から3年以外の年数が経過している車の不合格率を調査すること、ひとつひとつのモデルではなく製造企業の記録を比較すること、個々のモデルの結果を調べるときに検索できるデータベースをつくることなどが含まれていた。私たちは自分たちのオンラインニュースにそうしたサイトへのリンクを掲載し、読者がこうした分析から利益を得られるようにした。</simpara>
<simpara>このことは、データに基づく話に付随する未加工データを公表することが持ついくつかの利点を良く説明している。他の追跡調査のために後でデータ使うことを計画していてし、ばらくの間それを公表しないでおきたい場合などの例外はあるだろうが、全体的にはデータを公開することはいくつかの重要な利点を有している。</simpara>
<itemizedlist>
<listitem>
<simpara>
あなたの作業は物事を調査してその結果を人々に伝えることだ。全てのデータを入手するのに困難が生じたときにはその作業を誰かに譲ることもあなたの作業の一部だ。
</simpara>
</listitem>
<listitem>
<simpara>
あなたが見逃していた、あるいは単純にあなたの話で取り扱うほど重要ではなかったが、他の人たちにとっては重要な利益である事柄を他人が指摘してくれることもあるかもしれない。
</simpara>
</listitem>
<listitem>
<simpara>
データをより詳細に分析したり、数値を異なった技術を使って示したりビジュアル化するなど、他の人たちがあなたの作業をさらに進めることもできる。他の人たちのアイディアや技術を使って行われるこうした作業は、また別の生産的な方法でデータを調査することになるだろう。
</simpara>
</listitem>
<listitem>
<simpara>
これは、ジャーナリスティックなプロセスに説明責任と透明性を与えるものだ。他の人たちはやろうと思えばあなたの方法とあなたの作業を理解することができるようになる。
</simpara>
</listitem>
</itemizedlist>
<simpara>&mdash; <emphasis>Martin Rosenbaum, BBC</emphasis></simpara>
</section>
<section id="_アルゼンチンにおけるバスの補助金">
<title>アルゼンチンにおけるバスの補助金</title>
<simpara>アルゼンチンにおける公共のバス輸送システムに対する補助金の額は、2002年以降は毎年の最高額を更新しながら急増し続けている。しかし2011年、選挙での勝利の後、アルゼンチン政府は同年12月から公共サービスに対する補助金を削減することを宣言し、それと同時に中央政府は地方のバスと地下鉄の管理をブエノスアイレス市政府に移行することを決定した。しかし、地方政府へ補助金が移行するのかが明らかにされておらず、また運送システムの安全を保証するための資金も不十分だったことから、ブエノスアイレス市政府はこの決定を却下した。</simpara>
<simpara>この事態を受けて、私はLa Naciónで働いている仲間と初めて会い、私たちのデータジャーナリズム活動をどのように始めればよいかを話し合った。経済部門担当の編集者は、 <ulink url="http://www.transporte.gov.ar/">Secretaría de Transporte</ulink>（運輸省）で公開されている補助金のデータから始めたらよいのではないかと提案してくれた。というのも、データの形式や専門用語のためにそれを理解するのはとても難しかったからだ。</simpara>
<simpara>公共輸送システムの不便さは、毎日580万人もの乗客の生活に影響を与えている。遅延やストライキ、故障、おまけに事故もよく起こる。私たちは、アルゼンチンの公共輸送機関に対する補助金がどこへ渡っているのかを調査して、現在開発中の「輸送機関に対する補助金のエクスプローラー」によってそのデータに簡単にアクセスできるようにしようと決めた。</simpara>
<figure id="FIG0322"><title>輸送機関に対する補助金エクスプローラー (La Nación)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-LL-01.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-LL-01.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>私たちはバス会社が政府から毎月どのくらいのお金を受け取っているのかを計算することから始めた。そのために、私たちは <ulink url="http://www.transporte.gov.ar/content/subsidios-sistau/">運輸省のWebサイト</ulink> で公表されている、PDFで400ページを越えるデータを調査した。そこには、2006年以降の1300社以上に対する毎月の支払い金額が掲載されていた。</simpara>
<figure id="FIG0323"><title>補助金をもらっている運送会社のランキング(La Nación)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-LL-02.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-LL-02.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>私たちはスクレイパー（Webページから情報を取り出すプログラム）を開発する専門のプログラマーとチームを組んだ。それは、データの常時ダウンロードを自動化し、PDF形式のデータをエクセルやデータベース形式のファイルに変換するためだ。私たちが使用しているのは、印刷物やオンラインで提供されている自分たちで調査や可視化した28万5,000以上の記録を含むデータ・セットだ。それに加えて、私たちはこのデータを全てのアルゼンチン人が再利用やシェアできるように、コンピュータで読み取れる形式に直している。</simpara>
<simpara>次のステップは、公共の輸送車両を1ヶ月維持するのに政府は1台あたり平均してどれだけの支出をしているのかを特定することだった。そのために私たちは別の政府機関のWebサイトを閲覧した。それは、アルゼンチンの輸送関連の規制に責任を負っている  <ulink url="http://www.cnrt.gov.ar/index2.htm">国家運輸規制委員会</ulink>（CNRT） だ。このWebサイトに掲載されているバス会社が所有している車両は全部で9,000台だ。私たちはバス会社の名前を一致させ2つのデータ・セットを串刺し検索できるようにするためのノーマライザーを開発した。</simpara>
<simpara>調査を進めるためには、それぞれの車両の登録ナンバーが必要だった。CNRTのWebサイトには、ライセンスプレートと一緒になった会社ごとかつ路線ごとの車両のリストが掲載されていた。アルゼンチンの車両登録ナンバーは車両の製造年と文字と数字で構成されている。例えば、私の車の登録ナンバーはIDF234だ。「I」は、2011年の3月‐4月を表している。私たちは会社ごとのバスの平均的な使用年数を突き止めるために、この仕組みを逆転させて、リストに掲載されている全ての会社が所有しているバスのライセンスプレートを割り出した。そうすることで、それぞれの会社にどのぐらいのお金が流れているかを示し、車両の平均的な使用年数に基づく金額を比較できるからだ。</simpara>
<simpara>その課程の途中で、私たちが必要とするデータが含まれている政府が公表したPDFの内容が変更された。不思議なことに、ファイルの名前やURLはそのままだった。いくつかのPDFは今でも縦の「合計」が記載されていない状態のままだ。それによって2002年から2011年の調査全体が照合できなくなってしまっている。</simpara>
<simpara>私たちはこの事例をボストンのハッカー達が組織しているハッカソンに持ち込んだ。そこでは開発者のマット・ペリーが気前よく「PDF Spy」と呼ばれるものを作ってくれた。このアプリケーションは、そのハッカソンで最優秀賞を獲得した。 <ulink url="http://gristlabs.com/2011/09/24/pdfspy/">PDF Spy</ulink> は、Webページに掲載されているPDFを探してPDFの内容に変更があったかどうかをチェックしてくれる。マット・ペリーは「政府の言う”透明性”に決して騙されるな」と書き記している。</simpara>
<figure id="FIG0324"><title>政府から受け取っている金額に対する車両の年数の比較(La Nación)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-LL-03.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-LL-03.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>====プロジェクトの参加者</simpara>
<simpara>ジャーナリスト7名とプログラマーたちそしてインタラクティブ・デザイナー1名のチームで、13ヶ月かけて実行した。</simpara>
<simpara>このプロジェクトで必要とされた職業は以下の通りだ。</simpara>
<itemizedlist>
<listitem>
<simpara>
公共輸送システムに対する補助金の働きとそのリスクそしてバス会社の市場について熟知しているジャーナリスト。
</simpara>
</listitem>
<listitem>
<simpara>
データを解体、解析、標準化し、PDFから抽出してエクセルのスプレッドシートにする技術を持っているプログラマー。
</simpara>
</listitem>
<listitem>
<simpara>
データを分析し何通りかの異なった計算ができる統計学者。
</simpara>
</listitem>
<listitem>
<simpara>
インタラクティブなデータのビジュアル化ができるデザイナー。
</simpara>
</listitem>
</itemizedlist>
<simpara>====使用したツール</simpara>
<simpara>アプリケーションに対してはVBasicを、RailsにはRUbyとともにExcel Macros、Tableau Public、そしてJunar Open Data Platformを、またSubsidies ExplorerにはGoogle charts APIとMysqlを使用した。</simpara>
<simpara>このプロジェクトの影響はとても大きかった。私たちのサイトは数え切れないほどたくさんの人に閲覧され、調査はLa Naciónの紙版で注目記事としてトップページに掲載された。</simpara>
<simpara>この最初のデータジャーナリズム活動の成功は、私たちが対内的に調査報道をカバーし公衆にサービスを提供するようなデータ操作を確立するための事例を作る役に立った。その結果が、Data.lanacion.com.ar というプラットフォームだ。私たちはそこで、公共の利益に関わるさまざまなトピックについてのデータを、コンピュータで読み取れる形式で公開している。</simpara>
<simpara>&mdash; <emphasis>Angélica Peralta Ramos, La Nación (Argentina)</emphasis></simpara>
</section>
<section id="_市民データレポーター">
<title>市民データレポーター</title>
<simpara>データに裏打ちされた記事は、大きな報道機関からのみ生み出されるわけではない。そのようなスキルは、市民ジャーナリストが彼らの地元に関するデータにアクセスし、記事を書くことにもつながる。</simpara>
<simpara>これは、<ulink url="http://amigosdejanuaria.wordpress.com/">Friends of Januária（ジャヌアリアの友）</ulink> というブラジルの市民メディアプロジェクトが始まったきっかけでもある。このプロジェクトは、<ulink url="http://rising.globalvoicesonline.org/">Rising Voices（声を上げよう） </ulink>からの助成金を受け、  <ulink url="http://globalvoicesonline.org/">Global Voices Online（世界の声オンライン）</ulink>のアウトリーチ事業となり、さらには <ulink url="http://www.article19.org/">Article 19（アーティクル19）</ulink>の特別なサポートを受けた。ブラジルのもっとも貧しい地域の一つであるミナイス・ジェライス州北部の小さな町ジャヌアリアに住む若者たちは、2011年の9月から10月にかけて、基本的な編集技術と予算モニタリングの手法についてのトレーニングを受けた。また彼らは情報公開請求の作り方と、インターネット上の公的データベースにある公共の情報へアクセスする方法についても学んだ。</simpara>
<simpara>およそ6.5万人ほどの住民しか持たないジャヌアリアは、地元の政治家選びにおいて失敗した町として知られている。3、4年の間に7人もの市長を生み出したからだ。彼らのうちのほとんどは、汚職を含む行政上の誤ちによって職を追われた。</simpara>
<simpara>ジャヌアリアのような小さな町は国内メディアからの注目を集められていないことが多い。メディアはより大きな町や州都へ注目しがちだからだ。しかし、小さな町の住民にも、行政モニタリングを通じて結託することでより大きな力を生み出すチャンスがある。なぜなら、地元の日々の変化に直面しているのはほかの誰でもない彼らだからだ。インターネットを使用すれば、住民は以前に比べて容易に予算やそのほかの地元に関するデータへアクセスすることができるようになった。</simpara>
<figure id="FIG0325"><title>市民メディアプロジェクト、ジャヌアリアの友は、住民がデータジャーナリストになる手法を伝授した。</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-XX.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-XX.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>12回にわたるワークショップの後、ジャヌアリアの友から生まれた新たな市民ジャーナリストたちは、小さな町の公共データが公になることでどのような状態を導くことができるかを身をもって明らかにした。例えば、22歳の市民ジャーナリスト ソラリア・アモリムは、連邦政府のデータから、町から給与を得る医者が何名いるかを読み取り、記事にした。しかし、その数字は市の実態にそぐわないものであった。この記事を書くために、ソラリアはSUS (Sistema Único de Saúde or Unique Health System)のWebサイト <ulink url="http://bit.ly/tabnet-datasus">http://bit.ly/tabnet-datasus</ulink> にある、人口に応じて無償の医療プログラムを提供する連邦政府のプログラムに関するデータにアクセスした。これによると、ジャヌアリアには様々な分野の専門家を含む71名の医者が必要であった。</simpara>
<simpara>SUSデータからはじき出された医者の人数は、ソラリアが知るその地域のものとは一致しなかった。住民はいつも医者の少なさを嘆いていたし、中には診察を受けるためにほかの地域へわざわざ通わなければならない患者もいた。のちに、彼女はある女性にインタビューを行った。その女性は最近オートバイの事故にあったにも関わらず、医者がいなかったがためにジャヌアリアの病院で診療を受けることができなかった。彼女は町の保健所にも話を聞いたが、彼らはジャヌアリアにはSUSのデータに比べ医者の数が少ないということを認めるだけだった。</simpara>
<simpara>はじめの発見を皮切りに、公的な情報と町の実情との間に生じる違いについて疑問の声が多く上がった。そのうちのひとつは、連邦政府のデータが間違っているのではないか、つまりブラジルの健康に関する情報には深刻な欠陥があるのではないかというものだった。もうひとつの可能性は、ジャヌアリアの町からSUSへの報告が正しくないのではないかというものだ。どちらの可能性についても、正確な答えを導くためには更なる調査を必要とする。しかしソラリアの記事はこの一連の流れを導く大きな役割を果たした。矛盾を浮き彫りにし、ほかの人たちがこの問題についてより多くを知ろうとするきっかけになったからだ。</simpara>
<simpara>「私は田舎に住んでいたので、高校を卒業するのがとても大変だったんです」ソラリアは言う。「人生においてやり遂げたいことを聞かれた時には、いつもジャーナリストになりたいと答えていました。でも私とジャーナリストでは住む世界が違いすぎて、きっと無理なんだろうなと思っていました。」ジャヌアリアの友のトレーニングを受けてからというもの、データにアクセスすることは町の現実を変える重要な手段の一つだと考えてている。「今私は町や国や世界を変える一助になれるって感じているわ」彼女は加えた。</simpara>
<simpara>もうひとり、20歳のアリソン・モンティエリトンもまた、このプロジェクトから生まれた市民ジャーナリストで、データを使って記事を書いた一人だ。最初の授業の、題材を探して町を歩き回るという課題の中で、彼はある大きな交差点にある信号が年初に壊れたまま放置されていることについて記事を書くことを決めた。インターネットからデータを探す方法について学んだあと、彼は町にある車両の数と、車の保有者から得られる税金の額について調べた。彼は次のように記事を書いた：</simpara>
<blockquote>
<simpara>車両の数が増えてしまい、ジャヌアリアの状況は悪化している。IBGE（ブラジルで最も重要な研究所）によると、2010年にジャヌアリアにあった車両の台数は13,771（そのうちの7,979はオートバイ）であった。住民は信号修理の遅れは資金不足によるものではないと考えている。ミナス・ジェライス州の財務省によると、町は2010年に47万レアルもの車両税を得ているからだ。</simpara>
</blockquote>
<simpara>データにアクセスすることによって、アリソンはジャヌアリアがどれほど多くの車両を保有しているか（ほぼ5人に1台の割合だ）、そして信号機を壊れたままにしておくことが多くの住民を危険にさらしているということを明らかにしてみせた。彼は記事の読者に、車の保有者から町が得ている税金の額を知らせ、この額は信号を修理しドライバーや歩行者を危険から守るのに十分な額ではないか、と問いかけた。</simpara>
<simpara>ソラリアとアリソンによって書かれた記事はとてもシンプルなものではあるが、彼らは市民ジャーナリストにとってデータがどれほど有益なものかを示した。ジャーナリストになるには、記事を作成するためにデータを操る専門家を多数有することのできるような大きな報道機関に所属する必要はない。12回のワークショップによって、ソラリアとアリソンは、編集や報道に関する経験を持っていなかったにも関わらず、データに裏打ちされた、地元の状況に関する興味深い記事を書くことができたのだ。</simpara>
<simpara>&mdash; <emphasis>アマンダ・ロッシ、ジャヌアリアの友</emphasis></simpara>
</section>
<section id="_選挙結果を示す_ビッグボード">
<title>選挙結果を示す「ビッグボード」</title>
<simpara>選挙結果は、あらゆる報道機関にヴィジュアルでストーリーを伝える機会を与えてくれるが、長い間、このような機会は逃されてきた。2008年、われわれとグラフィック担当デスクは、それを変えるために着手した。</simpara>
<simpara>われわれは、ストーリーを伝え、図や地図に数字の寄せ集めるだけではない選挙結果を見せる方法を探し出したかった。前回の選挙で、<ulink url="http://nyti.ms/senate-2">われわれ</ulink> が <ulink url="http://nyti.ms/senate-3">行った</ulink> <ulink url="http://nyti.ms/senate-1">こと</ulink> がまさにそうだった。</simpara>
<simpara>大量の数字があることは必ずしもよいことではない。いわゆる、われわれが「CNNモデル」と呼んでいた図表ばかりのものだ。それはつまり誰が勝ったのかという、読者がまさに知りたいことを提供していたため、機能した。</simpara>
<simpara>そして、根本的に壊れたものをこねくり回す危険性が顕著だった。徹底的に違うこと行い、人々の期待から離れることで、われわれは少なくとも物事をより混乱させる可能性があった。</simpara>
<simpara>最後に、正答を思いついたのは、グラフィック担当デスクのシャーン・カーターだった。われわれが最終的に<ulink url="http://nyti.ms/board-elections">「ビッグボード」</ulink> と呼ぶことになったものだ。わたしが最初にモックアップを目にしたとき、文字通り頭をたたかれたような瞬間だった。</simpara>
<simpara>それはまさに正しかった。</simpara>
<figure id="FIG0326"><title>選挙結果を示すビッグボード（ニューヨーク・タイムズ）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-ZZ-ZZ.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-ZZ-ZZ.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>どうしてこのビジュアル・ジャーナリズムは素晴らしいものになったのか？まず、読者がすぐにトップにある、選挙人投票を表した大きなバーに目をやる。ジャーナリズムの文脈では、（記事の）リードと呼ぶものだ。それは、読者が知りたかったことを、早く、シンプルに、ビジュアルのノイズなしに、まさに伝えたということだ。</simpara>
<simpara>次に、読者が見るのは、ニューヨーク・タイムズが候補者がどの州を勝ち取りそうかをどのように感じているのかによって構成された、下にある5つの縦列のグループだ。真ん中の列にあるのは、ジャーナリズムの文脈で言うナットグラフと呼ぶものだ。ここでは、なぜオバマが勝つのかということを説明している。そのインタラクティブを見れば、オバマが勝ちたい州のすべてを取り、5つの五分五分の州のうち4つをとるということが明確に分かる。</simpara>
<?dbfo-need height="1in"?>
<simpara>わたしにとって、この5つの縦列構造は、ビジュアル・ジャーナリズムがほかのデザイン形式とはどれだけ異なるかの例だ。理想的には、ビジュアル・ジャーナリズムの素晴らしい作品は、美しくもあり、情報量が多いものになるだろう。しかし、ストーリーか美学のどちらかを決めるとき、ジャーナリストはストーリーが過ぎるに違いない。そして、このレイアウトは、純粋なデザイナーがデータを提示するのに選択する方法ではないかもしれない一方で、それはストーリーをとてもよく伝えます。</simpara>
<simpara>そして最後に、あらゆるウェブのインタラクティブのように、この作品も読者をいっそう深く誘い込む。そこには、ストーリーのメイン部分と競り合わないように、州ごとの投票率や選挙人の数、そしてわざと軽視された割合の報道のようなディテールがある。</simpara>
<simpara>これらすべてによって、「ビッグボード」が、ほとんど完璧に間違いなく確実な逆ピラミッドを描いた、ビジュアル・ジャーナリズムの偉大な作品となった。</simpara>
<simpara>&mdash; <emphasis>アロン・ピルホーファー（ニューヨーク・タイムズ）</emphasis></simpara>
</section>
<section id="_crowdsourcing_the_price_of_water_水の価格のクラウドソーシング">
<title>Crowdsourcing the Price of Water (水の価格のクラウドソーシング)</title>
<simpara>2011年の3月からクラウドソーシングの新しい実験として、水道料金の情報収集がフランス全土で行われている。たった４ヶ月の間に、5,000を超える人がわざわざ水道料金の請求書を探し、スキャンし、<ulink url="http://www.prixdeleau.fr/">Prix de l&#8217;Eau</ulink> (水道料金) プロジェクトにアップロードし、水市場の企業支配に関する情報を提供した。結果として、水道事業周辺の透明性を改善するためにギーク、NGO、伝統的なメディアを団結させた、前例のない調査になった。</simpara>
<figure id="FIG0327"><title>The Price of Water (Fondation France Liberté)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/03-WW.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/03-WW.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>フランスの水道市場は10,000 を越える顧客（納税者に分配するための水を購入している市）とほんの一握りの公共事業会社から成っている。この寡占状態では、パワーバランスが歪み、企業に有利になっている。そして企業は時々、隣接した町に異なる価格を請求しているのだ！</simpara>
<?dbfo-need height="1in"?>
<simpara>フランスのNGO団体 France Libertés は過去２５年間、世界規模で水の問題に取り組んでいる。France Libertésは現在、フランス市場の透明性を改善すること、そして市民と水道事業の契約を交渉する町長・市長を力づけることに、重点的に取り組んでいる。フランス政府は問題に取り組むことを２年前に決断し、水の価格と品質の国勢調査を行っている。これまでに、3%のデータだけが集まった。速度を上げるために、<ulink url="http://www.france-libertes.org/">France Libertés</ulink> は直接市民を巻き込むことを望んだ。</simpara>
<?dbfo-need height="2in"?>
<simpara>OWNIチームと一緒に私は、ユーザーが水の領収書をスキャンし彼らが払った水道料金を入力するクラウドソーシングのインターフェースをprixdeleau.fr (price of water)上に設計した。過去４ヶ月間で8,500人がサインアップ（登録）し、5,000 通の領収書がアップロードされ、領収書が正当であることが確認された。</simpara>
<simpara>これは市場状況に関する完全な評価を可能にはしていないが、水道料金に対して誠実かつ草の根的な関心が存在していることを利害関係者、例えば国営の水監視団体に示した。彼らは初め透明性について懐疑的であった。しかし一連の活動を経て、不透明性と企業の過誤と戦うFrance Libertésへ積極的に参加するように、彼らは心を変えた。報道機関は、これから何を学ぶことができるのか？</simpara>
<variablelist>
<varlistentry>
<term>
NGOとパートナーを組め
</term>
<listitem>
<simpara>
  NGOは政策文書を策定するために大量のデータを必要とする。彼らは、新聞社の重役ではなく、データの収集作業に対してならば多額の出費をいとわない。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ユーザは生データを提供できる
</term>
<listitem>
<simpara>
  ユーザがデータ収集かデータの洗練作業が出来る場合に、クラウドソーシングは最もうまく機能する
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
情報源を尋ねろ
</term>
<listitem>
<simpara>
  我々は、ユーザーにオリジナルの領収書のスキャンを頼むことはいくらかのユーザー（特に、我々の目標とする読者は平均より年を取っているので）の参加を思いとどまらせるだろうと考え、ユーザーにオリジナルの領収書のスキャンを頼むかどうか熟考した。ユーザーにオリジナルの領収書のスキャンを頼むことは幾人かを遠ざけたかもしれないけれど、データの信頼性を上げた。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
検証の機構を立ちあげろ
</term>
<listitem>
<simpara>
  我々は点数制度と、ユーザーの投稿を入念に検査するピア・レビューの機構を設計した。これは、ウェブサイトに繰り返し訪問する気があまりないユーザーには、とても複雑であった。これはFrance Libertés teamで使われたが、ポイントシステムに動機づけられたと感じたのは10かそこらの従業員だけだった。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
簡潔にしろ
</term>
<listitem>
<simpara>
  我々は、たった2・3回のクリックで、ユーザーが水の価格付けに関する情報公開請求を出願できるように、自動メールシステムを構築した。これは革新的で良く設計されていたが、この機能は十分な投資利益率を提供しなかった。（100個の要求だけが送られた。）
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
読者を目標にしろ
</term>
<listitem>
<simpara>
  France Libertésは、消費者権利に関する新聞60 Millions de Consommateursと手を組んだ。60 Millions de Consommateursは彼らの団体を大々的に巻き込んだ。これはこの計画に対して完全に合っていた。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
主要業績評価指標（KPI）を注意深く選べ
</term>
<listitem>
<simpara>
  この計画は４ヶ月間で45,000人の訪問者を集めた。45,000人は<ulink url="http://www.nytimes.com/">nytimes.com</ulink> の15分のトラフィックに相当する。本当に大事なことは、5人1人が登録し、10人に1人が彼／彼女らの領収書をスキャンし、アップロードする時間を取ることだった。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>&mdash; <emphasis>Nicolas Kayser-Bril, Journalism++</emphasis></simpara>
</section>
</section>
<section id="getting_data">
<title>データを取得する</title>
<informalfigure role="informal">
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-00-cover.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-00-cover.png</phrase></textobject>
</mediaobject>
</informalfigure>
<?dbfo-need height="1in"?>
<simpara>最初のデータジャーナリズムプロジェクトに取り掛かる準備ができた。最初に必要なのは、ちょっとしたデータである。このセクションは、どこからデータを手に入れるかを見ていく。ウェブ上からデータを探す方法、情報公開に関する法律の下にデータを請求する方法、体系化されていないソースからスクリーン・スクレイピングを用いてデータを集める方法、読者からデータセットを集めるためにクラウドソーシングを用いる方法について学ぶ。最後に、データセットを再配布することに対し法律が何を言っているか、また他者にあなたのデータを利用可能にさせるための簡単な法的手段について見ることにする。</simpara>
<section id="_5分でわかるフィールドガイド">
<title>5分でわかるフィールドガイド</title>
<simpara>特定のトピックや議論に関するデータを探している？実際にどんなデータがあるか、それをどこで見つけたらいいかわからない？何から手をつければいいか分からない？この節では、Web上に公開されているデータの情報源を見つけるための方法を見ていく。</simpara>
<section id="_検索を効率化する">
<title>検索を効率化する</title>
<simpara>いつも見つけやすいとは限らないが、ウェブ上の多くのデータベースは、公開した本人が望むと望まざるとにかかわらずサーチエンジンにインデックスされている。それを探すためのいくつかのヒントを紹介しよう。</simpara>
<literallayout class="monospaced">・データを探すときは、検索結果として得られるべきデータのフォーマットや情報源を想定して、データの「コンテキスト」も検索クエリに含むようにしよう。Googleや他のサーチエンジンはファイルタイプでの検索ができるようになっている。例えば、スプレッドシートだけを検索する場合は、検索クエリに‘filetype:XLS filetype:CSV'を追加すればいい。同様に、地図データには‘filetype:shp'、データベースから抽出されたデータには‘filetype:MDB, filetype:SQL, filetype:DB'を追加する。もし、そういう気分になったなら、PDFファイルだけを探す（‘filetype:pdf’）ことも可能だ。
・URLの一部で検索することもできる。Googleで‘inurl:downloads filetype:xls’を使えば、URLに“downloads”を含むすべてのExcelファイルを見つけることができる。（もし、ひとつのダウンロード元フォルダが見つかったら、そのサーバの同じフォルダに別のデータが見つかることもよくある。）また、検索結果を特定のドメインに限定することもできる。例えば、‘site:agency.gov’のように。
・もう一つ人気のあるトリックを。データそのものを直接探すのではなく、データが固まって置かれている格納場所を見つける方法がある。例えば、‘site:agency.gov Directory Listing’という検索クエリでは、Webサーバが生成したディレクトリの中身のリストを手に入れることができるので、生データのファイルに簡単にアクセスできる可能性がある。また、‘site:agency.gov Database Download’という検索クエリは、人間が作成したリストを見つけようとする。</literallayout>
<?dbfo-need height="2in"?>
<simpara>.</simpara>
<sidebar>
<simpara>公的団体によって保持されているデータを手に入れるため、私が使う方法のひとつめは、広報担当者でなく、情報公開法を通じてでもなく、データの保持者のところに直接行くことである。もちろん、法に基づいた手段や、公的記録の請求を行うこともできるが、それでは事が動くのに時間がかかる。請求したのと違うフォーマットでのレスポンスを受け取ったり、（いくつかのケースで起きたことだが）独自仕様のソフトウェアを行政体が使っていて、指定したフォーマットに展開できないことになりがちである。しかし、もしその機関のためにデータを管理している人に最初に上手く辿り着くことができれば、そのテーマに関してどんなデータを、どのように持っているかについて質問することができる。フォーマットを知ることができる。データに関する専門用語を使うこともできるし、データをうまく請求するにあたって知っておくべきこともわかる。このアプローチの問題点、それは多くの場合、こういった人物に辿り着くことが難しいことである。広報官は、私に彼らとやりとりをするように求めるだろう。このようなケースの場合、広報官、データの権威者、そして私の三者間で電話会議をしたり、あわよくば直接ミーティングを実施する機会を設けるのが最善である、と私は知っている。さらに私は、彼らが断らない方法でその機会をセットすることができる。「彼らに負担をかけたくないんです」「不要に負担になったり、無駄に広い請求をしたくありません。どんなデータがあるかを理解し、欲しいものをどのようにリクエストすべきか、ミーティングをすることで私の理解が助けられるのです」</simpara>
<simpara>もしこの方法が上手く行かなかったら、私の頼みの綱はリクエストにあるレコードのレイアウトとデータディレクトリについて質問をすることだ。それから、実際にデータをリクエストする。彼らがどんなシステムの中で、どうデータを保持しているかについて、私は最初に質問する。そうすることで、リクエストをする前に、データをどのようにエクスポートさせるか、調査することができるのである。</simpara>
<simpara>最後に、モンタナの小さな新聞社で働いていたときの成功談である。私は郡のデータが欲しかったのだが、それはメインフレームからエクスポートできないと言われたものだった。私は少し調べて、協力と手助けを申し出た。データの専門家と協力し、私達は短いスクリプトを準備し、フロッピーディスク（これはかなり前の話だ）にデータを書き出した。私はデータを得て、郡は誰にでも必要とあらばデータを渡せるようになったのである。彼らはそのようなことを意図していたわけではなかったが、彼らも時々データを展開することが必要であったし、システムを完璧に理解しているわけではなかったので、私たちは皆で互いに助け合ったのである。</simpara>
<simpara>&mdash; <emphasis>シェリル・フィリップス, The Seattle Times</emphasis></simpara>
</sidebar>
</section>
<section id="_データサイトやサービスを閲覧する">
<title>データサイトやサービスを閲覧する</title>
<simpara>ここ2〜3年でデータ専門ポータル、データハブ、あるいはデータサイトと呼ばれるサイトが数多くWeb上に出現している。これらのサイトは公開されたデータを取得するのに良い場所である。まずは手始めに、下記のサイトを見てみるといいだろう。</simpara>
<figure id="FIG042"><title>datacatalogs.org (Open Knowledge Foundation)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-01.png</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
公式データポータル
</term>
<listitem>
<simpara>
  政府のデータ公開ポリシーは国によって異なる。アメリカのdata.govやイギリスの data.gov.uk などに触発され、データポータルを立ち上げる国は増えている。これは、政府の情報を市民や民間企業が再活用することを促進するためである。datacatalogs.org では、そのようなサイトの最新でグローバルなインデックスを提供している。もう一つの便利なサイトとしては、Guardian World Government Dataがある。これは、多くの国の政府のデータカタログを横断的に検索できるメタサーチエンジンである。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://thedatahub.org/">The Data Hub</ulink>
</term>
<listitem>
<simpara>
  Open Knowledge Foundationによって運営されているコミュニティベースの情報リソースであり、データの発見、共有、再利用を簡単にする。特に、一連のプロセスは機械的に自動化されている。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="https://scraperwiki.com/">ScraperWiki</ulink>
</term>
<listitem>
<simpara>
  ・ScraperWikiは、データの一部を簡単に切り取って抽出するためのツールである。これにより、データをさまざまなアプリで再利用したり、ジャーナリストや研究者がデータを引っ掻き回したりすることができる。ほとんどのscraperWikiや抽出されたデータベースは公開されており、再利用可能である。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>・世界銀行や国連のデータポータルはハイレベルな指標をすべての国に提供している。それらのデータの多くは過去何年にもわたって蓄積されている。
  ・データの共有と再販に関するコミュニティ形成を狙った多くのスタートアップ企業が出現している。これには、Buzzdata（私有や公有のデータセットについて共有したりコラボレーションしたりする場を提供）や、InfochimpsやDataMarketのようなデータショップが含まれる。</simpara>
<variablelist>
<varlistentry>
<term>
<ulink url="http://buzzdata.com/">Buzzdata</ulink>, <ulink url="http://www.infochimps.com/">Infochimps</ulink>, and <ulink url="http://datamarket.com/">DataMarket</ulink>
</term>
<listitem>
<simpara>
  Emerging startups that aim to build communities around data sharing and resale.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://datacouch.com/">DataCouch</ulink>
</term>
<listitem>
<simpara>
  ・データコーチでは、あなたのデータをアップロードし、精錬し、共有＆可視化を行うことができる
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="http://www.freebase.com/">Freebase</ulink>
</term>
<listitem>
<simpara>
  Googleの興味深い子会社であるFreebaseは、「オープンデータを愛するコミュニティによって構築された人、場所、物の相関グラフ」を提供している。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Research data
</term>
<listitem>
<simpara>
  UK Data Archiveのように国や専門家が主導する研究データの集約場所も数多く存在する。多くのデータには無料でアクセスできるが、有償のサブスクリプションが必要だったり、データの再利用ができなかったり、再配布に許可が必要なデータも多い。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<sidebar>
<title>紙のアーカイブからデータを取得する</title>
<simpara>アフガニスタンおよびイラクでの米国軍事書類がウィキリークスによって公開された直後、我々はAlgerian War Diariesを出版することでアルジェリア戦争の50周年を祝うためのコンセプトを適用することに決めた。アルジェリアのフランス軍のアーカイブを集め、デジタル化することをはじめた。ペーパーフォーマットはあるが、パリにある陸軍省のアーカイブで利用可能である。ドキュメントの写真を撮影させるため、ジャーナリストと学生を送り出した。アーカイブの多くはステープラーで綴じられていたので、キヤノンのP-150ポータブルスキャナーを使ったスキャンを試みたものの上手くいかなかった。</simpara>
<simpara>最終的に、数週間でおよそ10,000ページが集められた。テキスト認識のソフトウェア (ABBYY FineReader) を使用したが、ひどい結果しか残らなかった。さらに省は、アーカイブの中の最も興味深い箱へ近づくことを独断的に禁じた。何より、省はその場で自由に撮影することができる書類の再配布を、誰であろうとも禁じたため、我々はそのリスクに見合う価値がないと感じ、プロジェクトを保留状態にすることを決めた。</simpara>
<simpara>&mdash; <emphasis>Nicolas Kayser-Bril, Journalism++</emphasis></simpara>
</sidebar>
</section>
<section id="_フォーラムで質問する">
<title>フォーラムで質問する</title>
<simpara><ulink url="http://getthedata.org/">Get The Data</ulink>や <ulink url="http://www.quora.com/">Quora</ulink> などのフォーラムで既に類似の質問・回答がないか検索してみよう、なければ質問してみよう。GetTheDataはデータに関連したQ&amp;Aサイトであり、特定の話題に関するデータをどこで見つけられるか、特定のデータ源をどうやって検索したらいいか、データを可視化するのにどんなツールを使ったらいいか、データクレンジングやフォーマットをそろえるためにどうすればいいか、などの質問ができる。</simpara>
</section>
<section id="_メーリングリストで質問する">
<title>メーリングリストで質問する</title>
<simpara>メーリングリストは特定のトピックに関するコミュニティ全体の知識の集大成だ。データジャーナリストにとっては、 <ulink url="http:/bit.ly/ddj-list">Data-Driven Journalism List</ulink> や <ulink url="http://bit.ly/nicar-subscribe/">NICAR-L</ulink>  は素晴らしいとっかかりになるだろう。どちらのメーリングリストも参加者はデータジャーナリストかComputer Assisted Reporting (CAR)のギークばかりであり、彼らはあらゆる種類のプロジェクトに関与している。ひょっとしたらあなたが取り組もうとしている話と似たような仕事を既に行なった人がいて、どこからはじめればいいかを教えてくれるかもしれない。もしそうでなくても、データそのものへのリンクを教えてくれるかもしれない。 <ulink url="http://project-wombat.org">Project Wombat</ulink> （リファレンスに関する難しい質問のためのディスカッションリスト）や、<ulink url="http://lists.okfn.org/mailman/listinfo">Open Knowledge Foundation</ulink>や  <ulink url="http://theinfo.org/">theInfo</ulink> のメーリングリストを試してみるのもよい。あるいは調べたいトピックや地域に関するメーリングリストを探してみるのもよいだろう。</simpara>
</section>
<section id="_hacks_hackersに参加する">
<title>Hacks/Hackersに参加する</title>
<simpara><ulink url="http://hackshackers.com/">Hacks/Hackers</ulink> は急速に成長している国際的な草の根のジャーナリズム団体だ。4つの大陸にまたがる数十の支部と数万人のメンバーから構成されている。そのミッションは、ニュースや情報の未来について再考しているジャーナリスト（hacks）と技術者（hackers）のネットワークを作ることだ。そのような広大なネットワークを使えば、あなたは自分が探している情報についてどこを探せばよいか知っている人と出会う確率を高められるだろう。</simpara>
</section>
<section id="_専門家に質問する">
<title>専門家に質問する</title>
<simpara>教授や公務員や民間企業の人たちはしばしばどこを探せばよいか知っている。彼らに電話したり、メールしてみよう。イベントで声をかけたり、彼らのオフィスを訪問しよう。質問は丁寧に。「Xに関する記事を書いているのですが、どこを調べるといいでしょうか。もしくは、誰に聞けばいいか、教えてくださいませんか？」</simpara>
</section>
<section id="_政府のitについて勉強する">
<title>政府のITについて勉強する</title>
<simpara>データにアクセスしようとするとき、政府が保持している情報の技術・管理上の背景を理解しておくことはしばしば助けになる。CORDISであれ、COINSであれ、あるいはTHOMASであれ、大文字の短縮形の名前のデータベースは、その目的を少しでも理解できれば、しばしば最も便利な情報源になる。</simpara>
<literallayout class="monospaced">政府の組織図を探し、分野横断的な機能を持つ部門や課（調査課やITサービス課）を見つけたら、そのWebサイトを見てみよう。多くのデータが複数の部門に保管されており、特定のデータベースは彼らにとって王冠の宝石のように大事にしまってあるかもしれないが、他のデータは無料でくれるかもしれない。</literallayout>
<simpara>政府のサイトでダイナミックなインフォグラフィックスを見てみよう。これらはしばしば構造化されたデータソースやAPIを備えており、自分で動かしてみることができる（フライト追跡アプレットや天気予報のJavaアプリなど）。</simpara>
<sidebar>
<title>通話記録から探す</title>
<simpara>数ヶ月前、私は（当時の大統領候補であった）テキサス州知事のRick Perryの通話記録を解析したいと思っていた。それは待ちに待った州の公的記録のリクエストの結果であった。データは基本的に、120ページ以上に渡るFAX品質のドキュメントの形でやってくる。電話番号の逆引きのため WhitePages.com のAPIを活用したが、それからデータ入力とクリーンアップを必要とする活動であった。</simpara>
<?dbfo-need height="1in"?>
<simpara>Mashing together names with state and federal (FEC) election data, we found that Perry reached out to campaign and super PAC donors <ulink url="http://bo.st/perry-phone">from state work phones</ulink>, a frowned-upon practice that raised questions about ties between him and a &#8220;super PAC&#8221; working in his favor.</simpara>
<simpara>&mdash; <emphasis>ジャック・ギラム, AP通信</emphasis></simpara>
</sidebar>
</section>
<section id="_もう一度検索する">
<title>もう一度検索する</title>
<simpara>前回検索した時には使っていなかったフレーズや単語の組み合わせでもう一度検索してみよう。自分が探していることについて知れば知るほど、検索エンジンで見つかる可能性が高まるかも！</simpara>
</section>
<section id="_情報公開請求を書く">
<title>情報公開請求を書く</title>
<simpara>もし、政府があなたの必要とするデータを持っていることを確信できたら、情報公開請求が一番良い方法かもしれない。請求の方法の詳細は次節で説明する。</simpara>
<simpara>&mdash; <emphasis>Brian Boyer (Chicago Tribune), John Keefe (WNYC), Friedrich Lindenberg (Open Knowledge Foundation), Jane Park (Creative Commons), Chrys Wu (Hacks/Hackers)</emphasis></simpara>
<sidebar>
<title>法律の失敗</title>
<simpara>After reading a <ulink url="http://bit.ly/hygiene-inspections">scholarly article</ulink> explaining that publishing the outcome of hygiene inspections in restaurants reduced the number of food-related illnesses in Los Angeles, I asked the Parisian hygiene services for the list of inspections. Following the procedure set out by the French FOIA, I waited 30 days for their refusal to answer, then went to the Access to Public Data Commission (CADA in French), which rules on the legitimacy of FOI requests. CADA upheld my demand and ordered the administration to release the data. The administration subsequently asked for two months extra time, and CADA accepted that. Two months later, the administration still hadn&#8217;t done anything.</simpara>
<simpara>I tried to get some big-name (and big-pocketed) open data advocates to go to court (which is a €5000 affair and a sure win with CADA support), but they were afraid to compromise their relations with official open data programs. This example is one among several where the French administration simply ignores the law and the official initiatives do nothing to support grassroots demands for data.</simpara>
<simpara>&mdash; <emphasis>Nicolas Kayser-Bril, Journalism++</emphasis></simpara>
</sidebar>
<?dbfo-need height="2in"?>
</section>
</section>
<section id="_データの権利">
<title>データの権利</title>
<simpara>情報公開請求をする前にあなたは自分が探しているデータが既に利用可能でないか、他の人が既に請求済みでないかをチェックしておくべきだ。前章のケーススタディでは、どこをチェックすべきかについての示唆があった。もし、所望のデータを探しても探しても見つからないなら、正式な請求を申請しても良いだろう。ここでは、より効果的に請求できるいくつかのコツを紹介する。</simpara>
<variablelist>
<varlistentry>
<term>
時間を節約するために、あらかじめ計画を立てよう
</term>
<listitem>
<simpara>
  情報を探すことに着手する時はいつでも、正式にアクセス請求を行うことを考えよう。すべての可能性をトライして疲れきってしまう前に。リサーチの最初の段階で請求を行っておき、他の調査を並行して進めることによって、時間を節約することができる。手続きの遅れに備えておこう：お役所で手続きに時間がかかることはあるものだと、ある程度の覚悟をしておいた方が良い。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
料金に関するルールを確認しよう
</term>
<listitem>
<simpara>
  請求を開始する前に、請求や情報の入手にかかる料金に関するルールを確認しておこう。そうすることで、役人があなたに突然お金を要求してきても、あなたは自分の権利を主張できるだろう。あなたは、コピーや郵送のコストを省くために電子文書での受け取りを依頼できる。申請書には電子フォーマットの情報を希望する旨を書いておこう。これで、電子的な情報が存在する限り、料金の発生を防ぐことができる。とはいえ、電子化されていない情報であっても、最近は文書をスキャンすることができるので、それを電子メールに添付して送付することは可能だ。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
自分の権利について知ろう
</term>
<listitem>
<simpara>
  行動を起こす前に、自分の権利について知っておこう。そして、自分の立ち位置がどこで、役所がどんな存在で、何に対して義務を負っていないかを知っておこう。例えば、ほとんどの情報公開法では、あなたの請求に対して当局が返答を行わなければならないタイムリミットが規定されている。世界的に、その期限は数日から1ヶ月の範囲である。請求を行う前に、その国での期限について調べておき、請求した日付を記録しておこう。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>政府はあなたにデータを処理する義務はないが、彼らが持っているデータをすべて与える義務はある。そしてもし、政府の法的能力に照らし合わせた結果、彼らが持っているはずのデータであれば、彼らは確かにそれをあなたに提供する義務があるのだ。</simpara>
<variablelist>
<varlistentry>
<term>
自分の権利について知っていることを伝えよう
</term>
<listitem>
<simpara>
  通常、法的には請求の中で情報公開法について言及する必要はないが、それを行うことをお勧めする。なぜなら、それによって、あなたが自分の法的権利について知っていることを示せるので、その後のプロセスが法律に従って正しく行われる可能性が高まるからだ。特に、EUに対する請求では、法令1049/2001に則った情報アクセス請求であることを明確に記述するのがベストである。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
請求はシンプルに
</term>
<listitem>
<simpara>
  どんな国でも、最初はシンプルな情報請求から始めるのが良い。その後、得られた情報に対して徐々に質問を追加していこう。これによって、「複雑な請求」という理由で公的機関が仕事を先延ばしするリスクを避けることができる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
請求の範囲を明確に
</term>
<listitem>
<simpara>
  役所の一つの部門で所有している情報への請求の方が、役所全体を調べて回る必要がある情報への請求よりも早く回答が得られるだろう。役所が第三者機関（例えば、情報提供を行う民間企業や関連省庁）に問い合わせを行わなければならないような請求は、通常時間がかかるものだ。粘り強くやろう。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>ファイルキャビネットの中を想像してみる
  政府のファイルキャビネットにはどんなデータが並べられているか想像してみよう。例えば、交通事故の後、警察から白紙のフォームを受け取ったら、交通事故に関して警察がどんな情報を取得したり、取得しなかったりしているかを推定できる。</simpara>
<variablelist>
<varlistentry>
<term>
請求は具体的に
</term>
<listitem>
<simpara>
  請求を申請する前に振り返ってみよう：あいまいな部分がないか？異なる自治体や政府組織のデータを比較しようとしている場合は特に重要だ。例えば、「過去3年間」のデータを依頼した場合、ある組織ではカレンダーイヤーで過去3年間のデータを送ってくるかもしれないし、別の組織では年度単位での過去3年分のデータを送ってくるかもしれない。この場合、データを直接比較できなくなってしまう。もし、請求の真の理由を、もっと一般的な理由で隠したい場合でも、請求の範囲が広くなりすぎたり、不明確になりすぎると、役所が対応する気持ちをくじくことになるので、請求の範囲の広さはほどほどにとどめておくべきである。具体的で明確な請求は、より早く正確な回答を引き出せるものだ。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
複数の請求を申請しよう
</term>
<listitem>
<simpara>
  どこに請求を出せばいいのか確信が持てない場合、同時に複数の組織に請求を申請すればよい。場合によっては、複数の組織が異なる回答をくれるかもしれない。その場合、あなたが調査しようとしているテーマについて、より良い全体像を知る助けになるだろう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
海外にも請求しよう
</term>
<listitem>
<simpara>
  請求は電子的に行われることが多くなってきているので、あなたがどこに住んでいるかは関係ない。また、あなたが請求を行いたい国に住んでいなくても、その国の大使館に請求することができるし、大使館はあなたの請求をしかるべき組織に転送しなければならない。まず、関係する大使館にそれが可能かを確認する必要がある。なぜなら、大使館職員は情報公開法について教育されていない可能性があり、その場合は直接、その国の政府や自治体に請求を申請した方が安全だからだ。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
試験的な請求で様子をみよう
</term>
<listitem>
<simpara>
  もし、多くの政府組織に同じ請求を行う場合、最初は試験的に2〜3の組織に対して請求してみよう。これによって、必要なデータを取得するために正しい言葉遣いがなされているか、現実的にあなたの請求に回答することが可能なのかどうかを判定できる。その結果に応じて請求の文書を修正し、改めて対象となる組織全部に送付すればよい。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
例外を予測しよう
</term>
<listitem>
<simpara>
  もし、あなたの請求に対して何らかの例外が適用される可能性があるなら、公にしにくい情報と常識的に例外が適用されない情報を分けて、それぞれ別々に請求を行おう。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ファイルへのアクセスを要求しよう
</term>
<listitem>
<simpara>
  もし、あなたが情報が保持されている組織の近くに住んでいるなら（例：文書が保管されている主要都市）、オリジナルの文書を調べさせてくれるよう、頼むことができる。これは、多くの文書にまたがって記述されているかもしれない情報を調べる時の助けとなる。通常、このような調査は無料であり、あなたの都合の良い時間に行うことができることになっている。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
記録をつけよう！
</term>
<listitem>
<simpara>
  請求のコピーをとって保管しておこう。あとで「確かに請求が行われた」ことを証明したり、「回答が間違っている」ことを主張したりするために。請求のやりとり自体を記事にしようとする場合も、これは証拠となる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
請求を公にしよう
</term>
<listitem>
<simpara>
  あなたが請求を行ったことを公にすることで、回答をスピードアップさせよう。もし、あなたが情報公開請求を行ったことをニュースとして記事にしたり放送したりすれば、政府組織にとってその請求を処理し回答しなければならないというプレッシャーになる。もし請求に対する回答があれば、その情報をアップデートできるし、さもなければ、締め切りを過ぎても回答がなかったことをニュースにできる。こうすることで、国民に対して情報公開法に関する権利と、実際の活用方法を教育することができる。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note>
<simpara>請求に関する一連のやりとりを行ったり、それをweb上で可視化する場合に使える便利なサービスがいくつかある。イギリス政府向けには <ulink url="http://www.whatdotheyknow.com/">What Do They Know?</ulink>  、ドイツ政府向けには <ulink url="https://fragdenstaat.de/">Frag den Staat</ulink> 、EU機関向けには <ulink url="http://www.asktheeu.org/">Ask the EU</ulink> である。また、 <ulink url="http://www.alaveteli.org/">Alaveteli</ulink> プロジェクトは世界の数十カ国で同様のサービスの実現を支援している。</simpara>
</note>
<figure id="FIG043"><title>What Do They Know? (My Society)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-AA.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-AA.png</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
同僚を巻き込もう
</term>
<listitem>
<simpara>
  もし、同僚が情報公開法に懐疑的なら、彼らを説得するためには、情報公開法を通じて得られた情報をベースにした記事を書くことが一番の方法だ。あなたがが書いたり放送したりする記事で情報公開法を利用したことについて触れることは、権利について国民の意識を高め、その価値を強めるという意味でも推奨される。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
生データを要求しよう
</term>
<listitem>
<simpara>
  もし、コンピュータを使ってデータを分析、加工したい場合、電子的で機械が読み込めるフォーマットでデータを提供してもらえるよう明確に請求する必要がある。例えば、予算情報を「会計ソフトによる分析に適したフォーマット」で依頼できる。同様に、ある情報について、「集計前のデータ」や「粒度の細かいデータ」を請求することもできる。この点についての詳細は <ulink url="http://bit.ly/access-report">this report</ulink> を参照。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<?dbfo-need height="1in"?>
<variablelist>
<varlistentry>
<term>
情報公開法が適用されていない組織に関する情報も請求する
</term>
<listitem>
<simpara>
  場合によっては、情報公開法が適用されないNGO、民間企業、宗教団体や他の組織からデータを手に入れたいと思うことがあるかもしれない。しかし、そのような組織であっても、情報公開法が適用されている政府や自治体を通じて情報を入手することは可能である。例えば、政府や内閣が特定の民間企業やNGOに対して投資や取引を行っているかどうかを質問したり、裏づけとなる資料を要求することができる。もし、情報公開請求についてさらなる支援が必要な場合、ジャーナリストのためのWebサイト <ulink url="http://www.legalleaks.info/toolkit.html">Legal Leaks toolkit for journalists</ulink>のツールキットを調べるとよい。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>&mdash; <emphasis>Helen Darbishire (Access Info Europe), Djordje Padejski (Knight Journalism Fellow, Stanford University), Martin Rosenbaum (BBC), and Fabrizio Scrollini (London School of Economics and Political Science)</emphasis></simpara>
<sidebar id="foi-spending">
<title>Using FOI to Understand Spending</title>
<simpara>I&#8217;ve used FOI in couple of different ways to help cover COINS, the UK Government&#8217;s biggest database of spending, budget and financial information. At the beginning of 2010, there was talk from George Osborne that if he became chancellor, he would release the COINS database to facilitate greater transparency in the Treasury. At this time it seemed a good idea to investigate the data in and structure of COINS so I sent a few FOI requests, one for the <ulink url="http://bit.ly/wdtk-coins-1">schema of the database</ulink>, one for the guidance Treasury workers receive when <ulink url="http://bit.ly/wdtk-coins-2">they work with COINS</ulink>, and one for the Treasury <ulink url="http://bit.ly/wdtk-coins-3">contract with the database provider</ulink>. All of which resulted in publication of useful data. I also requested all the spending codes in the database, <ulink url="http://bit.ly/wdtk-coins-4">which was also published</ulink>. All of this helped to understand COINS when George Osborne became chancellor in May 2010 and published COINS in June 2010. The COINS data was used in a number of websites encouraging the public to investigate the data&#8212;including <ulink url="http://openspending.org/">OpenSpending.org</ulink> and the Guardian&#8217;s <ulink url="http://coins.guardian.co.uk/coins-explorer/search">Coins Data Explorer</ulink>.</simpara>
<simpara>After further investigation it seemed that a large part of the database was missing: the Whole of Government Accounts (WGA) which is 1,500 sets of accounts for public funded bodies. I used FOI to <ulink url="http://bit.ly/wdtk-coins-5">request the 2008/09 WGA data</ulink> but to no avail. I also asked for the report from the audit office for WGA&#8212;which I hoped would explain the reasons the WGA was not in a suitable state to be released. That was <ulink url="http://bit.ly/wdtk-coins-6">also refused</ulink>.</simpara>
<simpara>In December 2011, the WGA was released in the COINS data. However I wanted to make sure there was enough guidance to create the complete set of accounts for each of the 1,500 bodies included in the WGA exercise. This brings me on to the second way I used FOI: to ensure the data released under the UK transparency agenda is well-explained and contains what it should. I put in a FOI request for the <ulink url="http://bit.ly/wdtk-coins-7">full set of accounts for every public body included in WGA</ulink>.</simpara>
<simpara>&mdash; <emphasis>Lisa Evans, the Guardian</emphasis></simpara>
</sidebar>
</section>
<section id="_情報公開法を使い倒せ">
<title>情報公開法を使い倒せ！</title>
<simpara>情報公開法を利用することは、素晴らしいツールだ。しかし、それを使いこなすには方法論としばしば粘り強さが必要だ。この節では、調査系ジャーナリストとしての私自身の仕事から、3つのケースを紹介し、情報公開法の利点や課題についてまとめる。</simpara>
<section id="_ケーススタディ1_農業助成金">
<title>ケーススタディ1：農業助成金</title>
<simpara>毎年、EUは約600億ユーロ（7.5兆円）を農業や農業従事者に支払っている。毎年だ。これは、1950年代の終わり頃から始まっている。これまで、政治的には補助金が最も貧乏な農業従事者を救うために必要であると説明されていた。しかし、2004年、このトピックに関する最初の情報公開法の利用がデンマークで行われ、それによって、これがあくまで「説明」でしかないことが明らかになった。小規模農場は公式・非公式の場でしばしば不満を訴えていたように、悲惨な状態でもがいていたが、現実には、補助金の大半は少数の大規模地主や農業企業の懐に入っていたのだ。だから、私が知りたかったのは、「このパターンはヨーロッパ全体に広がっているのか？」だった。</simpara>
<simpara>2004年、私は欧州委員会に対してデータを請求した。毎年2月、欧州委員会はEU各国からデータを集めている。データには、誰がEUのファンディングに応募しているか、受益者はいくらもらっているか、その金の使い道は土地を耕すためなのか、地域開発のためなのか、粉ミルクを輸出するためなのかなどが含まれている。当時、欧州委員会はデータをCSVファイルとしてCDで受け取っていた。データは大量だが、原理的には扱いやすい形式だ。もし、あなたもデータがもらえるなら、CSVがよい。</simpara>
<simpara>2004年の時点で欧州委員会はデータの公開を拒否した。主な理由は、データがデータベースにアップロードされていて、データを引き出すには多大な労力がかかるからということであった。この主張は、欧州のオンブズマン機関から「悪政」と呼ばれている。このケースに関する全ての文書は、wobbing.euのウェブサイトに掲載されている。<ulink url="http://bit.ly/eu-wobbing">on the wobbing.eu website</ulink>. 2004年の時点で、我々には法律にかまっている暇はなかった。我々は、データが欲しかったのだ。</simpara>
<figure id="FIG044"><title>The Farm Subsidy website (Farmsubsidy.org)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-BB.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-BB.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>だから、我々はパートナーとチームを組んでヨーロッパのひとつひとつの国に対してデータを取得しようとした。2005年、イギリス、スウェーデン、オランダのメンバーがデータを取得することができた。フィンランド、ポーランド、ポルトガル、スペインの一部地域、スロベニアなど、他の国々もそれに続いた。ガードの固いドイツでさえ、北ライン-ウェストファリア地方のデータを2007年に提供してくれた。このデータを得るために私は裁判所まで行かなくてはならなかったが --- しかし、Stern紙やSternオンラインのニュースマガジンの記事の良いネタになった。<ulink url="http://bit.ly/stern-wobbing">Stern and Stern online news magazine</ulink>.</simpara>
<simpara>デンマークとイギリスが最初の情報開示国になったのは偶然だろうか？いや、必ずしも偶然とはいえない。より広く政治情勢を考えてみると、当時の農業補助金はWTO交渉の文脈でとらえなければならない。WTO交渉では、補助金はプレッシャーを受けていたのだ。デンマークやイギリスは欧州の中ではリベラル寄りの国である。だから、これらの国では「透明性」の方向に政治的な風が吹いていたのかもしれない。</simpara>
<simpara>この話はここで終わらない。より詳しいエピソードやデータはfarmsubsidy.orgを見て欲しい。<ulink url="http://farmsubsidy.org/">farmsubsidy.org</ulink>.</simpara>
<simpara>教訓：情報公開法を活用しよう。ヨーロッパでは、情報法が定める自由に様々な多様性がある。また、タイミングや国が違えば、政治的興味も違ってくる。この知識を自分に有利になるように活用しよう。</simpara>
<sidebar>
<title>権利を知ろう。</title>
<simpara>データを公表する時、データにある著作権やその他の権利に関して気をもむべきだろうか？法律専門のチームと共に権利に関する問題を常にクリアにすべきでありながら、大雑把に言うと、もしそのデータが政府によって公表されているものであった場合、許可を得ることを求めたり、実際に許可を得る必要はない。もしそのデータがデータを販売していない非営利の団体によって公表されている場合、そんなに用心深くする必要はない。もし、データを販売している営利団体であった場合、絶対にデータ使用の許可を得るべきである。</simpara>
<simpara>&mdash; <emphasis>サイモン・ロジャース、ガーディアン紙(現ツイッター社、データエディター)</emphasis></simpara>
</sidebar>
</section>
<section id="_ケーススタディ2_副作用">
<title>ケーススタディ2：副作用</title>
<simpara>我々はみな、薬をのむときはモルモットだ。薬には副作用がある。我々はみんな、この事実を知っている。だが、潜在的な利益と、潜在的なリスクをはかりにかけて、決定を行っている。ただ不幸なことに、この決定は詳細な情報を得た上での決断ではないことがしばしばある。</simpara>
<?dbfo-need height="1in"?>
<simpara>ティーンネイジャーがにきび予防のピルを飲む時、彼らはきれいな肌を望んでいるのであって、気分が悪くなるとは思っていない。しかしある薬で、まさしくこれが起こったのだ。その薬を服用した若者は憂鬱になり、自殺さえ行った。この副作用の危険性は、ジャーナリストの間ではよく知られた噂だったが、若者は容易にその情報を入手できなかった。</simpara>
<simpara>副作用に関するデータというものが存在する。薬品の製造者は、観測された副作用に関する情報を、定期的に保険機関に報告しなければならない。このデータは、その薬品が市場で認可された時点で、国や欧州当局によって保管される。</simpara>
<simpara>最初のブレークスルーは、またデンマークの国レベルでやってきた。デンマーク、オランダ、ベルギーチームによる国境を越えた調査中に、オランダもデータを公開してくれた。これは、情報公開法の連鎖活用の別の事例だ。オランダ当局に対し、デンマークではデータにアクセス可能であることを指摘することで、我々の調査を大きく前進させることができた。</simpara>
<simpara>しかし、噂は本当だった。ヨーロッパで、その薬品を服用した結果、自殺した若者が数カ国にわたって存在していたのだ。ジャーナリスト、研究者、そして若い被害者の家族はみな、この情報へのアクセスを強く希望していた。欧州のオンブズマンは欧州医薬品庁に対し、透明性を高めるよう働きかけてくれ、これが功を奏した。it <ulink url="http://bit.ly/eu-ombudsman">looks as if he succeeded</ulink>. あとは、ジャーナリストがデータを引っ張り出し、資料全体を分析するだけだ。ある研究者が言うように、我々はみなモルモットなのか？、それとも、きちんとしたコントロールメカニズムがはたらいているのか？</simpara>
<simpara>教訓：透明性に対する回答が「No」でもひるむな。辛抱強く、時間をかけてストーリーを追っていこう。事態が好転するかもしれないし、後々、良好になった情報アクセスをもとに、より優れたレポートが書ける可能性もあるのだ。</simpara>
</section>
<section id="_ケーススタディ3_死の商人">
<title>ケーススタディ3：死の商人</title>
<simpara>最近の歴史は全ての集団にとって痛みに満ちている。特に、戦後と歴史の転換点では。その時、ジャーナリストは、調査が難しいデータをどうやって手に入れたらいいだろうか。例えば、この10年間での戦争で暴利を得た者たちは、いつ、力をつけてきたのか？これは、スロベニア人、クロアチア人、ボスニア人のジャーナリストチームが取り組んだタスクだった。</simpara>
<simpara>そのチームは、1990年代はじめ、国連の武器禁輸措置の期間に、旧ユーゴスラビアで行われた武器の取引に関する調査に乗り出した。この仕事のベースになったのは、この話題に関する議会の審問からの文書群だった。輸送経路を記録し、取引の構造を理解するため、船の番号やトラックのナンバープレートを追跡しなければならなかった。</simpara>
<simpara>スロベニアの議会委員会はバルカン戦争からの不当利得行為に関する質問について調査していたが、なんらかの結論に至ることはなかった。しかし、機密解除された文書やデータに非常に価値のある手がかりが含まれていたのだ。その文書は、6000ページもあり、スロベニアチームが情報公開法を通じて入手した。</simpara>
<simpara>このケースでは、データは文書から抽出され、データベースの中で並び替えられる必要があった。さらなるデータの追加と、分析、研究によって、彼らは、不法な武器取引のおびただしいルートをマッピングすることができた。<ulink url="http://bit.ly/kaasogmulvad-smuggling">illegal weapon trade</ulink>.</simpara>
<simpara>チームは成功し、結果は比類なく優れており、彼らにとって初めての賞を受賞した。 <ulink url="http://bit.ly/journalismfund-smuggling1">unique</ulink> 最も重要なのは、チーム参加者の全体の地域に関する重要事項であり、「死の貨物」が通る国に滞在するジャーナリストたちからストーリーを集めることができたからだった。</simpara>
<simpara>教訓：良い生データは、それが予期しない場所にあったとしても、探り出せ。そして、既存の公開データと組み合わせてみよ。</simpara>
<simpara>&mdash; <emphasis>Brigitte Alfter, Journalismfund.eu</emphasis></simpara>
<sidebar>
<title>情報自由法と友人</title>
<simpara>バルカン諸国の多くには、政府腐敗の問題がある。これらの国では地方政府の説明責任になると腐敗は、多くの場合、さらに高い割合となる。数ヶ月間、ベオグラードをベースにするCentre for Investigative Reporting <ulink url="http://www.cins.org.rs/">Centre for Investigative Reporting</ulink> のセルビア人ジャーナリストのグループが2009年に30以上の自治体から、情報自由法に関する異なる種類のドキュメントに関する質問をなげてきた。それ以前は、ほとんど何も一般公開されなかった。アイデアは、政府の現物の記録を取得し、スプレッドシートにデータを置き、自治体の間で基本的なチェックや比較を実行し、最大値と最小値の数値を取得することでした。基本的な指標は、予算番号、定期的かつ特別な経費、職員給与、旅費、従業員数、携帯電話の費用、日当、公共調達の数字などであった。記者がそのような情報を求めていたことは初めてであった。</simpara>
<simpara>その結果、数多くの偽の説明、不正行為、汚職事件を解く包括的なデータベースとなった。最高給取りの市長リストからは、セルビアの大統領に比べてより多くのお金を受け取ったことが明らかになった。他の多くの公的機関関係者にも多額な旅費の返済を受けたとし、過払いされていた。私たちの苦労して集めた公共調達データは公的機関の混乱を強調することに寄与した。150以上の記事がデータベースから世の中に出て、それらの多くがセビリアの地方メディアや国営メディアによってピックアップされた。</simpara>
<simpara>私たちは同様の政府からの比較可能なデータを使った記録の比較ができるようになった。
実物は逸脱した行為を表示し、腐敗の可能性に光を当てることができるようになる。誇張されているもの、または異常な費用だけを比較することによって、不正を検出することができる。</simpara>
<simpara>&mdash; <emphasis>ジョルジェ・Padejski, ナイト・ジャーナリズム・フェロー、スタンフォード大学</emphasis></simpara>
</sidebar>
</section>
</section>
<section id="_getting_data_from_the_web_ウェブからデータを得る">
<title>Getting Data from the Web（ウェブからデータを得る）</title>
<simpara>あらゆる方法を試行したものの、データを届ける方法はまだ見つかっていない。ウェブ上にデータは見つかったものの、悲しいかな、ダウンロード可能でなかったり、コピー＆ペーストできない状態だったとする。大丈夫、そこからデータを取り出す方法はまだあるかもしれない。例えば：</simpara>
<?dbfo-need height="1in"?>
<itemizedlist>
<listitem>
<simpara>
WebベースのAPI経由でデータを取得する。オンラインデータベースやモダンなWebアプリケーション（Twitter、Facebookなど多数ある）がインターフェースを提供している場合がある。ソーシャルメディアサイトと同様、政府が公開するデータや商用データにアクセスする有力な方法である。
</simpara>
</listitem>
<listitem>
<simpara>
PDFファイルからデータを抽出する。この方法は難しい。PDFはもともとプリンタ向けの言語であり、文書に含まれるデータ構造のための情報を多く持てないためである。PDFファイルからの情報抽出は本書で扱う範囲外ではあるが、世の中のいくつかのツールやチュートリアルが役に立つかもしれない。
</simpara>
</listitem>
<listitem>
<simpara>
Webサイトをスクリーンスクレイピングする。それが可能なユーティリティを用いる、または簡単なコードを書くことにより、通常のWebページから構造化された内容を抽出する。とても強力な方法で多くの場合に適用できる方法だが、Webそのものの仕組みをある程度知る必要がある。
</simpara>
</listitem>
</itemizedlist>
<simpara>このようなすばらしい技術的な選択肢とともに、簡単な方法も忘れてはならない：機械可読なデータを持つファイルの検索に時間を使ったり、あなたが望むデータを持っている組織に問い合わせたりすることにも価値がある。</simpara>
<simpara>この章では、HTMLで書かれたWebページからデータを取得する基本的な例を紹介する。</simpara>
<section id="_what_is_machine_readable_data_機械可読データとは">
<title>What Is Machine-Readable Data?（機械可読データとは？）</title>
<simpara>これら方法のほとんどの目的は、機械可読データへのアクセスである。機械可読データとは、人間が読める形かどうかにはかかわらず、コンピュータ処理のために生成されるデータのことである。このようなデータの構造は、含まれる情報に関連し、表示のされ方には関連しない。機械可読フォーマットの代表例はCSV、XML、JSON、Excelファイルである。一方、Word文書やHTMLページ、PDFファイルは、文書の視覚的なレイアウトと関係が深い。例えばPDFはプリンタへ直接情報伝達する言語であり、判別可能な文字よりも、ページ上の線や点の位置により大きく関わっている。</simpara>
</section>
<section id="_scraping_websites_what_for_webサイトのスクレイピング_目的は">
<title>Scraping Websites: What For?（Webサイトのスクレイピング：目的は？）</title>
<simpara>皆これはすでに行っている：Webサイトを訪れ、その中のある表に興味を持ち、Excelファイルへコピーする。その中でいくつか数値を増やしたり、保存しておくこともできる。しかし実際はあまり有効ではない。あなたが望むデータはたくさんのWebサイトにまたがって存在することもある。手動でのコピー作業はすぐに退屈になるだろう。ちょっとしたコードを使うのが理にかなっている。</simpara>
<simpara>スクレイピングの利点は、天気予報から政府支出まで、たとえ生データへアクセスするAPIが提供されていなくても、実質的にあらゆるWebサイトに対して有効な点にある。</simpara>
</section>
<section id="_what_you_can_and_cannot_scrape_スクレイプできる_できない内容">
<title>What You Can and Cannot Scrape（スクレイプできる/できない内容）</title>
<simpara>スクレイプできる内容にはやはり制約がある。スクレイプを難しくする点はいくつかある：</simpara>
<itemizedlist>
<listitem>
<simpara>
構造情報がわずかな（または存在しない）、不適切に整形されたHTMLコード（昔の政府のWebサイトなど）
</simpara>
</listitem>
<listitem>
<simpara>
自動アクセスを避けるため設置された認証システム（CAPTCHAコードや有料コンテンツ）
</simpara>
</listitem>
<listitem>
<simpara>
ユーザー行動を追跡するためブラウザのCookieを使用する、セッションベースのシステム
</simpara>
</listitem>
<listitem>
<simpara>
ワイルドカード検索の可能性および完全な一覧表示の不足
</simpara>
</listitem>
<listitem>
<simpara>
サーバー管理者によるバルク・アクセスのブロック設定
</simpara>
</listitem>
</itemizedlist>
<simpara>もう一つの制約は法の壁である：国によっては、データベースの権利を重要視しており、オンライン化された情報の再利用について、あなたの権利が制限される可能性がある。あなたがジャーナリストとしての特権をお持ちであれば、その権限によっては、ライセンスを見なかったことにして再利用の強行も可能かもしれない。自由に利用可能な政府のデータのスクレイピングは問題ないが、その結果の公表前には二重チェックが必要かもしれない。営利団体およびいくつかのNGOはその点では寛容でなく、自分たちのシステムを「妨害」していると訴えてくる可能性もある。他にも、得た情報によりプライバシーが侵害され、データ・プライバシーに関する法律や職業倫理を犯す可能性もある。</simpara>
<sidebar>
<title>貼り付ける, 抜き出す, 組み合わせる, 洗浄する</title>
<simpara>英国の膨大で広範囲なデータを便利なフォーマットでの提供とすることについては、まだリリースされていない。接待や国会議員の業務外の利益、ロビー活動などに関するデータは定期的に公開されているが、しかしそれは分析が難しい方法での公開となっている。</simpara>
<simpara>いくつかの情報については、きつくて辛い唯一の方法がある。それぞれが12そこらのレコードを持つ膨大なエクセルファイルたちのデータをつなぎあわせることは閣僚会合の包括的なリストをつくるための唯一の方法だった。しかし別の情報においてはウェブのスクレイピングが非常に有用であることを示した。</simpara>
<simpara>Using a service like ScraperWiki to ask coders to produce a scraper for information like the Register of MPs' interests did around half of our job for us: we had all MPs' information in one sheet, ready for the (lengthy) task of analysing and cleaning.</simpara>
<simpara>Services like this (or tools such as Outwit Hub) are a huge help to journalists trying to compile messy data who are unable to code themselves.</simpara>
<simpara>&mdash; <emphasis>James Ball, the Guardian</emphasis></simpara>
</sidebar>
</section>
<section id="_tools_that_help_you_scrape_スクレイプに役立つツール">
<title>Tools That Help You Scrape（スクレイプに役立つツール）</title>
<simpara>Webサイトからの情報抽出に使えるプログラムは、ブラウザ拡張機能やWebサービスを含め数多くある。ブラウザによっては <ulink url="http://www.readability.com/">Readability</ulink> （ページからテキストを抽出する）や <ulink url="http://www.downthemall.net/">DownThemAll</ulink> （一度にたくさんのファイルをダウンロードできる）などによって、退屈な手動作業を自動化できる。Chromeの拡張機能である <ulink url="http://bit.ly/chrome-scraper">Scraper extension</ulink> はWebサイトにあるテーブルを抽出するために作成された。FireFoxの開発者向け拡張機能 <ulink url="http://getfirebug.com/">FireBug</ulink> （同様の機能はChrome、Safari、IEにすでに存在する）を用いれば、Webサイトがどのように構築され、ブラウザとサーバがどのような通信を行うかを明確に追跡できる。</simpara>
<simpara><ulink url="https://scraperwiki.com/">ScraperWiki</ulink> は、Python、Ruby、PHPなどさまざまな言語でスクレイパーを記述するのに役立つWebサイトだ。コンピュータ上にプログラミング環境を準備する時間はないけれど、スクレイピングは行いたい、という場合にこのサイトは便利である。GoogleスプレッドシートやYahoo! Pipesなど他のWebサービスも、別のWebサイトからの抽出に役立つだろう。</simpara>
</section>
<section id="_how_does_a_web_scraper_work_webスクレイパーが動作する仕組み">
<title>How Does a Web Scraper Work?（Webスクレイパーが動作する仕組み）</title>
<simpara>Webスクレイパーは多くの場合、Python、Ruby、PHPのようなプログラミング言語で記述されたコードの小さな集まりである。適切な言語の選択は、あなたがどのコミュニティに属しているかによる：あなたと同じニュースルームや都市に、すでにある言語を使って作業している人がいれば、その同じ言語を使うのがよいだろう。</simpara>
<simpara>先に述べたようなポイント・アンド・クリック型のスクレイピング・ツールは、手始めには有用である。一方、Webサイトのスクレイピングにおける実際の複雑さは、必要な情報を抽出するために、適切なページ、およびページ中の適切な要素を対応づける点にある。この作業はプログラミングではなく、Webサイトとデータベースの構造の理解することと言える。</simpara>
<simpara>Webサイトを表示するとき、ブラウザは2つの技術を使用している。1つはHTTPで、Webサーバーと通信し、文書や画像、動画など必要なリソースを要求する。もう1つはHTMLで、Webサイトを構成する言語である。</simpara>
</section>
<section id="_the_anatomy_of_a_web_page_webページの解剖">
<title>The Anatomy of a Web Page（Webページの解剖）</title>
<simpara>HTMLページは、HTML「タグ」で定義される箱型領域の階層構造によって定義される。大きな箱の中には、たくさんの小さな箱が入る。多くの子要素（列とセル）を持つテーブルがその一例である。タグの種類は多く、箱やテーブル、画像、リンクの生成など、それぞれが異なる機能を持つ。タグはその他に付加的な属性を持つこともでき、他と重複しない識別子を与えられる。また「クラス」と呼ばれるグループに含めることも可能で、これにより文書中のどの要素であるかを特定できる。要素を適切な選択と内容抽出、これがスクレイパーを作成する際の鍵となる。</simpara>
<simpara>Webページ中の要素を眺めると、あらゆる部分が箱形領域の組み合わせから成っていることがわかる。</simpara>
<simpara>Webページをスクレイプするには、HTML文書に含まれる、性質の異なるいくつかの要素について知っておくとよい。例えば <literal>&lt;table&gt;</literal> 要素はテーブル全体を定義し、 <literal>&lt;tr&gt;</literal> (table row) は列要素、 <literal>&lt;td&gt;</literal> (table data) は行方向のセル要素を定義する。もっともよく見かけるであろう基本的な要素は <literal>&lt;div&gt;</literal> で、これは単純に内容のひとかたまりを定義する。ブラウザ上で <ulink url="http://bit.ly/developer-toolbar">developer toolbar</ulink> を使用すると、簡単に、これら要素が並ぶ様子を確認できる。Webページがどのような構成で成り立ち、どのようなコードで書かれているのかがわかる。</simpara>
<simpara>タグはブックエンドのように機能する。まとまりの開始部分と終了部分にマークする。例えば <literal>&lt;em&gt;</literal> <emphasis>はイタリック体や強調表示にするテキストの開始部分に置かれ、</emphasis> <literal>&lt;/em&gt;</literal> はその終了部分に置かれる。簡単である。</simpara>
</section>
<section id="_an_example_scraping_nuclear_incidents_with_python_例_pythonを用いた原子力事故のスクレイピング">
<title>An Example: Scraping Nuclear Incidents with Python（例：Pythonを用いた原子力事故のスクレイピング）</title>
<simpara><ulink url="http://www-news.iaea.org/EventList.aspx">NEWS</ulink> は、全世界での放射能事故の情報を集めた国際原子力機関（IAEA）のポータルサイトである（そしてWeird Title Clubの会員における強力な競争相手でもある！）Webページには、事故の一覧がシンプルに、スクレイプが容易なブログ形式で表示されている。</simpara>
<figure id="FIG045"><title>国際原子力機関（IAEA）ポータル（news.iaea.org）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-CC.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-CC.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>まず、<ulink url="https://scraperwiki.com/">ScraperWiki</ulink> 上でPythonによるスクレイパーを作成する。折りたたまれたコードを少し含む以外はほとんど空であるテキスト領域が表示される。別のブラウザウィンドウで<ulink url="http://www-news.iaea.org/EventList.aspx">IAEA のサイト</ulink> を開き、ブラウザの開発者メニューを開く。「Elements（要素）」ビューで、ニュース記事を1つ選び、HTML要素の中でそのニュースのタイトルが書かれた部分を探す。ブラウザの開発者メニューにより、Webページの要素とHTMLコードとを結びつけることができる。</simpara>
<simpara>調査の結果、ニュースのタイトルは  <literal>&lt;table&gt;</literal> の中にある <literal>&lt;h4&gt;</literal> 要素に含まれている。各出来事は <literal>&lt;tr&gt;</literal> 列に入り、出来事の詳細や日付の情報を含んでいる。すべての出来事のタイトルを抽出したい場合は、title要素中にある全テキストを検索しながら、表にある各列を連続して選択する方法を見つける必要がある。</simpara>
<simpara>これらの処理をコードにする場合、全ての処理をそこに含める必要がある。必要なステップがどのようなものかを掴みたいなら、シンプルなゲームをしよう：ScraperWikiウィンドウで、スクレイパーがどのような処理を重ねていけばよいか、料理レシピの各行のように、順を追った自分向けの手順を書いてみるとよい。（Pythonであれば、実行行でないことを示すため、行の先頭にハッシュ記号を入れておく）例えば：</simpara>
<screen># Look for all rows in the table（テーブル中の全ての列を探す）
# Unicorn must not overflow on left side.（Unicornは左側にあふれないように）</screen>
<simpara>できるだけ細かい手順で書くことを勧める。プログラムは、スクレイピング対象のページ内容をすべて知っているわけではない。</simpara>
<simpara>上記のような疑似コードで書き出した後、最初のスクレイパーとコードの主な部分を比較してみよう：</simpara>
<screen>import scraperwiki
from lxml import html</screen>
<simpara>最初のセクションでは、ライブラリから既存機能−あらかじめコード化されたスニペット−をインポートしている。 <literal>scraperwiki</literal> でWebサイトのダウンロードが可能になる。<literal>lxml</literal> はHTML文書の構造を分析するツールである。いいお知らせ：ScraperWikiでPythonスクレイパーを書いているならこの2行は常に同じである。</simpara>
<screen>url = "http://www-news.iaea.org/EventList.aspx"
doc_text = scraperwiki.scrape(url)
doc = html.fromstring(doc_text)</screen>
<simpara>次にコードは (変数): <literal>url</literal> という項目を作成し、IAEAのページのURLをその値として代入する。スクレイパーに、これからこのURLに着目するのだということを伝える。URLそのものはコードの一部ではなく、 <emphasis>文字列</emphasis> つまり一連の文字の並びとして扱う。</simpara>
<simpara>そして <literal>url</literal> 変数を入力として関数 <literal>scraperwiki.scrape</literal> に渡す。関数は定義された処理--この場合はWebページのダウンロードを行う。終了後の出力結果を別の変数 <literal>doc_text</literal> に入れる。<literal>doc_text</literal> にはWebサイトに含まれる実際のテキストが入る。つまりブラウザで見えている内容ではなく、全てのタグを含むソースコードである。このフォームはパースがあまり簡単ではなく、各要素の対応付けが容易になるような特別な表現、いわゆるドキュメント・オブジェクト・モデル（DOM）を生成する別の関数 <literal>html.fromstring</literal> を用いる。</simpara>
<screen>for row in doc.cssselect("#tblEvents tr"):
link_in_header = row.cssselect("h4 a").pop()
event_title = link_in_header.text
print event_title</screen>
<simpara>最後に、表にあるそれぞれの列を探し、そのヘッダーから出来事のタイトルを抽出するためにDOMを使用する。2つのコンセプト：for ループと要素選択 (<literal>.cssselect</literal>) を新たに用いる。forループの仕組みはその名前の通りだ。アイテムの一覧を1つずつ対象にして、一時的なエイリアス（この場合は <literal>row</literal> ）を割り当て、アイテムごとにインデントされた処理をそれぞれ実行する。</simpara>
<simpara>もう1つの新しいコンセプト、要素選択は、文書中の要素を探すための特別な言語を活用する。CSSセレクタは、通常はHTML要素へのレイアウト情報付加に使われ、ページ外の要素を適切に指定できる。今回の場合は（6行目で） <literal>#tblEvents tr</literal> を選択し、ID <literal>tblEvents</literal> （ハッシュ記号でIDを識別する）を持つ表の要素中に含まれるそれぞれの <literal>&lt;tr&gt;</literal> にマッチする。この処理で取得できるのは <literal>&lt;tr&gt;</literal> 要素の一覧である。</simpara>
<simpara>次の行（7行目）で、<literal>&lt;h4&gt;</literal> （タイトル）中に含まれるすべての <literal>&lt;a&gt;</literal> （ハイパーリンクを表す）を選択する。今回は着目する要素は1つだけ（1列あたり1タイトル）なので、 <literal>.pop()</literal> 関数によるセレクタで得られた一覧のうち、先頭だけを取り出す必要がある。</simpara>
<simpara>DOM中の要素の中には、実際のテキスト（マークアップ言語に含まれない、コンテンツとしてのテキスト）を含むものがある。それらに対しては8行目のように <literal>[要素名].text</literal> という書式で参照できる。そして最終行の9行目のように、ScraperWiki のコンソール画面にテキストを出力することになる。スクレイパー上で Run をクリックすると小さなウィンドウが現れ、IAEAサイト中から出来事の名前が抽出、表示される。</simpara>
<figure id="FIG046"><title>動作中のスクレイパー（ScraperWiki）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-DD.png" scale="90"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-DD.png</phrase></textobject>
</mediaobject>
</figure>
<?dbfo-need height="1in"?>
<simpara>スクレイパーの基本的な仕組みをここまで確認した。Webページをダウンロードし、DOM形式に変換し、特定の内容を選択および抽出できる。残っている課題があれば、この基本的な骨組みをベースに、ScraperWikiやPythonのドキュメントを参考にしてみよう。</simpara>
<itemizedlist>
<listitem>
<simpara>
出来事のタイトルに対応するリンクのアドレスは見つかるだろうか？
</simpara>
</listitem>
<listitem>
<simpara>
CSSのクラス名を用いて、日付や場所の情報を含む小さな箱の領域を選択し、要素のテキストを抽出できるだろうか？
</simpara>
</listitem>
<listitem>
<simpara>
ScraperWikiは、スクレイパーの処理結果を保存できるよう小規模なデータベースを持っている。提供されているドキュメントに含まれるサンプルを参考にすると、出来事のタイトル、リンク、日付を保存できる。
</simpara>
</listitem>
<listitem>
<simpara>
出来事の一覧はページ数が多い。歴史的な出来事を複数のページへ抽出できるだろうか？
</simpara>
</listitem>
</itemizedlist>
<simpara>このような抽出に取り組んでみる場合、ScraperWikiを参考にするとよい。既にあるスクレイパーに多数の有用なサンプルがある。頻繁に参考にしよう、データは刺激を与えてくれる。このように、スクレイパーを作成するにしても、まったくゼロから始める必要はない。自分の行いたい内容に近いものを選び、手元に入手し、取り組んでいる内容に当てはめてみよう。</simpara>
<simpara>&mdash; <emphasis>Friedrich Lindenberg, Open Knowledge Foundation</emphasis></simpara>
<sidebar>
<title>Scraping a Public Database</title>
<simpara>Some French physicians are free to choose their own rates, so that one can pay between €70 and €500 for a 30-minute visit at an oncologist, for instance. This data regarding rates is legally public, but the administration provides only a hard-to-navigate online database. In order to have a good view of the doctors' rates for Le Monde, I decided to scrape the entire database.</simpara>
<simpara>That&#8217;s where the fun began. The front-end search form was a Flash application that redirected to an HTML result page via a POST request. With help from Nicolas Kayser-Bril, it took us some time to figure out that the application used a third page as a &#8220;hidden&#8221; step between the search form and the result page. This page was actually used to store a cookie with values from the search form that was then accessed by the results page. It would have been hard to think of a more convoluted process, but the options of the cURL library in PHP make it easy to overcome the hurdles, once you know where they are! In the end, getting hold of the database was a 10-hour task, but it was worth it.</simpara>
<simpara>&mdash; <emphasis>Alexandre Léchenet, Le Monde</emphasis></simpara>
</sidebar>
<?dbfo-need height="1in"?>
</section>
</section>
<section id="_データソースとしてのウェブ">
<title>データソースとしてのウェブ</title>
<simpara>どのようにすればインターネットにしか存在しないものをもっと見つけることが出来るのだろうか？ 本章ではあなたが探しているものがメールアドレスかウェブサイトか、あるいは画像かウィキペディアの記事であろうとも、あなたが探しているものの背景を教えてくれるツールを紹介する。</simpara>
<section id="_ウェブツール">
<title>ウェブツール</title>
<simpara>はじめに特定のページについてよりもサイト全体の詳細を発見するために使うことができるいくつかのサービスだ:</simpara>
<variablelist>
<varlistentry>
<term>
Whois
</term>
<listitem>
<simpara>
  If you go to <ulink url="http://whois.domaintools.com/">whois.domaintools.com</ulink> (or just type whois <emphasis>www.example.com</emphasis> in Terminal.app on a Mac, with a URL in place of the placeholder here) you can get the basic registration information for any website. In recent years, some owners have chosen private registration, which hides their details from view, but in many cases you&#8217;ll see a name, address, email, and phone number for the person who registered the site. You can also enter numerical IP addresses here and get data on the organization or individual that owns that server. This is especially handy when you&#8217;re trying to track down more information on an abusive or malicious user of a service, since most websites record an IP address for everyone who accesses them.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Blekko
</term>
<listitem>
<simpara>
  The <ulink url="http://blekko.com/">Blekko search engine</ulink> offers an unusual amount of insight into the internal statistics it gathers on sites as it crawls the Web. If you type in a domain name followed by "/seo", you&#8217;ll receive a page of information on that URL.
  The first tab in <xref linkend="FIG048"/> shows you which other sites are linking to the domain in popularity order. This can be extremely useful when you&#8217;re trying to understand what coverage a site is receiving, and if you want to understand why it&#8217;s ranking highly in Google&#8217;s search results, since they&#8217;re based on those inbound links. <xref linkend="FIG049"/> tells you which other websites are running from the same machine. It&#8217;s common for scammers and spammers to astroturf their way towards legitimacy by building multiple sites that review and link to each other. They look like independent domains, and may even have different registration details, but they&#8217;ll often actually live on the same server because that&#8217;s a lot cheaper. These statistics give you an insight into the hidden business structure of the site you&#8217;re researching.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<figure id="FIG047"><title>The Blekko search engine (Blekko.com)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-PP-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-PP-01.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG048"><title>Understanding web popularity: who links to who? The other handy tab is "Crawl stats", especially the "Cohosted with" section. (Blekko.com)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-PP-02.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-PP-02.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG049"><title>Spotting web spammers and scammers (Blekko.com)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-PP-03.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-PP-03.png</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
Compete.com
</term>
<listitem>
<simpara>
  By surveying a cross-section of American consumers, <ulink url="http://www.compete.com/">compete.com</ulink> builds up detailed usage statistics for most websites, and makes some basic details freely available. Choose the Site Profile tab and enter a domain (<xref linkend="FIG0410"/>). You&#8217;ll then see a graph of the site&#8217;s traffic over the last year, together with figures for how many people visited, and how often (as in <xref linkend="FIG0411"/>). Since they&#8217;re based on surveys, the numbers are only approximate, but I&#8217;ve found them reasonably accurate when I&#8217;ve been able to compare them against internal analytics. In particular, they seem to be a good source when comparing two sites, since while the absolute numbers may be off for both, it&#8217;s still a good representation of their relative difference in popularity. They only survey US consumers though, so the data will be poor for predominantly international sites.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<figure id="FIG0410"><title>Compete.com&#8217;s site profile service (Compete.com)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-PP-04.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-PP-04.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG0411"><title>What&#8217;s in vogue? What&#8217;s in demand?: Hotspots on the web (Compete.com)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-PP-05.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-PP-05.png</phrase></textobject>
</mediaobject>
</figure>
<variablelist>
<varlistentry>
<term>
Google&#8217;s Site Search
</term>
<listitem>
<simpara>
  One feature that can be extremely useful when you&#8217;re trying to explore all the content on a particular domain is the "site:" keyword. If you add "site:example.com" to your search phrase, Google will only return results from the site you&#8217;ve specified. You can even narrow it down further by including the prefix of the pages you&#8217;re interested in, for example, "site:example.com/pages/", and you&#8217;ll only see results that match that pattern. This can be extremely useful when you&#8217;re trying to find information that domain owners may have made publicly available but aren&#8217;t keen to publicize, so picking the right keywords can uncover some very revealing material.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_ウェブページ_画像_映像">
<title>ウェブページ、画像、映像</title>
<simpara>Sometimes you&#8217;re interested in the activity that&#8217;s surrounding a particular story, rather than an entire website. The tools below give you different angles on how people are reading, responding to, copying, and sharing content on the web.</simpara>
<variablelist>
<varlistentry>
<term>
Bit.ly
</term>
<listitem>
<simpara>
  I always turn to <ulink url="http://bitly.com/">bit.ly</ulink> when I want to know how people are sharing a particular link with each other. To use it, enter the URL you&#8217;re interested in. Then click on the Info Page+ link. That takes you to the full statistics page (though you may need to choose "aggregrate bit.ly link" first if you&#8217;re signed in to the service). This will give you an idea of how popular the page is, including activity on Facebook and Twitter, and below that you&#8217;ll see public conversations about the link provided by backtype.com. I find this combination of traffic data and conversations very helpful when I&#8217;m trying to understand why a site or page is popular, and who exactly its fans are. For example, it provided me with strong evidence that the prevailing narrative about grassroots sharing and Sarah Palin was wrong.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<?dbfo-need height="1in"?>
<variablelist>
<varlistentry>
<term>
Twitter
</term>
<listitem>
<simpara>
  As the micro-blogging service becomes more widely used, it becomes more useful as a gauge of how people are sharing and talking about individual pieces of content. It&#8217;s deceptively simple to discover public conversations about a link. You just paste the URL you&#8217;re interested in into the search box, and then possibly hit "more tweets" to see the full set of results.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Googleのキャッシュ
</term>
<listitem>
<simpara>
  When a page becomes controversial, the publishers may take it down or alter it without acknowledgment. If you suspect you&#8217;re running into the problem, the first place to turn is Google&#8217;s cache of the page as it was when it did its last crawl. The frequency of crawls is constantly increasing, so you&#8217;ll have the most luck if you try this within a few hours of the suspected changes. Enter the target URL in Google&#8217;s search box, and then click the triple arrow on the right of the result for that page. A graphical preview should appear, and if you&#8217;re lucky, there will be a small "Cache" link at the top of it. Click that to see Google&#8217;s snapshot of the page. If that has trouble loading, you can switch over to the more primitive text-only page by clicking another link at the top of the full cache page. You&#8217;ll want to take a screenshot or copy-paste any relevant content you do find, since it may be invalidated at any time by a subsequent crawl.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
The Internet ArchiveのWayback Machine
</term>
<listitem>
<simpara>
  If you need to know how a particular page has changed over a longer time period, like months or years, the Internet Archive runs a service called <ulink url="http://archive.org/web/web.php">The Wayback Machine</ulink> that periodically takes snapshots of the most popular pages on the web. You go to the site, enter the link you want to research, and if it has any copies, it will show you a calendar so you can pick the time you&#8217;d like to examine. It will then present a version of the page roughly as it was at that point. It will often be missing styling or images, but it&#8217;s usually enough to understand what the focus of that page&#8217;s content was then.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ソースを見る
</term>
<listitem>
<simpara>
  It&#8217;s a bit of a long shot, but developers often leave comments or other clues in the HTML code that underlies any page. It will be on different menus depending on your browser, but there&#8217;s always a "View source" option that will let you browse the raw HTML. You don&#8217;t need to understand what the machine-readable parts mean, just keep an eye out for the pieces of text that are often scattered amongst them. Even if they&#8217;re just copyright notices or mentions of the author&#8217;s names, these can often give important clues about the creation and purpose of the page.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
TinEye
</term>
<listitem>
<simpara>
  Sometimes you really want to know the source of an image, but without clear attribution text there&#8217;s no obvious way to do this with traditional search engines like Google. <ulink url="http://www.tineye.com/">TinEye</ulink> offers a specialized "reverse image search" process, where you give it the image you have, and it finds other pictures on the web that look very similar. Because they use image recognition to do the matching, it even works when a copy has been cropped, distorted, or compressed. This can be extremely effective when you suspect that an image that&#8217;s being passed off as original or new is being misrepresented, since it can lead back to the actual source.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
YouTube
</term>
<listitem>
<simpara>
  If you click on the Statistics icon to the lower right of any video, you can get a rich set of information about its audience over time. While it&#8217;s not complete, it is useful for understanding roughly who the viewers are, where they are coming from, and when.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_emails">
<title>Emails</title>
<simpara>If you have some emails that you&#8217;re researching, you&#8217;ll often want to know more details about the sender&#8217;s identity and location. There isn&#8217;t a good off-the-shelf tool available to help with this, but it can be very helpful to know the basics about the hidden headers included in every email message. These work like postmarks, and can reveal a surprising amount about the sender. In particular, they often include the IP address of the machine that the email was sent from, a lot like caller ID on a phone call. You can then run whois on that IP number to find out which organization owns that machine. If it turns out to be someone like Comcast or AT&amp;T who provide connections to consumers, then you can visit MaxMind to get its approximate location.</simpara>
<simpara>To view these headers in Gmail, open the message and open the menu next to reply on the top right and choose "Show original".</simpara>
<simpara>You&#8217;ll then see a new page revealing the hidden content. There will be a couple of dozen lines at the start that are words followed by a colon. The IP address you&#8217;re after may be in one of these, but its name will depend on how the email was sent. If it was from Hotmail, it will be called <literal>X-Originating-IP:</literal>, but if it&#8217;s from Outlook or Yahoo it will be in the first line starting with <literal>Received:</literal>.</simpara>
<simpara>Running the address through Whois tells me it&#8217;s assigned to Virgin Media, an ISP in the UK, so I put it through MaxMind&#8217;s geolocation service to discover it&#8217;s coming from my home town of Cambridge. That means I can be reasonably confident this is actually my parents emailing me, not impostors!</simpara>
</section>
<section id="_トレンド">
<title>トレンド</title>
<simpara>If you&#8217;re digging into a broad topic rather than a particular site or item, here&#8217;s a couple of tools that can give you some insight:</simpara>
<variablelist>
<varlistentry>
<term>
Wikipedia Article Traffic
</term>
<listitem>
<simpara>
  If you&#8217;re interested in knowing how public interest in a topic or person has varied over time, you can actually get day-by-day viewing figures for any page on Wikipedia at <ulink url="http://stats.grok.se/">stats.grok.se</ulink>. This site is a bit rough and ready, but will let you uncover the information you need with a bit of digging. Enter the name you&#8217;re interested in to get a monthly view of the traffic on that page. That will bring up a graph showing how many times the page was viewed for each day in the month you specify. Unfortunately you can only see one month at a time, so you&#8217;ll have to select a new month and search again to see longer-term changes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Google Insights
</term>
<listitem>
<simpara>
  You can get a clear view into the public&#8217;s search habits using <ulink url="http://www.google.com/insights/search/">Insights from Google</ulink> (<xref linkend="FIG0412"/>). Enter a couple of common search phrases, like "Justin Bieber vs Lady Gaga", and you&#8217;ll see a graph of their relative number of searches over time. There&#8217;s a lot of options for refining your view of the data, from narrower geographic areas, to more detail over time. The only disappointment is the lack of absolute values&#8212;you only get relative percentages, which can be hard to interpret.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<figure id="FIG0412"><title>Google Insights (Google)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-PP-06.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-PP-06.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>&mdash; <emphasis>Pete Warden, independent data analyst and developer</emphasis></simpara>
</section>
</section>
<section id="_ガーディアンデータブログ_guardian_datablog_でのクラウドソーシング">
<title>ガーディアンデータブログ（Guardian Datablog）でのクラウドソーシング</title>
<simpara>クラウドソーシング（http://en.wikipedia.org/wiki/Crowdsourcing　（Wikipediaによれば））とは、「クラウドとしても知られる人々のネットワークへのアウトソーシング業務を含む、分散された問題解決や生産のプロセスである」。次の文はサイモン・ロジャーズへのインタビューから、憲兵支出スキャンダル、ドラッグ使用、サラ・ペイリン文書に取り組むために、データブログ（Datablog）がどのようにクラウドソーシングを用いたかについてである。</simpara>
<simpara>時々、あなたは一人では調べることが不可能な、何トンものファイル、統計、報告書を入手することだろう。または、アクセスできなかったり、ひどいフォーマットのため大したことができない資料をあなたは見つけるかもしれない。これがクラウドソーシングが役立ちうる場所である。</simpara>
<simpara>ガーディアン（Guardian)が得た１つのものは、多くの読者、多くの対の目である。もし我々が入力する必要がある面白いプロジェクトがあれば、我々は読者に助けてくれるよう頼むことができる。それが、我々がhttp://mps-expenses.guardian.co.uk/　「憲兵の支出」で行ったことだ。我々には450,000の文書があったが、何かをするにはごくわずかな時間しかなかった。そうすると任務を我々の読者層に公開するよりもいい方法があるだろうか？</simpara>
<simpara id="FIG0413">編集されたステファン・パウンドの偶然の支出（ガーディアン（the Guardian））
<inlinemediaobject>
  <imageobject>
  <imagedata fileref=":figs/incoming/04-EE.png"/>
  </imageobject>
  <textobject><phrase>:figs/incoming/04-EE.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>憲兵の支出プロジェクトは多くのマル秘情報を生み出した。我々はデータよりも多くのストーリーを得た。プロジェクトはトラフィックに関して並外れた成功だった。人々は実にそれを好んだ。</simpara>
<simpara>我々は現在　http://bit.ly/guardian-drugs　 「MixMag と一緒に麻薬使用に対して何かをする」に取り組んでおり、これも驚くべきだ。どれだけ多くの人が戻ってくるかという点では、英国犯罪調査よりも大きくなりそうで、それはすばらしいことだ。</simpara>
<simpara>これら両プロジェクトに共通するものは、それらが人々が心から気にかけている争点に関するもので、人々が喜んでプロジェクトのために時間を費やそうとすることだ。我々が行ったクラウドソーシングの多くは偏執狂に頼っている。憲兵の支出では、我々は最初に大量のトラフィックを得て、それからすぐ下火になった。しかし我々には異常やストーリーを求めて偏執的に全てのページを調べる人々がまだいた。ある人は30,000ページを調べた。彼らは多くのことを知っている。</simpara>
<simpara>我々はクラウドソーシングをhttp://bit.ly/guardian-palin-papers「サラ・ペイリン文書」にも用いた。再び、この取組はストーリーのために生情報を精査するうえで、非常な助けになった。</simpara>
<simpara>ストーリーを作り出すことに関しては、クラウドソーシングは我々にとって実にうまく機能してきた。人々は本当にクラウドソーシングが好きで、それはガーディアン（the Gurardian）を良く見せている。しかしデータを生み出すことに関しては、我々はあまりクラウドソーシングを使ってこなかった。</simpara>
<simpara>我々が実施してとてもうまくいったクラウドソーシングプロジェクトのうちのいくつかは、昔ながらの調査のようだった。あなたが人々に彼らの経験、生活、やってきたことについてたずねると、彼らはとてもよく働く。なぜなら人々がごまかそうとしないからだ。彼らは彼らが感じるままを発言するだろう。我々が、我々のために我々の仕事をしてほしいと人々に頼む時、人々が信頼できるデータを生み出せるような枠組みを見出す必要がある。</simpara>
<simpara>データの信頼性を考慮すると、http://www.oldweather.org/「古い天気」が取っているアプローチはとても良いと思う。彼らは各項目の作業につき10人の人々を割り当てた。それは正確性を確保するためによい方法だ。 憲兵の支出では、我々は憲兵がオンラインに行き、彼らの記録を彼らが良く見えるように編集するリスクを最小化しようと試みた。しかしこのような防御は永久には保たない。特定のURLを注意したり編集がロンドンのSW1地域から来ているのではないか気を付けることしかできない。なので油断がならない。我々が得ていたデータは常に信頼できるとは限らなかった。ストーリーは素晴らしかったが、それは我々が自信をもって使える生の数字は生み出さなかった。</simpara>
<simpara>もし私が、クラウドソーシングをデータ収集に使いたいと考える、意欲に燃えたデータジャーナリストに助言を与えるとすれば、人々が真に気に掛ける事柄について行うように、そしてそれが１面のトップ記事になる時まで、注意を払い続けるように励ますだろう。またあなたがそれをゲームのように見せられるなら、人々を励ますのにとても役立ちうる。我々が支出のストーリーに二度目に取り組んだ時、それを行う人々にとって、個々の課題ははるかにゲームのようだった。これは大きな違いをもたらす。なぜなら、もし人々に、単に検査するために情報の山を与えて、「これを調べろ」と言うだけだと、困難ではるかに報いのない仕事にしてしまいかねないと思うからだ。そこで私は課題を面白くすることがとても重要だと思う。</simpara>
<simpara>&mdash; <emphasis>Marianne Bouchart, データジャーナリズムブログ（Data Journalism Blog）, ガーディアンのサイモンロジャーズへのインタビュー（interviewing Simon Rogers, the Guardian）</emphasis></simpara>
</section>
<section id="_データブログは五輪チケットに関する報道のためにクラウドソーシングをどう使ったか">
<title>データブログは五輪チケットに関する報道のためにクラウドソーシングをどう使ったか</title>
<simpara>最も反響が大きかったクラウドソーシングプロジェクトは <ulink url="http://bit.ly/guardian-olympics">五輪チケット抽選に関する記事</ulink> でしょう。英国の何千という人が2012年五輪のチケットを手に入れようと試み、手に入らずに怒りが渦巻きました。人々は数百ポンド分を注文し、何も手に入れられなかった。しかし、誰も本当のことは知りませんでした。一部の人だけが大声で不満を言っているだけで、ほとんどの人は実際には満足だったのか。だから我々は確かめようとしたわけです。</simpara>
<simpara>この話題に関する良いデータがない中で私たちが実際に出来うる最善のことは、人々に質問することだと決断しました。そして、私たちはその試みを軽い内容のものとして扱わないといけないと考えました。バランスのとれたサンプルではないからです。</simpara>
<simpara>私たちはグーグルフォームをつくり、<ulink url="http://bit.ly/guardian-olympics2">非常に具体的な質問</ulink>をしました。それは実際のところ長いフォームでした。いくら分のチケットを注文したのか。カードからいくら引き落とされたのか。結果はどうだったか。そういう質問項目です。</simpara>
<figure id="FIG0414"><title>何枚の五輪チケットを手に入れましたか？読者の答えはこちら。（ガーディアン）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-FF.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-FF.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>私たちはそれを小さな画像ファイルにして、サイトのトップに置きました。すごい勢いでシェアされていきました。私が考えるに、これが重要なことの一つです。私の記事のために私は何を知りたいと思うのだろうと考えるだけではなく、人々は私にいま何を語りたいのだろうと考えなければなりません。そして人々が話したいものをあなたが引き出せたときだけ、クラウドソーシングは成功するのです。このプロジェクトは、私たちがクラウドソーシングに取り組んだ最初の試みの一つでしたが、反応は巨大なものでした。１時間もかからず千件の反応があり、その日の内に７千件に達しました。</simpara>
<simpara>ですので明確なことに、我々はこの点において結果をより真剣に提示しました。最初は、どれほどうまくいくか想像もつきませんでした。だから、私たちはいくつかの警告もつけました。ガーディアンの読者は他の人々よりも裕福かもしれない。思っていたよりも少ないチケットしか手に入れなかった人はそれを私たちにいいたがるかもしれない、などです。</simpara>
<simpara>私たちはこの結果がどれほどの価値をもつであろうか知りませんでした。最終的に私たちの記事のよりどころとなる７千件の良い記録を得ました。そしてその半分がチケットを買おうとして手に入らなかったことがわかりました。我々はこれらをすべて報道しました。たくさんの人が参加していたため、大きな影響力がありました。</simpara>
<simpara>数週間後、チケット抽選に関する公的な概要報告書が発表されました。私たちの記事の数字と驚くほど近かったのです。ほとんど完全に正しかった。運が良かった部分もあると思いますが、私たちがそれほど多くの人々から声を集める事ができたからでもあるでしょう。</simpara>
<simpara>もしあなたが読者にこのようなことをコメント欄を使って聞き始めたら、その結果を用いてできることは限られるだろう。だからあなたはまず考えないといけません。「私が知りたいことのために何が最高のツールなのだろう」と。コメント欄なのか。アプリなのか。もしアプリなら、あなたは考えないといけない。それが出来上がるのを待つ価値があるのか。それをつくるために必要なリソースにみあったものかと。</simpara>
<simpara>この例では、私たちはグーグルフォームを使うことを思いついた。もし誰かがフォームを埋めると、その結果がスプレッドシートに並んでいるところを見ることができる。これはつまり、もしそれがいまもアップデートされていても、結果がいまも入ってきていても、スプレッドシートをあけてその結果のすべてをすぐにみることができるということだ。</simpara>
<simpara>私はこの作業にグーグルで挑むことができた。しかし、私はエクセルにそれをダウンロードし、数値が低いものから高いものにソートする作業などをした。そして私は人々がどれだけお金を使ったか、数字を選ぶのではなく、書き込んでいるエントリーをみつけ、それをすべて修正した。私はできるだけ除外はしないと決めた。だから有効な返答だけを考慮するのではなく、受け取った返答は修正していった。外国の貨幣を使った人もいたから、私はそれを英国通貨に換算した。それらは骨が折れるものだった。</simpara>
<simpara>この分析のすべてを数時間で終えたけれど、私はあきらかにバカげた投稿にノックアウトされた。多くの人が彼らはチケットのためにまったくお金を使わなかったと記していた。それはおかしいが、まあいい。そういうものは７０００件中１００件もなかった。</simpara>
<simpara>明らかにおかしい高額を数字を書き込み結果をゆがめようという人も数十人いた。たとえば１０００万ポンドとか。そこで私は普段私たちが使っている通常のデータに関する原則を適用できたデータセットを残した。ピボットテーブルと呼ばれるものを使った平均化した。そういうことだ。</simpara>
<simpara>私たちはどれほどの勢いをこのプロジェクトが持つか想像もしていなかった。そこで私が一人でスポーツブログの編集者と一緒に携わっていた。私たちは一緒に頭をつきあわせて考え、これは楽しいプロジェクトになるかもしれないと思った。私たちは最初から最後までを２４時間でやった。アイデアがあり、昼食の時間にアップして、１日上サイトの目立つ場所におき、その結果を翌朝に公表した。</simpara>
<simpara>私たちはグーグルドックスを使うことにした。結果を完全に管理できるからだ。他の分析ツールを使う必要はなかった。あなたが特殊な世論調査ソフトを使い始めるときは、あなたはしばしば使えるツールがかぎられる。もし私たちが求めた情報がとくに最新の注意をようするものなら、グーグルを使うことに躊躇し、内製したツールを使うことを考えたかもしれない。しかし、一般的にグーグルフォームはガーディアンのページに落とし込むことが非常に簡単で、それを使っているということが事実上見えない。だから非常に快適だ。</simpara>
<simpara>クラウドソーシングを使いたいというデータジャーナリストへのアドバイスとしては、あなたが知りたいと思うことを非常に具体的にしなければならない。複数の選択の答えを可能な限りたくさん得るようなことを質問すること。あなたが得たサンプルが偏っているか気づくため、あなたが話を聞こうとする対象の基本的な人口統計を手に入れようとすること。あなたが量について聞くのなら、ガイダンスの中でその量をアラビア数字で示せるようにすること。特定の通貨を使ってもらうこと。そういうことだ。量が多くてもしっかりとその答えをつかめないのであれば、多ければ良いというわけではない。そして常に、常にコメント欄をつけること。ならなら多くに人は他の欄を埋めるけれど、彼らが最もやりたいのは自分の意見を述べることだからだ。とくに、消費者に関する話や怒りについてはそうだ。</simpara>
<simpara>&mdash; <emphasis>データジャーナリズムブログのマリアナ・ブーシャートによるガーディアンのジェームズ・ボールへのインタビュー</emphasis></simpara>
</section>
<section id="_データの利用と共有_ゴチック体ときれいな印刷_そして現実">
<title>データの利用と共有。ゴチック体ときれいな印刷、そして現実</title>
<simpara>この節では、データとデータベースに関する法律の状況と、使用可能な公共ライセンスや法的な手法を使ってあなたのデータを広げて行くためにあなたができることを簡単に見て行く。データドリブンジャーナリズムへのあなたの情熱を次の述べるようなもので弱めさせてはならない。データに対する法的な規制は常にあなたを邪魔するわけではない。法的規制があなたが公開したデータを使おうとする他の人たちを邪魔しないようにすることも容易にできる。</simpara>
<simpara>当たり前のことを言うと、データを獲得するというのは簡単にはなっていない。データがウェブ上に広く公開される以前は、あなたが必要とするデータセットを特定したとしても、誰であれそのデータセットのコピーを持っている人に、あなたがそれにアクセスできるようにするために頼まねばならなかったかもしれない。するためのコピーを誰が持っているか尋ねる必要があるかもしれない。書類が必要かもしれないし、郵便か訪問する必要があったかもしれない。いまや自分のコンピューターから相手のコンピューターに依頼を出し、こちらにコピーを送ってもらえば良い。概念的には似ているが、あなたはコピーをすぐに手に入れる。クリエーターや出版者が何もせずとも、おそらくあなたがコピーをダウンロードしたことを知らずとも。</simpara>
<simpara>プログラムでデータをダウンロードするのはどうか（それはしばしばスクレイピングと呼ばれる）、それに利用規約は？前のパラグラフを考えてみよう。あなたのブラウザーはちょうどそういうプログラムだ。利用規約がある種のプログラムのアクセスしか許さないとしたら？もしあなたが尋常ではない時間とお金があればそういうドキュメントを読めるかもしれないし、弁護士に助言を求めてなんとかするように頼むかもしれない。しかし普通は、愚かなことはせず、もしあなたのプログラムがサイトをたたけば、あなたのネットワークはそのサイトへのアクセスをブロックされるだろう。そうされるのも当然かもしれない。今はウェブのデータにアクセスしたり、スクレイピングしたりすることの実践が大量にある。もし実行しようとするならスクレイパーウィキのようなサイトにある事例を読めば有利なスタートが切れるだろう。</simpara>
<simpara>あなたがいったん興味あるデータを手にいれると、疑問に思い、読み込み、ソートし、ビジュアライズし、関連づけ、その他あなたがやりたい分析をデータのコピーをつかって実行できる。あなたは分析を公開できる。そしてそれはどんなデータも参照できる。（自由な言論にあるように）「事実はただである」というキャッチフレーズには多くのものがある。しかし、おそらくこれはデータベースかより広く非公式にはデータガバナンスの合法性を考えすぎる人たちの間だけのキャッチフレーズだろう。</simpara>
<simpara>もし、よいデータジャーナリスト、またはそうなろうとする人ならば、ただ事実やデータの要点を含む分析を公開しようとするだけでなく、分析を実行するためにつかったり、なにがしか付け加えたりしたデータセットやデータベースも公開しようとするだろうか。またはおそらくたんにデータをキュレートしているだけで、何の分析もしていないかもしれない（それでもいい。世界はキュレーターを必要としている）。もしあなたが誰か他の個人や団体が集めたデータをつかっているならば、問題があるかもしれない。（もしあなたのデータベースがすべてあなたによって集められたものならば、次のパラグラフを次の次のパラグラフでの実践を共有するためのモチベーションとして読んで欲しい）</simpara>
<simpara>もしあなたが著作権がどれほど創造的な仕事を規制しているかに詳しく、もし著作権保持者がその作品を使う許可を与えなかったら（もしくはその作品がパブリックドメインかあなたの使用がフェアユースのような例外であり、限定されているかもしれない）、著作権の保持者はあなたに使用や流通や演奏などをとめさせることができる。事実は無料だが、事実の集合体は同じように規制されるかもしれない。創造物に適用される著作権だけでなく、そこには多様な関連法がある。簡潔に言うと、データベースは創造的な作品として、著作権が適用されうる。多くの司法が「額の汗」に基づき、創造的ではない形の単なるデータベースの作製もそのデータベースを著作権の対象にする。とくに米国では、著作権がより最小の創造性で適用される傾向がある。（フェイスト社とルーラル社の電話帳をめぐる裁判事例が米国の典型例だ。もし見たいのであれば）。しかし、いくつかの裁判では、データベース権もまたデータベースを規制する。これは著作権からは分離されている。（適用範囲で多くの重複はある。とくに著作権が適用される創造性の限界がほとんど存在しない部分で）。もっともよく知られているのは、EUのデータベース権だ。繰り返すが、あなたが欧州にいるならば、あなたは他の組織や個人からデータベースを公開する前に許可を確実に得ることを望むかもしれない。</simpara>
<simpara>あきらかにそのような規制はデータドリブンジャーナリズムのエコシステムが育つのに最善の道ではない。（社会全体にとってもよくない。社会学者らがEUにsui generisの権利登場前にかたっており、以降の研修がそれが正しかったことを示した）。幸運にも、データベースの公開者として、そういった規制をデータベースから取り除くこともできる。本質的に先に許可を与えることによって（そのデータベースがあなたがさらなる許可を与える許可を持たない要素がないと仮定して）。これはあなたのデータベースをパブリックライセンスかパブリックドメインにリリースすることでそういうことができる。ちょうど多くのプログラマー彼らのコードを無料のオープンソースライセンスで提供し、他者がそのコードのうえに新たな制作ができるように。（データドリブンジャーナリズムはしばしばデータだけでなく、コードを含む。もちろんコードもリリースすべきだ。データと分析が再生可能になるように）。あなたのデータをオープンにすべきなたくさんの理由がある。例えば、聴衆が新たなビジュアライズやアプリケーションをそれで生み出し、あなたはリンクをはれるかもしれない。ガーディアンが彼らのデータジャーナリズムのフリッカーへの投稿でそうしたように。データセットは他のデータセットと結びつけられる。あなたやあなたの読者により大きなその話題への理解をもたらすために。他者があなたのデータですることはあなたに新しいストーリーをもたらす。もしくはストーリーのアイデアか違うデータドリブンプロジェクトのアイデアを。それはあなたに確実に名声をもたらすだろう。</simpara>
<figure id="FIG0415"><title>Open Data badges (Open Knowledge Foundation)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/04-GG.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/04-GG.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>パブリックライセンスでの公開が必要だと気づいたとき、質問が浮かび上がる。どのライセンスにするか。このトリッキーな質問の答えは、あなたがなそうとしている計画やコミュニティによる。もしくはあなたがあなたの仕事を提供したいと思っているところ。彼らが使うライセンスを使えば良い。もしより深く掘り下げたいなら、無料でオープンのライセンスから始めよ。つまり、だれでも何でもできる許可だ。（帰属と継承は必要かもしれない）。フリーソフトの定義とオープンソースの定義がソフトウェア、データベース含む、になしたものは、作品をオープンにするものを定義し、オープンライセンスがユーザーに許すことを定義したことだ。</simpara>
<simpara>Open Knowledge Definition <footnote><simpara>Open Knowledge のプロジェクトの一つ。</simpara></footnote> のサイトに。<ulink url="http://opendefinition.org/licenses/">現在利用可能なライセンスの一覧</ulink>がある。まとめると、基本的に３つのクラスのライセンスがある。</simpara>
<variablelist>
<varlistentry>
<term>
パブリックドメイン献呈
</term>
<listitem>
<simpara>
  これらはまた、最大限に寛容なライセンスとして機能する。その成果物を使用する際に一切の条件がない。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
自由もしくは帰属表示ライセンス
</term>
<listitem>
<simpara>
  クレジットを入れることがこれらのライセンスの唯一の重要な条件。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
複製改変自由、二次著作物も改変可能、継承ライセンス
</term>
<listitem>
<simpara>
  これらもまたもし公開するのであれば、同じライセンスを共有するような修正を必要とする。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>もしあなたが誰かがオープンライセンスで公開したデータセットを使っているのであれば、上記のパラグラフがオープンライセンスの条件の満たし方の簡便なガイドであることに留意しよう。あなたがもっとも目にしそうなライセンス、クリエイティブ顧問図やオープンデータコモンズや様々な政府、通常は簡単に重要な条件が何かを示す要約を取り上げる。典型的には、ライセンスはデータセットをダウンロードしたサイトで示されている。（もちろんスクレイプしたサイトもデータセットをもっている）。フォーマットにそってデータセットそのもののなかで目立つ場所にもある。これらのマーク付けはあなたがデーターセットを公開するときにも、なすべきことだ。</simpara>
<simpara>最初に戻る。もしあなたが必要とするデータセットがいまもオンラインで入手できない場合、もしくはなんらかのアクセス規制されていたら？あなたがアクセスできるよう求めるのに加え、世界が再利用できるようにデータがオープンされることを求めよう。それらのデータでどんなすばらしいことができるかの指標を与えることができる。</simpara>
<simpara>世界との共有はプライバシーやその他の考慮、規制がいくつかのデータセットにはくると連想させる。たしかにオープンデータは多くの技術的な障壁、著作権のような障壁を下げる。しかし、それはそのホッカの適用可能な法律に従わなくていいことを意味しない。それはいつもそういうものだ。そしてそこには巨大な資源とときにジャーナリストからの保護があり、それこそ調査する必要があるとあなたの良識が指し示すものだ。</simpara>
<simpara>グッドラック！あなたが法的なリスクを管理する必要以上に、必要なことはまだまだあるだろう。</simpara>
<simpara>&mdash;　<emphasis>クリエイティブ・コモンズのマイク・リンクスヴァイヤー</emphasis></simpara>
</section>
</section>
<section id="_データを理解する">
<title>データを理解する</title>
<informalfigure role="informal">
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-00-cover.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-00-cover.png</phrase></textobject>
</mediaobject>
</informalfigure>
<?dbfo-need height="1in"?>
<simpara>データを手に入れたとき、あなたは何をするだろうか？何を探すだろう？どんなツールを使うべきだろう？このセクションは、あなたのデータ・リテラシーを改善するためのいくつかのアイデア、数字と統計と向き合うための秘訣、そして、未整理で、不完全で、しばしばドキュメント不足のデータ・セットの作業をするときに気をつけるべきことから始まる。それから我々は、データからストーリーを見つけ出す方法や、データ・ジャーナリストの選ぶツール、そしてあなたが扱っているトピックにあなたの見識を加えるのにデータ・ビジュアライゼーションを活用する方法についても学ぶ。</simpara>
<section id="_３つのシンプルな手順でデータが読み書きできるようになるには">
<title>３つのシンプルな手順でデータが読み書きできるようになるには</title>
<simpara>リテラシーが"知識を読み、統一のとれた文章を書き、印刷物を批評的に考える"ことであるように、データのリテラシーとは、データを獲得し、統一のとれたデータを作成し、批評的にデータを考える能力のことである。データのリテラシーは、統計的な知識だけでなく、巨大なデータの集まりをどのように扱うか、それがどのように作成されたのか、どうやって複数のデータの集合をつなげるか、それらをどのように読み解くかを含んでいる。</simpara>
<figure id="FIG051"><title><ulink url="http://www.flickr.com/photos/jdhancock/3386035827/">Digging into data</ulink> (photo by JDHancock)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-MM.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-MM.jpg</phrase></textobject>
</mediaobject>
</figure>
<?dbfo-need height="1in"?>
<simpara>ポインターのニュース大学は、ジャーナリストのために数学のクラスを提供している。そこではレポーターがパーセンテージの変化や平均などの考え方を学んでいる。面白い事に、こうした手法は、ポインターのオフィスの近くのフロリダ高校で、10歳から11歳の5年生の授業でも教えられている。</simpara>
<simpara>ジャーナリストが、通常高校に入る前に教えられるような数学のトピックに助けを必要としているという事実は、ニュースルームがデータの読み書きからどれだけ離れているかを示している。これは問題だ。あるデータジャーナリストが確信間隔の意味を知らないとしたら、気候の変化における大量の数値を上手く扱うことなどできるだろうか？</simpara>
<simpara>レポーターがより上手にデータを扱うのに、統計の学位が必要という訳では無い。数字を前にしたとき、いくつかの簡単なトリックでよりよいストーリーを紡ぐことができる。マックス・プランク・インスティテュートのガード・ギガレンザー教授が言うように、洞察を持って使わなければ、よりよりツールがジャーナリズムをよりよいものにすることはできない。</simpara>
<simpara>もしあなたが数学や統計の知識を持っていないとしても、この３つの質問をすることで簡単に経験を積んだデータジャーナリストになることができる。</simpara>
<section id="_1_データはどのように収集されたのか">
<title>1. データはどのように収集されたのか？</title>
<section id="_驚異的なgdpの成長">
<title>驚異的なGDPの成長</title>
<simpara>すばらしいデータを取り出すための最も簡単な手段は、ねつ造する事だ。これは自明なことだが、GDPの数値を元になされたコメントはにせものであることが多い。前イギリス大使のクレイグ・マレイは彼の書籍『サマルカンドでの殺人』で、ウズベキスタンの成長率は政府と海外諸国の間の交渉に従っていることを紹介している。言い換えれば、その数値は国内の経済とは一切関係が無い。</simpara>
<simpara>GDPは、政府が彼らにとっての主な収入源である付加価値税を守るための指標として、一番よく使われる。政府が付加価値税によって運営されていない場合、あるいは政府が予算を公開していない場合、GDPを調べる理由はないし、ねつ造したほうが気楽である。</simpara>
</section>
<section id="_犯罪の数は常に増加している">
<title>犯罪の数は常に増加している</title>
<simpara>"スペインの犯罪数が3%増加した"とEl Paisが報じた。ブリュッセルでは、不法滞在者や薬物中毒による犯罪が増加していると、RTLは言う。この種類の警察による統計を元にしたレポートは良くあるが、暴力ざたについては多くを語らない。</simpara>
<simpara>我々は、EU諸国の中ではそうしたデータが改ざんされていないことを信じる事ができる。しかし、警察官は誘惑に弱い。たとえば警官の働きが問題の解決で評価されるとき、警官は調査を必要としない問題を可能な限り多くレポートした方が良いという事になる。そうした犯罪の一つが、マリファナの所持である。この事は、この15年間でフランスでの薬物関連の犯罪の数が４倍になったにも関わらず消費量は変わっていない事の説明になる。</simpara>
</section>
<section id="_あなたにできること">
<title>あなたにできること</title>
<simpara>数値の信頼性に疑いを持った時は、必ず２重にチェックをする。政治家の発言を引用する時のように。ウズベキスタンのケースに関して言うと、その地域にしばらくの間住んでいた人に１本電話を入れるだけでも十分だ(<emphasis>この国は、公式発表にあるように1995年の３倍裕福になったと感じますか？</emphasis>)。</simpara>
<simpara>警察のデータに関しては、社会学者はしばしば被害者の調査を行い、人々に犯罪の被害を被ったかを訪ねる。こうした調査結果は、警察のデータより不安要素がかなり少ない。それがおそらく、こうした事実がニュースのヘッドラインを飾らない理由だろう。</simpara>
<simpara>例えばベンフォードの法則のようなテストを使うことで、データの信頼性を正確に見極める事ができるが、あなたが批判的な思考を行う事に勝るものはない。</simpara>
</section>
</section>
<section id="_2_そこから何を学ぶことができるか">
<title>2. そこから何を学ぶことができるか？</title>
<section id="_多発性硬化症のリスクは夜に働くと倍になる">
<title>多発性硬化症のリスクは夜に働くと倍になる</title>
<simpara>まっとうな思考を持ったドイツ人なら誰でも、この見出しを見た後夜勤をやめてしまうだろう。しかし、この記事は結局のところ何がリスクなのかを我々に教えてはくれない。</simpara>
<simpara>1000人のドイツ人を例にとると、そのうちの１人は多発性硬化症になるだろう。いま、その1000人のドイツ人が全て夜勤をしたら、多発性硬化症の患者の数は2人に跳ね上がる。シフト勤務をした場合に多発性硬化症になるリスクの増分は、100%ではなくて1000分の1だ。この情報が、その仕事をするか思い悩む時により有益である事は間違いない。</simpara>
</section>
<section id="_平均で15人のヨーロッパ人に1人は文字が全く読めない">
<title>平均で15人のヨーロッパ人に1人は文字が全く読めない</title>
<simpara>この見出しは、恐ろしいことのように見える。これは実際に正しい。5億人のヨーロッパ人の間で、3600万人はおそらく文字の読み方を知らない。付け加えると、3600万人は7歳以下である(Eurostatのデータ)。</simpara>
<simpara>平均について文章を書く時は、常に「何に関する平均か？」を考えるべきだ。この言及は均質な集団を参照しているだろうか？ たとえば、均質ではない分布パターンは、なぜほとんどの人が平均よりも上手に車を運転できるのかを説明している。多くの人は、人生においてまったくのゼロかあるいはただの一度しか事故を経験しない。ほんの一握りの、向こう見ずなドライバーがたくさんの事故を起こして、平均の数値を多くの人が経験するよりはるかに高く押し上げるのだ。同じ事が、収入の分布にも言える。多くの人は平均よりも少ない収入しか得ていない。</simpara>
</section>
<section id="_あなたにできること_2">
<title>あなたにできること</title>
<simpara>常に分布と基準レートを考慮に入れる。平均と中央値、最頻値(分布の中で最も頻繁に出現する値)もチェックすることで、あるデータについての見識を高める事ができる。多発性硬化症の例にあるように、数値の桁を知っていれば、文脈付けがより簡単になる。最後に、レポートを100分の1</simpara>
</section>
</section>
<section id="_3_その情報はどれだけ信用できるか">
<title>3. その情報はどれだけ信用できるか？</title>
<section id="_統計サンプルのサイズの問題">
<title>統計サンプルのサイズの問題</title>
<simpara>”80%の人が、裁判のシステムに不満を持っている”と、サラゴザのディアロ・デ・ナバラの調査結果は言う。800人の回答者の結果から、4600万人のスペイン人の考えを推測できるだろうか？ 実際、これは論争のタネになっている。</simpara>
<simpara>大人数(数千人以上)の人を調査するのに、1000人以上の回答者がいればエラーの幅を3%以下に抑えることができる。これは、同じ調査を全く違うサンプルを対象に行うと、10回に9回は最初に得たのと3%以内の違いしか無い結果を得ることを意味する。統計はパワフルな手段で、対象となるサンプルの大きさは信頼できない調査の原因になることはめったにない。</simpara>
</section>
<section id="_お茶を飲むと脳卒中のリスクが低減される">
<title>お茶を飲むと脳卒中のリスクが低減される</title>
<simpara>お茶を飲むことの効能について書いた記事は良くある。お茶は心筋梗塞のリスクを低減するというこのダイ・ウェルトの小さな記事も例外では無い。お茶の効果についての研究は熱心にされているが、リサーチの多くはダイエット、職業やスポーツなどの生活様式を考慮できていない。</simpara>
<simpara>多くの国で、お茶は健康を気にする上流階級のための飲み物になっている。もしリサーチャーがお茶を研究する際に生活様式を管理していないなら、そうした研究結果は「金持ちはより健康だ。そして、彼らはたぶんお茶を飲んでいる」という程度の意味しか持たない。</simpara>
</section>
<section id="_あなたにできること_3">
<title>あなたにできること</title>
<simpara>お茶の研究における相関とエラーマージンの背景にある数字は、全くもって正しい。少なくとも多くの場合に。しかし、リサーチャーが相関の相関(お茶を飲むことはスポーツをすることに関連があるというような)を考慮に入れていないなら、レポートは大して意味を持たない。</simpara>
<simpara>一人のジャーナリストとして、よほど疑いが無い限り数値を含む結果に挑むのはほとんど意味が無い。しかし、リサーチャーが関連する情報を考慮していないことをチェックするのは、たやすいことだ。</simpara>
<simpara>&mdash; <emphasis>Nicolas Kayser-Bril, Journalism++</emphasis></simpara>
</section>
</section>
</section>
<section id="_ニュースの中の数値を扱うためのヒント">
<title>ニュースの中の数値を扱うためのヒント</title>
<simpara>データを扱うために一番重要な事は、楽しむということだ。データは近寄りがたいものに見えるかもしれない。しかし、データを恐れていては何もできなくなってしまう。何か楽しむもの、調べがいのあるものとして扱えば、データはいとも簡単にその秘密とストーリーを示してくれる。だから、データを他の証拠と同じように簡単に、公平に扱えば良い。とりわけ、データを扱うことをイマジネーションの練習だと思うと良い。</simpara>
<simpara>疑り深くある事とシニカルである事を混同してはいけない。懐疑的であることは良いことだ。シニカルとは、あきらめてやめてしまうことを指す。もしあなたがデータジャーナリズムを信じるなら、この本を読んでいるのだからたぶんそうだと思うが、データは、嘘やいまいましい風刺画や斜に構えたヘッドラインより遙かに優れたものを持っていると信じなくてはいけない。</simpara>
<simpara>もし私が不況の時に飲酒の量が増えると言ったら、あなたはそれはみんなが落ち込んでいるからだと答えるだろう。もし私が飲酒の量が減ると言ったら、あなたはみんなが破産してしまったからだと言うだろう。言い換えれば、データが伝えることはあなたが考える解釈に影響を与えない。すなわち、物事はどちらにせよ悲惨なのだ。もし飲酒の量がふえるなら、それは悪いことだ。もし減るなら、それも悪いことだ。ここでの要点は、もしあなたがデータを信じるなら、あなたが自分のムードや信念や期待にとらわれる前に、データ自身に語らせるべきだということだ。</simpara>
<simpara>不確実性は問題ではない。我々は数値を権威と確実性に結びつけて考える。しかし、つまるところ答えなどというものはない。あるいは、その答えが我々にできる最善のものだとしてもなお、それが実際にはかすりもしないということがあり得るのだ。私は、我々がそうしたことを伝えるべきだと思う。もしそれがストーリーをスポイルしてしまうというなら、私はそれは新しい質問を生み出すためのすばらしい方法だと言うだろう。</simpara>
<itemizedlist>
<listitem>
<simpara>
The investigation is a story. The story of how you tried to find out can make great journalism, as you go from one piece of evidence to another&#8212;and this applies in spades to the evidence from data, where one number will seldom do. Different sources provide new angles, new ideas, and richer understanding. I wonder if we&#8217;re too hung up on wanting to be authoritative and tell people the answer&#8212;and so we miss a trick by not showing the sleuthing.
</simpara>
</listitem>
</itemizedlist>
<?dbfo-need height="1in"?>
<simpara>一番の質問は、良くあるものだ。これは本当に大きな数字なのか？この数値はどこから来たのか？あなたは、あなたが思っているこの数値の意義が正しいと確信できるか？こうしたものは、データについて考えるきっかけになる。一つの数値を眺めることで絞り出されたもの、現実の世界の複雑さ、広い範囲で時を超えて比較されるもの、グループまたはチリ。つまりコンテキストだ。</simpara>
<simpara>&mdash; <emphasis>マイケル・ブラストランド, フリーランス・ジャーナリスト</emphasis></simpara>
</section>
<section id="_データを扱うための基礎的な手順">
<title>データを扱うための基礎的な手順</title>
<simpara>あなたがデータプロジェクトを始める時に、少なくとも３つのキーコンセプトを理解する必要がある:</simpara>
<itemizedlist>
<listitem>
<simpara>
データを求める際に、あなたが答えようとしている質問のリストから始めるべきだ。
</simpara>
</listitem>
<listitem>
<simpara>
データはたいていひどい状態で、奇麗にする必要がある。
</simpara>
</listitem>
<listitem>
<simpara>
データには明示的になっていない特徴があるかもしれない。
</simpara>
</listitem>
</itemizedlist>
<figure id="FIG052"><title>ひどいデータ</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-MM.png" scale="89"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-MM.png</phrase></textobject>
</mediaobject>
</figure>
<section id="_あなたが答えようとしている質問を理解する">
<title>あなたが答えようとしている質問を理解する</title>
<simpara>多くの場合、データを処理する事は生身の情報源にインタービューをする事に似ている。 あなたは、あるデータについて質問をして答えを引き出そうとする。しかし、情報源の人が自分たちが知っている事しか答えてくれないように、一塊のデータは正しい情報を持っている質問にしか答えてくれない。つまり、あなたはデータを取得する前に自分がどんな質問に答える必要があるのかを注意深く考える必要があるのだ。基本的には、あなたは逆向きに作業を進めることになる。最初にデータによって証明できる供述のリストを</simpara>
<simpara>犯罪レポートに関するサンプルを考えてみよう。あなたがあなたの住む都市の犯罪の傾向に注目したストーリーを考えるとしよう。あなたが論じようとしているのは、異なる犯罪が一番発生しやすい一日のうちの時間帯と曜日、その都市のどのエリアが様々な犯罪カテゴリのホットスポットかである。</simpara>
<simpara>あなたはあなたが要求するデータが犯罪の報告された日と時間、犯罪の種類（殺人、窃盗、強盗など）、そして犯罪が起こった場所の情報を含んでいなければならない事に気づく。だから、日付と時間、犯罪のカテゴリと住所があなたがそうした質問に答えるのに必要な最低限の要素だ。</simpara>
<simpara>しかし、この４つの変数のデータセットでは答える事ができない興味深い質問がたくさんあることに注意してほしい。例えば被害者の人種と性別、盗まれたものの総額、または最も多く逮捕者を出した警官は誰かなど。それに、あなたは例えば３年間といった特定の機関の記録しか得る事ができない。こうした疑問はあなたの想定していたストーリーの範囲の外にあるかもしれないが、それは問題ではない。しかし、データの分析をはじめてから突然に都市の地域毎にどれだけの犯罪が逮捕によって解決されたかの比率を知りたくはないだろう。</simpara>
<simpara>ここから学べる事はデータベースにあるレコードとレコードに含まれる値をすべて要求するのは、目の前にあるストーリーのための質問に答えるだけの部分的なデータを要求するよりも良いアイデアだと言う事だ。（実際に、部分的なデータを取得するのにエージェンシーにプログラミングを依頼するなら、すべてのデータを取得する方が安く済む）あなたはいつでも自分のデータの一部を抽出する事ができるし、すべてのデータセットにアクセスできれば、レポートを書いている最中に後から思いつく新しい質問にも答えられる。そして、ストーリーを補足する他の質問のアイデアを与えてくれるかもしれない。守秘義務に関する法律やほかのポリシーによってあるデータ、犠牲者の身元や匿名の情報源などは公開できないかもしれない。しかし、部分的なデータベースであっても何も無いよりずいぶんと良いものだ。編集されたデータベースが、どの質問に答える事ができてどの質問に答える事ができないかをあなたが理解している限りは。</simpara>
</section>
<section id="_乱雑なデータをきれいにする">
<title>乱雑なデータをきれいにする</title>
<simpara>データベースに関する作業で最も大きな問題の一つは、しばしばあなたが分析のために使うデータが役所のために集められているということだ。問題は正確さの標準がこの２つの間でかなり異なる事だ。</simpara>
<simpara>例えば、犯罪者の裁判システムのデータベースの主要な機能は、被告人ジョーンズを監獄から出して裁判官スミスの元に公聴会の時間に確実に連れて行く事だ。このためにはジョーンズの誕生日が間違っていても、彼の住所が誤って記載されていても、あるいはミドルネームが間違っていることさえ大きな問題にはならない。一般的には、このシステムは不完全なレコードをつかってもジョーンズをスミスの裁判部屋に約束通りの時間に連れて行く事ができる。</simpara>
<simpara>しかしそうした間違いはデータ・ジャーナリストがデータベースからパターンを発見しようとする試みを歪ませる。そのため、あたらしいデータセットを手に入れた際にあなたが最初にするべき仕事の大部分は、データがどれだけひどいかを調査することであり、それを奇麗にすることである。データのひどさをチェックする手っ取り早くて有効な手段は、カテゴリ別の値の頻度の表を作る事で、そうするとそれぞれの値は比較的小さな違いしか持たないはずだ。（例えばExcelなら、フィルタかピボット・テーブルを使う事でこれを実現できる）</simpara>
<simpara>簡単な例として”性別”を取り上げてみよう。あなたは性別のフィールドに例えばMale、Female、M、F、1、0、MALE、FEMALEといったような値がごちゃまぜになっているのを見つけるかもしれないし、"Femal"のような綴り間違いも含まれているかもしれない。性別の分析を正しく行うためには、あなたは表記の統一ー恐らくMとFにーを行い、そしてすべての値をこの表記に合わせなければいけない。同じような問題を抱えたデータベースとして、もう一つアメリカの選挙戦の収支レポートがある。そこでは、職業欄に“Lawyer”、“Attorney”。“Atty”、“Counsel”、“Trial Lawyer” などのたくさんの異なる表記と綴り間違いが入っていたりするかもしれない。ここでもやはり、場所の表記をもっと短いリストになるように標準化の作業が必要だ。</simpara>
<simpara>名前を取り扱っているとき、データの掃除はさらに面倒になる。"Joseph T. Smith"、"Joseph Smith"、"J.T.Smith"、"Jos. Smith"そして"Joe Smith"はすべて同じ人だろうか？ それを決めるのには、住所や誕生日などの他の値を見るか、あるいはもっと大変な調査を行う必要があるかもしれない。Google Refineのようなツールは、データの掃除と標準化の作業のスピードを早めて退屈を軽減してくれる。</simpara>
<sidebar>
<title>Dirty Data</title>
<simpara>Thanks to the generally strong public records laws in the United States, getting data here isn&#8217;t as big a problem as it can be in many other countries. But once we get it, we still face the problems of working with data that has been gathered for bureaucratic reasons, not for analytic reasons. The data often is &#8220;dirty,&#8221; with values that aren&#8217;t standardized. Several times I have received data that doesn&#8217;t match up to the supposed file layout and data dictionary that accompanies it. Some agencies will insist on giving you the data in awkward formats like .pdf, which have to be converted. Problems like these make you appreciate it when you do get an occasional no-hassle dataset.</simpara>
<simpara>&mdash; <emphasis>Steve Doig, Walter Cronkite School of Journalism, Arizona State University</emphasis></simpara>
</sidebar>
</section>
<section id="_データは解説されていない特徴を持っているかもしれない">
<title>データは解説されていない特徴を持っているかもしれない</title>
<simpara>データベースの重要な鍵となるのはデータ辞書と呼ばれるものだ。典型的には、このファイル（テキストやPDF、スプレッドシートの時もある）は、データファイルがどのようなフォーマットになっているか（区切りを持つテキスト、固定長のテキスト、エクセル、ディーベースなど）、要素の並べ替えの順番、それぞれの要素の名前とデータのタイプ（文字列、整数、１０進数など）。あなたはこの情報をあなたが使おうとしている分析用のソフトウェア（エクセル、アクセス、SPSS、フュージョン・テーブル、各種SQLなど）に適切に読み込むために使う。</simpara>
<simpara>The other key element of a data dictionary is an explanation of any codes being used by particular variables. For instance, Gender may be coded so that "1=Male" and "0=Female." Crimes may be coded by your jurisdiction&#8217;s statute numbers for each kind of crime. Hospital treatment records may use any of hundreds of 5-digit codes for the diagnoses of the conditions for which a patient is being treated. Without the data dictionary, these datasets could be difficult or even impossible to analyze properly.</simpara>
<simpara>But even with a data dictionary in hand, there can be problems. An example happened to reporters at the Miami Herald in Florida some years ago when they were doing an analysis of the varying rates of punishment that different judges were giving to people arrested for driving while intoxicated. The reporters acquired the conviction records from the court system and analyzed the numbers in the three different punishment variables in the data dictionary: amount of prison time given, amount of jail time given, and amount of fine given. These numbers varied quite a bit amongst the judges, giving the reporters' evidence for a story about how some judges were harsh and some were lenient.</simpara>
<simpara>But for every judge, about 1-2 percent of the cases showed no prison time, no jail time, and no fine. So the chart showing the sentencing patterns for each judge included a tiny amount of cases as &#8220;No punishment,&#8221; almost as an afterthought. When the story and chart was printed, the judges howled in complaint, saying the Herald was accusing them of breaking a state law that required that anyone convicted of drunk driving be punished.</simpara>
<simpara>しかし、データ辞書を手にしたとしても、まだ問題は残っている。数年前にフロリダのマイアミヘラルドのレポーター達、飲酒運転で逮捕された人々に下された刑罰の審判結果の裁判官による違いを分析していた時に、こんな事が起こった。レポーター達は有罪の記録を裁判所のシステムから取得し、データの中の３つの異なる刑罰についての数値ー拘置された期間、刑務所の刑期を分析した。 こうした数値は審判によってかなりばらつきがあり、レポーター達にある裁判官は厳しく、またある裁判官は寛大であるというストーリーの証拠をもたらし。</simpara>
<simpara>しかし全ての判決の中で、１〜２パーセントのケースは交流期間や刑期を記していなかった。だからそれぞれの判決のパターンを示していたチャート に"無罪"はごくわずかしか無かった。そのストーリーとチャートが印刷されたとき、裁判官達は口々に文句を言った。ヘラルドが裁判官達を全ての飲酒運転違反者は罰せられるという州の法律を破っていると非難しているとして。</simpara>
<simpara>&mdash; <emphasis>スティーブ・ドイグ アリゾナ州立大学ウォルター・クロンカイト・ジャーナリズム・スクール</emphasis></simpara>
<?dbfo-need height="2in"?>
<sidebar>
<title>Mixed Up, Hidden and Absent Data</title>
<simpara>I remember a funny situation where we tried to access the Hungarian data on EU farm subsidies: it was all there&#8212;but in an excessively heavy PDF document and mixed up with data on national farm subsidies. Our programmers had to work for <emphasis>hours</emphasis> before the data was useful.</simpara>
<simpara>We also had a pretty interesting time with data about EU fish subsidies, which national payment agencies in all 27 Member States are obliged to disclose. Here&#8217;s an excerpt from <ulink url="http://bit.ly/alfter-eu27">a report we wrote on the topic</ulink>: &#8220;In the United Kingdom, for example, the format of the data varies from very user-friendly HTML search pages to PDF overviews or even lists of recipients in varying formats hidden away at the bottom of press releases. All this is within just one member state. In Germany and Bulgaria, meanwhile, empty lists are published. The appropriate headings are there but without any data.&#8221;</simpara>
<simpara>&mdash; <emphasis>Brigitte Alfter, Journalismfund.eu</emphasis></simpara>
</sidebar>
</section>
</section>
<section id="_一塊32ポンドのパン">
<title>一塊32ポンドのパン</title>
<simpara>日曜日のWales紙の記事に、ウェールズ政府がグルテンフリーの商品の処方箋にどれだけの予算をつかっているかが書かれている。見出しには一塊のパンに32ポンドを使っているとあるが、しかし実際にはこれはそれぞれ2.82ポンドの塊11個分のことだ。</simpara>
<simpara>処方箋毎のコストとして表記していた。しかし、彼らは処方箋や量についての定義の情報をデータ辞書に記載していなかった。</simpara>
<simpara>だからこの記述は、いくつかのパンのつめあわせという実際の姿とは異なり、個別の項目ーー例えばパン１斤ーーを指すものだと理解されていた。</simpara>
<simpara>回答を書いた人、プレスオフィスの人のいずれも、月曜日にその記事が公開されるまで量を問題にしなかった。</simpara>
<simpara>だから、政府が出すデータの説明書きがそこに何が含まれているのかを理解する助けになると考えてはいけないし、あなたが誤った認識を告げた後ですら、データの責任者がデータが間違っていると気がつくと考えてもいけない。</simpara>
<simpara>一般的に新聞はヘッドライン映えする事象を探しているので、よほど明確に解釈が否定されるのでなければ、ヘッドラインを飾れるものを詳細にチェックしてストーリーを台無しにしようとはしない。特に締め切りの間際には。</simpara>
<figure id="FIG053"><title>グルテンフリーのパンがウェールズの納税者に３２ポンドかかっているという証書 (ウェールズ・オンライン)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-AA.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-AA.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>しかし、ジャーナリストには馬鹿げたクレームもチェックする義務がある。もしかすると、それが記事をニュースリストから外すことになるとしても。</simpara>
<simpara>&mdash; <emphasis>クレア・ミラー, ウェールズ・オンライン</emphasis></simpara>
</section>
<section id="_データで始まり_ストーリーで終わる">
<title>データで始まり、ストーリーで終わる</title>
<simpara>読者を引き込むためには、見出しの数字で注目させなければならない。元のデータに当たらなくても、ストーリーだけでちゃんと読めるものである必要がある。見出しはエキサイティングなものに。そして、読者は誰なのかを忘れてはいけない。</simpara>
<simpara>こうした事例として、TBIJ（The Bureau of Investigative Journalism：非営利の調査報道機関）が、欧州委員会の財政資料 <ulink url="http://bit.ly/ec-fts">Financial Transparency System</ulink>をソースに報道したプロジェクトがある。このストーリーは特徴的な切り口で、データにアプローチしている。</simpara>
<simpara>データを見てみると、「カクテル」「ゴルフ」「日帰り旅行」といった用語が見られる。項目を選ぶと、欧州委員会がこうした事柄に費やした金額がわかる。ここから様々な疑問が生じ、ストーリーとなっていく。</simpara>
<simpara>だが、キーとなる用語が必ずしも思い通りになるとは限らない――時には自分が何を求めているのか、考え直す必要もあるだろう。このプロジェクトで我々は、委員がプライベートジェットにいくら費やしたかも明らかにしたかったが、データセットに「プライベートジェット」というフレーズはない。データからでなく、業者から名目を取り寄せる必要があった。委員会が使っている業者が「アベラーグ」ということがわかったので、そこに問い合わせ委員が使った金額を得ることができた。</simpara>
<simpara>このケースでは、データを得る目的がはっきりしていた。見出しになる数字を見つけることだ。そこから先は、後からついてくる。</simpara>
<simpara>ブラックリストや除外されたものから始める方法もある。データに載っていないものを知れば、データからストーリーを簡単に導き出せるのだ！ ファイナンシャル・タイムズとTBIJがコラボレーションした、EU構造基金のプロジェクトは、この方法がうまくいった事例だ。</simpara>
<simpara>構造基金の受け取りが禁じられている会社や団体について、委員会が定めたルールを元に、我々はデータを請求した。たとえば、タバコやタバコ製造者の支出だ。</simpara>
<simpara>タバコ会社や製造者、生産者の名前でデータを探すと、ブリティッシュ・アメリカン・タバコがドイツの工場をめぐって、150万ユーロを受け取っていたことが明らかになった。</simpara>
<simpara>委員会のルール外の金銭のやりとりについて、データからすぐにストーリーを導き出したわけだ。</simpara>
<simpara>データから何が見つかるかはわからない。だからまずはデータを見てみよう。恐れることはない。この方法は、大きい数字だとか、極端な数字だとか、もっとも一般的な数字だとか、はっきりとした特徴をあぶり出すときに、もっともうまくいくアプローチだ。</simpara>
<simpara>&mdash; <emphasis>カーライン・バー, Citywire</emphasis></simpara>
</section>
<section id="_データは語る">
<title>データは語る</title>
<simpara>データジャーナリズムというと、数字が示すある側面をすばやく、わかりやすく、かつ機能的に伝えるビジュアリゼーションや、地域の病院や通りを検索して表示できるデータベースといった、データをどう表現するかを扱うもの、と思う人もいるだろう。もちろん、それも価値がある。だが、他の形のジャーナリズムと同じように、データジャーナリズムも、やはりストーリーなのだ。では、どんなストーリーをデータから見出すのか？ BBCでの私の経験に基づいて、リストを示すとともに、データによるストーリーの種類を分類してみよう。</simpara>
<simpara>このリストを頭に入れておけば、データを分析している時だけでなく、その前段階、データを収集しているとき（誰でもアクセスできるデータを探すときであれ、自分で望む情報を集めるときであれ）にも、役に立つだろう。</simpara>
<variablelist>
<varlistentry>
<term>
数字を示す
</term>
<listitem>
<simpara>
  できるかぎりシンプルなストーリーであること。数字を数えあげるか、合計すること。たとえば、「この国の地方自治体は昨年、クリップに数十億ポンドを費やした」というように。しかし、その数字が多いのか、少ないのかわからないこともある。そうしたときには、コンテクスト、文脈が必要になる。それはこのようなものだ。
</simpara>
<variablelist>
<varlistentry>
<term>
比率で表す
</term>
<listitem>
<simpara>
  「昨年、地方自治体は、文房具の予算のうち、3分の2をクリップに費やした」。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
内部のものと比較する
</term>
<listitem>
<simpara>
  「地方自治体は、お年寄り向けの給食サービスよりも、クリップの方に多くの予算を費やしている」。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
外部のものと比較する
</term>
<listitem>
<simpara>
  「地方自治体は昨年、国の援助予算の2倍の額をクリップに費やした」。
</simpara>
</listitem>
</varlistentry>
</variablelist>
</listitem>
</varlistentry>
</variablelist>
<simpara>データによってコンテクストを示したり、比較する方法は他にもある。</simpara>
<variablelist>
<varlistentry>
<term>
経年変化
</term>
<listitem>
<simpara>
  「地方自治体は過去4年と比較して、3倍もの予算をクリップに費やしている」。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
"他のものとの比較"
</term>
<listitem>
<simpara>
  他の国や地域、組織と比較する方法もある。ただし、比較する基準はフェアでなくてはならない（地域で比較する場合、人口の違いは考慮に入れなければならないだろう）。「ボーセッシャーは一人あたり、国の平均の4倍ものお金をクリップに費やしている」。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>データをグループごとに分割してもよい:</simpara>
<variablelist>
<varlistentry>
<term>
カテゴリによる分析
</term>
<listitem>
<simpara>
  「パープル党政権の議会はイエロー党政権下の時よりも50％も多く、ペーパークリップに費やしている」。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>数字で要素を関連付けることもできる:</simpara>
<variablelist>
<varlistentry>
<term>
関連付ける
</term>
<listitem>
<simpara>
  「文房具会社から献金を受けている議員らが運営する議会は、1ポンドの献金につき、平均で100ポンドも多くペーパークリップに費やしている」
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>もちろん、因果と相関は別物であることは忘れてはいけない。</simpara>
<?dbfo-need height="1in"?>
<simpara>もしあなたがクリップの予算について調べているとしたら、どんな数字を追いかけますか。</simpara>
<itemizedlist>
<listitem>
<simpara>
あるコンテクストにおける、予算の総額？
  *地域、時間、または別の基準で比較？
  *比較がフェアになるように、たとえば人口のような別のデータを使っていますか？
  *面白い分析になるように、他のデータと比較したり、関連付けたりしていますか？
</simpara>
</listitem>
</itemizedlist>
<simpara>&mdash; <emphasis>マーティン・ローゼンバウム, BBC</emphasis></simpara>
</section>
<section id="_データ_ジャーナリスト達のお気に入りのツール">
<title>データ・ジャーナリスト達のお気に入りのツール</title>
<simpara>プシュー。これは、あなたのデータが密閉容器から漏れ出す音だ。さて、どうする？何を探す？どんなツールを使う？我々はデータ・ジャーナリスト達に彼らがどうやってデータを処理しているのか教えてくれるように頼んだ。ここに彼らの答えがある：</simpara>
<blockquote>
<attribution>
リサ・エヴァンス
<citetitle>ガーディアン</citetitle>
</attribution>
<simpara>ガーディアン・データブログでは、読者とのインタラクションを好み、彼らに我々のデータジャーナリズムを素早く再現できるようにして、読者達が私たちの成果を基に何かを作ったり、時には我々が理解できなかった事を理解したりするようにしている。だから、データ・ツールは直感的であるほど良い。我々は、誰もがプログラミング言語の習得や特別なトレーニング、高額な費用なしにこつをつかむ事が出来るツールを選んでいる。</simpara>
<simpara>このために、私たちはGoogleの製品を非常に良く使っている。我々が整理して公開するデータセットは全てGoogle Spreadsheetで提供していて、Googleアカウントを持っている人なら誰でもデータをダウンロードして、彼らのアカウントに読み込んだり独自のチャートを作ったり、あるいはデータをソートしてピボット・テーブルを作る事ができるし、自分の好きなツールにデータを読み込む事も出来る。</simpara>
<simpara>データをマッピングするのに、我々はグーグル・フュージョン・テーブル（Google Fusion Tables）を使う。ヒート・マップをフュージョンで作るときは、我々の使ったKMLファイルをシェアして、読者がそれをダウンロードして彼ら自身のーー恐らくデータブログのオリジナルの地図に幾層かのデータを追加したものーーを制作できるようにしている。そのほかのグーグルのツールの優れた点は、我々の読者がブログにアクセスするのに使う、デスクトップやモバイル端末、そしてタブレット端末などの多くのプラットフォームで動作することだ。</simpara>
<simpara>グーグル・スプレッドシートとフュージョンに加えて、我々は２つのツールを日常業務に使っている。一つ目はタベルーで、多次元のデータセットをビジュアライズするために用いる。二つ目はメニー・アイズで、データのおおざっぱな解析を行う。これらのツールはいずれも完璧では無いので、我々は読者を楽しませてくれるより良いビジュアライズのツールを探し続けている。</simpara>
</blockquote>
<blockquote>
<attribution>
シンシア・オマルツ
<citetitle>ファイナンシャル・タイムズ</citetitle>
</attribution>
<simpara>私がかつてコーダーになろうとしたかって？とんでもない！私はすべてのレポーターがコーディングの仕方を知っている必要があるとは思っていない。しかし、レポーターがもっと何ができるのかを理解して、どうやってコーダー達とやりとりをするのかを知る必要はあると思っている。</simpara>
<simpara>もしあなたがまだ始めたばかりなら、歩くことだ。走ってはいけない。あなたは、あなたの同僚や編集者達を説得して、データと向き合うことで他のやり方では獲得できないストーリーを得ることができ、やってみるだけの価値があると納得させなければならない。一度彼らがこのやり方の価値を認めれば、あなたはもっと複雑なストーリー、プロジェクトに手を広げることができる。</simpara>
<simpara>私のアドバイスは、エクセルを学んでシンプルなストーリーを試してみるということだ。小さくはじめて、データベース解析やマッピングなどに手を広げていくのだ。エクセルでもたくさんの事が実現できる。エクセルはとてもパワフルなツールで、多くの人は昨日のほんの一部すら使っていない。もし可能なら、Centre for Investigative Journalismが提供しているような、ジャーナリスト向けのエクセルの教室に行くと良いだろう。</simpara>
<simpara>データの解釈について：軽率に扱ってはいけない。あなたは誠実で無ければいけない。細部に気を払い、結果を求めなければいけない。データをどのように処理したのかノートをとり続けて、元のデータは残しておく。ミスを犯すのは簡単だ。私はいつも分析を２〜３回最初からやり直すようにしている。もっと良いのは、あなたの担当の編集者かほかのスタッフに同じデータを別々に分析してもらい、あなたの結果と比べることだ。</simpara>
</blockquote>
<blockquote>
<attribution>
スコット・クレイン
<citetitle>プロ・パブリカ</citetitle>
</attribution>
<simpara>一人のレポーターがストーリーを書くのと同じ早さで複雑なソフトウェアを書きデプロイする能力というのは、極めて新しいものだ。それはかつてもっと長い時間を要したが、二つのフリーでオープン・ソースの開発用フレームワークの登場によって状況が変わった。DjangoとRuby on Rails、この２つは２０００年代の中盤にリリースされた。</simpara>
<simpara>Djangoはプログラミング言語Pythonで構築されている。エイドリアン・ホロヴァティとカンサス州ローレンスのローレンス・ジャーナル・ワールドのニュースルームで働くチームが開発した。Ruby on Railsは、シカゴでデイビッド・ヘイメール・ハンソンとウェブ・アプリケーション会社の37Signalsが開発した。</simpara>
<simpara>二つのフレームワークは「MVCパターン」についての異なるアプローチをとってはいるが、それぞれ素晴らしく、非常に複雑なウェブ・アプリケーションを非常に素早く開発することができる。この２つのフレームワークは、アプリケーション開発の初期段階の面倒を軽減してくれる。データベースでのデータの作成や取得、URLとコードを対応づけるなどの動作はフレームワークに組み込まれていて、開発者はそうした基本的な動作のコードを書く必要が無いのだ。</simpara>
<simpara>アメリカにおけるニュースアプリケーションのチームについて公式の調査がある訳では無いが、データベースを使ったニュースアプリケーションにはほとんどの場合この２つのフレームワークを使用しているとされている。プロパブリカでは、Ruby on Railsを使っている。</simpara>
<simpara>Amazon Web Serviceのようなウェブ・サーバの「一部分」を提供するサービスの開発もまた、ウェブ・アプリケーションのリリースを時間のかかるものにしていたいくつかの要因を取り去った。</simpara>
<simpara>その他にも、我々は標準的なツールをデータを扱うために使う：Google RefineとMicrosoft Excelでデータをクリーンにする。SPSSとRを統計に使う。ArcGISとQGISを地理情報システムに。Gitをソースコード管理に。TextMate、VimそしてSublime Textをコードを書くために。MySQLやPostgresSQL、そしてSQL Serverをデータベースに。我々は独自に「グラス」と呼ばれるJavaScriptフレームワークを開発して、フロントエンドがリッチなアプリケーションをJavaScriptで素早く開発できるようにしている。</simpara>
</blockquote>
<blockquote>
<attribution>
シェリル・フィリップス
<citetitle>シアトル・タイムズ</citetitle>
</attribution>
<simpara>時には最もシンプルなツールが最良のツールになり得る。スプレッドシートの力は過小評価されがちだ。しかし、DOSの時代にスプレッドシートを使っていた時、私はテキサス・レンジャースのオーナー達のパートナーシップ契約書の複雑な計算式を理解する事ができた。ジョージ・Ｗ・ブッシュは主要なオーナーの一人だった。そのスプレッドシートは計算のミスに印をつけるのに訳だった。スプレッドシートをきれいにするスクリプトを書くこともできた。データ・ジャーナリストのための道具箱の基本だ。</simpara>
<simpara>そうは言っても、私のお気に入りのツールはさらなる力を持っている。SPSSは統計的な解析とプログラムのマッピングでパターンを地理的に見ることができる。</simpara>
</blockquote>
<blockquote>
<attribution>
グレゴール・アイシュ
<citetitle>オープン・ナレッジ財団</citetitle>
</attribution>
<simpara>私はPythonが大好きだ。Pythonは素晴らしいオープンソースのプログラミング言語で、簡単に読み書きができる（たとえば、あなたは１行毎にセミコロンをタイプする必要がない）。もっと重要なことは、Pythonには巨大なユーザーベースがあり、それ故に文字通りあなたが必要とするすべてのプラグイン（パッケージと呼ばれる）がそろっている。</simpara>
<simpara>Djangoはデータ・ジャーナリストが必要とすることは滅多にないだろう。Pythonベースのウェブ・アプリケーション・フレームワークで、大規模なデータベースを使ったウェブアプリケーションを作るためのツールだ。小さなインタラクティブ・インフォグラフィックにはヘビーすぎる。</simpara>
<simpara>ほかにも私はQGisを使っている。地理データを扱うデータ・ジャーナリストが必要とする地理情報システムの機能を広い範囲でカバーする、オープンソースのツールキットだ。もしあなたが地理的なデータをあるフォーマットから別のものに変換する必要があるなら、QGisを使うとよい。QGisは世の中にある地理情報フォーマットをほとんどサポートしている（Shapefiles、KML、 GeoJSONなど）。もしあなたがいくつかの領域を切り出す必要があるなら、これもQGisで出来る。それに加えて、QGisには巨大なコミュニティがあり、<ulink url="http://bit.ly/goettingen-tutorial">チュートリアル</ulink> のようなリソースをウェブ上でたくさん見つけることができる。</simpara>
<simpara>Rは科学の領域でのビジュアライゼーションのツールとして生まれた。Rに組み込まれていないデータ・ビジュアライゼーションやデータ変換手法を見つけるのは至難の技だ。Rはそれ自体が宇宙であり、ビジュアルデータ分析のメッカである。ひとつの障害は、Rが独自の言語を持っていて、（また別の）プログラミング言語を習得する必要があることだ。しかし、いちど初期の学習カーブに乗ってしまえば、これ以上にパワフルなツールはない。訓練されたデータ・ジャーナリストは、Rを巨大なデータセットを分析するのに使ってエクセルの限界（例えば、あなたが100万行以上のテーブルを持っているとき）を超えることができる。</simpara>
<simpara>Rに関してとても素晴らしいのは、CSVファイルの読み込みからチャートの生成まで、あなたがすべてのプロセスを通じてデータに行った操作の「手順」を、正確に保持出来る事だ。もしデータが変化したら、１クリックでチャートを生成し直すことができる。もし誰かがチャートの正確さに興味をもったら、実際のソースを示すことができるので、すべての人が全く同じチャートを独自に再現できる（あるいはあなたのミスをみつけるかもしれない）。</simpara>
<simpara>NumPyとMatPlotLibの組み合わせは、同様のことをPythonで行える。もしあなたがPythonに習熟しているなら、選択肢になる。NumPyとMatPlotLibはPythonパッケージである。データの分析とビジュアライゼーションに使うことができるが、両方とも静的なビジュアライゼーションに特化している。ツールチップやその他の込み入った機能を持ったインタラクティブなチャートを作ることはできない。</simpara>
<simpara>私はMapBoxを使っていないが、もしあなたがOpenStreetMapを元にして洗練された地図を作りたいなら非常に良いツールだと聞いている。例えば、マップのスタイル（色、ラベルなど）をカスタマイズすることができる。それにLeafletと呼ばれるMapBoxのツールがある。LeafletはJavaScriptの地図ライブラリで、地図のソース（OSM、MapBox、Google Maps、Bingなど）を簡単に切り替えることができる。</simpara>
<simpara>RaphaelJSは、もう少し低レベルのビジュアライゼーションライブラリで、ビジュアル要素（サークル、ライン、テキストのような）を使うことができる。また、こうした要素をアニメーションしたり、インタラクションを加えることもできる。すぐに使えるバー・チャートなどはないので、あなたはいくつかのレクタングルを使って自分で描画をしてやる必要がある。</simpara>
<simpara>しかし、Rhaphaelの良いところは、あなたが作ったものが全てInternet Explorerでも動くという事だ。これは、d3のような、多くの他の素晴らしいビジュアライゼーション・ライブラリでは実現できていない。悲しいことに多くのユーザーは未だにIEを使っていて、どんなニュースルームも、ユーザーの30%を無視する訳にはいかないのだ。</simpara>
<simpara>RaphaelJSのほかに、IEのためにFlashでのフォールバックを用意する選択肢もある。The New York Timesはこのやり方を実践している。この場合、あなたはアプリケーションを２度開発する必要がある。</simpara>
<simpara>私は未だに、IEとそのほかのモダンなブラウザーに受けてビジュアライゼーションを提供する「最良」のプロセスについて確信が持てないでいる。RaphaelJSで作ったアプリケーションがIEでひどく遅く動いていることがしばしばあるし、モダンなブラウザーでもFlash版より10倍も遅いこともある。だから、Flashを代替手段として用意するのは、全てのユーザーにハイクオリティーなアニメーションのビジュアライゼーションを提供するときのより良い選択肢だ。</simpara>
</blockquote>
<blockquote>
<attribution>
スティーブ・ドイグ
<citetitle>ウォルター・クロンカイトジャーナリズムスクール</citetitle>
</attribution>
<simpara>私が頼りにしているツールはエクセルだ。コンピュータでのレポーティングの多くの問題を解決できるし、学習が容易でほとんどのレポーターが利用できるという利点がある。テーブルをマージする必要があるとき、私は良くAccessを使うが、その後でマージされたテーブルをエクセルに戻してさらなる作業をする。私はESRIのArcMapを地理的な分析に使う。パワフルなツールで、地理的なデータを集めるエージェンシーでも使われている。TextWranglerは、癖のあるレイアウトを持つテキストテキスト・データを扱う時に素晴らしい仕事をするし、正規表現を使って洗練された検索と置換処理を行う事ができる。直線回帰のような統計のテクニックを使う必要があるときは、SPSSを使う。親しみやすいクリックメニューを持っている。100万行ものレコードをもつデータセットを扱いフィルタリングやプログラムされた変数のようなヘビーな用途には、SASを使う。</simpara>
</blockquote>
<blockquote>
<attribution>
ブライアン・ボイヤー
<citetitle>シカゴ・トリビューン</citetitle>
</attribution>
<simpara>我々が選ぶツールには、データをいじったりスクレーピングをしたりするためのPythonとDjangoが入る。また、PostGISやQGIS、それにMapBoxツールキットもすごいウェブ地図を構築するのに必要だ。RとNumPy + MatPlotLibは、我々がデータの分析調査を行うためのキットの選択肢としてどちらが優位か競っているところだが、自分自身で開発したCVSKitは最近の一番のお気に入りだ。</simpara>
</blockquote>
<blockquote>
<attribution>
アンジェリカ・パラルタ・ラモス
<citetitle>ラ・ナシオン (アルゼンチン)</citetitle>
</attribution>
<simpara>ラ・ナシオンで我々が使っているツール：</simpara>
<itemizedlist>
<listitem>
<simpara>
データのクリーニング、まとめと解析にエクセルを使っている。
</simpara>
</listitem>
<listitem>
<simpara>
Google Spreadsheets はGoogle Fusion TblesやJunar Open Data Platformのようなサービスと接続するために使う。
</simpara>
</listitem>
<listitem>
<simpara>
Junarは我々のデータをシェアしたり、我々の記事やブログ記事に埋め込むために必要である。
</simpara>
</listitem>
<listitem>
<simpara>
Tableauはインタラクティブなデータ・ビジュアライゼーションのために使う。
</simpara>
</listitem>
<listitem>
<simpara>
Qlikviewはとても高速なビジネス解析ツールで、大きなデータセットをフィルターして分析するのに使う。
</simpara>
</listitem>
<listitem>
<simpara>
NitroPDFはPDFをテキストとエクセルファイルに変換するのに使う。そして、
</simpara>
</listitem>
<listitem>
<simpara>
Google Fusion Tablesを地図ベースのビジュアライゼーションに使う。
</simpara>
</listitem>
</itemizedlist>
</blockquote>
<blockquote>
<attribution>
ペドロ・マークン
<citetitle>トランスパレンシア ハッカー</citetitle>
</attribution>
<simpara>技術的なバイアスのない草の根のコミュニティーとして、Transparency Hackersでは多くの異なるツールとプログラミング言語を使う。メンバーはそれぞれに好みのセットがあり、この多様さは我々の強みであり弱みでもある。一部のメンバーは「トランスパレンシー・ハッカー・リナックス・ディストリビューション」を開発していて、どこででもOSをブートしてデータ解析を始めることができる。このツールキットは、Refine、RStudio、そしてOpenOffice Calc（コンピュータに詳しい人々から見落とされているが、ちょっとした作業には本当に役に立つ）のような、データを扱うためのいくつかのおもしろいツールとライブラリを収めている。そして、我々はさっとプロトタイプを作成して結果をオンラインに保存するのに、Scraperwikiを良く使う。</simpara>
<simpara>データのビジュアライゼーションやグラフのために、多くの我々のよく使うツールがある。PythonとNumPyはとてもパワフルだ。何人かの人がRを試しているが、結局私はJavaScriptでグラフを描画するd3、Flot、そしてRaphaelJSのようなライブラリが我々のプロジェクトの多くで使われていると思う。最後に、我々は地図の作成のために多くのツールを試したが、Tilemillが非常におもしろいツールだった。</simpara>
</blockquote>
</section>
<section id="_データ可視化を利用してデータの中の知見を見つける">
<title>データ可視化を利用してデータの中の知見を見つける</title>
<blockquote>
<attribution>
William S. Cleveland (from Visualizing Data
<citetitle>Hobart Press)</citetitle>
</attribution>
<simpara>可視化はデータ分析において重要です。攻撃の最前線であり、他の方法では明らかにすることが難しいであろうデータの複雑な構造を提示してくれます。</simpara>
</blockquote>
<simpara>データはそれ自体は、コンピュータに保存されているビットやバイトであり、見ることが出来ません。データを見て理解するためには、それを可視化しなければなりません。ここでは広義の意味で_可視化_という言葉を用います。ここではデータを単にテキストで再現することも含みます。例えば、データセットをスプレッドシート・ソフトウェアにロードすることもデータ可視化と見なします。見ることができないデータが突然スクリーン上に見える"絵"になるのです。よって、問題はジャーナリストがデータを可視化するか否かではなく、状況に応じてどのような可視化が適しているのかが重要なのです。</simpara>
<simpara>言い換えれば、表をつくる以上の可視化が有用なのはいつでしょうか？端的な答えは、_ほとんどいつもです_。表それ自体はデータセットの概観を得るには、まず間違いなく不十分です。表からはデータの傾向をすぐに見いだすことができません。最も典型的な例は、データを地図上に可視化した場合にのみ見つけることが出来る地理的傾向です。しかし、他の種類の傾向もあるのでこのセクションで後ほど説明します。</simpara>
<section id="_可視化を利用して知見を見つける">
<title>可視化を利用して知見を見つける</title>
<simpara>データ可視化のツールや技術が、閉塞を打ち破ってくれるだろうと期待するのは非現実的です。それだけではデータセットからストーリーは生まれません。ストーリーを担保してくれるようなルールや"プロトコル"はありません。それよりも"知見"を探すために有用で、優秀なジャーナリストの手によって上手くストーリーに織り込まれます。</simpara>
<simpara>全ての新たな可視化がデータに関する何らかの知見を与えてくれるでしょう。知見のいくつかは既に知られているかもしれませんが（しかしおそらくまだ証明されていません）、中には全く新しく驚かせてくれるような知見もあるかもしれません。新たな知見は、ストーリーの始まりを意味するかもしれませんし、データにあるエラーの結果かもしれません。これは多くの場合、データ可視化によって見つかります。</simpara>
<simpara>データの中にある知見をより効率的に見つけるために、そのプロセスを<xref linkend="FIG054"/> で（そしてこのセクションの残りで）議論しているのでこれは役立つと思います。</simpara>
<figure id="FIG054"><title>Data insights: a visualization (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-BB.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-BB.png</phrase></textobject>
</mediaobject>
</figure>
<section id="_データ可視化の方法を学ぶ">
<title>データ可視化の方法を学ぶ</title>
<simpara>可視化はデータセットに関する特有の視座を与えてくれます。実に様々な方法でデータを可視化できます。</simpara>
<simpara>比較的小さな数字のデータを扱うときに、表はとてもパワフルです。最もはっきりと構成された形でラベルと量を示していただき、データをソートしてフィルターをかける能力と組み合わせることでその潜在的可能性を最も発揮します。加えて、エドワード・タフテは、例えば表のセルの中に、小さな表を含めたり、行ごとに棒を描いたり、小さな折れ線グラフを作ることを提唱しました（それ以来スパークラインと知られています）。これは、一次元的な外れ値、例えばトップ10が何かを知りたいときに有用です。しかし、複数の次元を同時に比較するときにはあまり役に立ちません（例えば時系列で、国ごとの人口を見るときです）。</simpara>
<figure id="FIG055"><title>タフテのコツ: スパークライン (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-BC-graphical-table.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-BC-graphical-table.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>表というのは、概して、複数次元のデータを描き、幾何学的な形式の見える性質のものにすることです。個々の視覚的性質の効用については多く書かれており、短く言うとこうなります:色は難しく、位置が全てである。例えば散布図では、二つの次元がxとyの位置で描かれています。さらにシンボルの色やサイズによって第三の次元も表現できます。折れ線グラフは特に一時的な展開を表現するのに向いており、棒グラフは、分類データを比較するのに最適です。表の要素をそれぞれの上に並べることができます。もしデータの仲の小さな数のグループを比較したければ、同じ表の複数事例を表示することがとても強力な方法です（小さな倍数としても言及されます）。全ての表で、異なる種類のスケールを用いてデータの異なる側面を探求できます（例えば、線形やログです）。</simpara>
<simpara>事実、私たちが扱うデータのほとんどが、何らかの形で実際の人に関連します。地図の力はデータを私たちのより物質的な世界に再びつなげてくれることです。犯罪事例の地理的データセットを想像してみてください。重要なことは、犯罪が_どこで_起こっているのかを知りたいということです。また地図はデータの地理的関係も明らかにしてくれます（例えば、南北や、都市・地方での傾向）。</simpara>
<figure id="FIG056"><title>Choropleth map (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-BD-choropleth.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-BD-choropleth.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>関連を語るときに、四番目に重要な可視化の種類はグラフです。グラフとはデータ・ポイント（結節点）の中の相互に関連する場所（接線）を見せることです。結節点の位置は多かれ少なかれ、複雑なグラフ・レイアウトのアルゴリズムによって計算されます。これによって私たちはすぐにネットワークの構造を把握できます。グラフ可視化の技は、概して、ネットワーク自体をモデル化する適切な方法を探すことを見つけることです。全てのデータセットが何かの関連を含むわけではありませんが、もし含んでいたとしても、注目する興味深い側面ではないかもしれません。場合によってはジャーナリストが接線と結節点を決めることになります。完璧な例はこれです。 <ulink url="http://slate.me/senate-social">U.S. Senate Social Graph</ulink> 接線は同一の票を65%以上投じている上院議員同士を結んでいます。</simpara>
</section>
<section id="_見ているものを分析し解釈する">
<title>見ているものを分析し解釈する</title>
<simpara>データを可視化したら、次のステップは自分で作った絵から何かを学ぶことです。自分自身にこう問うかもしれません。</simpara>
<itemizedlist>
<listitem>
<simpara>
この映像から何が見えるだろうか？それは自分が期待していたものだろうか？
</simpara>
</listitem>
<listitem>
<simpara>
何か興味深い傾向があるだろうか？
</simpara>
</listitem>
<listitem>
<simpara>
データの文脈においてそれは何を意味するのだろうか？
</simpara>
</listitem>
</itemizedlist>
<simpara>時折、可視化をしたものの、見た目が美しいだけで、何もデータについて興味深いことを見つけることが出来ないかもしれません。しかし、ほとんどの場合、些細なことではあるかもしれませんが可視化から_何か_を学ぶことが出来ます。</simpara>
</section>
<section id="_知見とステップを文書化する">
<title>知見とステップを文書化する</title>
<simpara>If you think of this process as a journey through the dataset, the documentation is your travel diary. It will tell you where you have traveled to, what you have seen there, and how you made your decisions for your next steps. You can even start your documentation before taking your first look at the data.</simpara>
<simpara>In most cases when we start to work with a previously unseen dataset, we are already full of expectations and assumptions about the data. Usually there is a reason why we are interested in that dataset that we are looking at. It&#8217;s a good idea to start the documentation by writing down these initial thoughts. This helps us to identify our bias and reduces the risk of misinterpretation of the data by just finding what we originally wanted to find.</simpara>
<simpara>I really think that the documentation is the most important step of the process&#8212;and it is also the one we&#8217;re most likely to tend to skip. As you will see in the example below, the described process involves a lot of plotting and data wrangling. Looking at a set of 15 charts you created might be very confusing, especially after some time has passed. In fact, those charts are only valuable (to you or any other person you want to communicate your findings) if presented in the context in which they have been created. Hence you should take the time to make some notes on things like:</simpara>
<itemizedlist>
<listitem>
<simpara>
Why have I created this chart?
</simpara>
</listitem>
<listitem>
<simpara>
What have I done to the data to create it?
</simpara>
</listitem>
<listitem>
<simpara>
What does this chart tell me?
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_transform_data">
<title>Transform data</title>
<simpara>Naturally, with the insights that you have gathered from the last visualization, you might have an idea of what you want to see next. You might have found some interesting pattern in the dataset which you now want to inspect in more detail.</simpara>
<simpara>Possible transformations are:</simpara>
<variablelist>
<varlistentry>
<term>
Zooming
</term>
<listitem>
<simpara>
  To have look at a certain detail in the visualization
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Aggregation
</term>
<listitem>
<simpara>
  To combine many data points into a single group
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Filtering
</term>
<listitem>
<simpara>
  To (temporarily) remove data points that are not in our major focus
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Outlier removal
</term>
<listitem>
<simpara>
  To get rid of single points that are not representative for 99% of the dataset.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Let&#8217;s consider that you have visualized a graph, and what came out of this was nothing but a mess of nodes connected through hundreds of edges (a very common result when visualizing so-called <emphasis>densely connected networks</emphasis>). One common transformation step would be to filter some of the edges. If, for instance, the edges represent money flows from donor countries to recipient countries, we could remove all flows below a certain amount.</simpara>
</section>
</section>
<section id="_which_tools_to_use">
<title>Which Tools to Use</title>
<simpara>The question of tools is not an easy one. Every data visualization tool available is good at something. Visualization and data wrangling should be easy and cheap. If changing parameters of the visualizations takes you hours, you won&#8217;t experiment that much. That doesn&#8217;t necessarily mean that you don&#8217;t need to learn how to use the tool. But once you learned it, it should be really efficient.</simpara>
<simpara>It often makes a lot of sense to choose a tool that covers both the data wrangling and the data visualization issues. Separating the tasks in different tools means that you have to import and export your data very often. Here&#8217;s a short list of some data visualization and wrangling tools:</simpara>
<itemizedlist>
<listitem>
<simpara>
Spreadsheets like LibreOffice, Excel or Google Docs
</simpara>
</listitem>
<listitem>
<simpara>
Statistical programming frameworks like R (r-project.org) or Pandas (pandas.pydata.org)
</simpara>
</listitem>
<listitem>
<simpara>
Geographic Information Systems (GIS) like Quantum GIS, ArcGIS, or GRASS
</simpara>
</listitem>
<listitem>
<simpara>
Visualization Libraries like d3.js (mbostock.github.com/d3), Prefuse (prefuse.org), or Flare (flare.prefuse.org)
</simpara>
</listitem>
<listitem>
<simpara>
Data wrangling tools like Google Refine or Datawrangler
</simpara>
</listitem>
<listitem>
<simpara>
Non-programming visualization software like ManyEyes or Tableau Public (tableausoftware.com/products/public)
</simpara>
</listitem>
</itemizedlist>
<simpara>The sample visualizations in the next section were created using R, which is kind of a Swiss Army knife of (scientific) data visualization.</simpara>
</section>
<section id="_an_example_making_sense_of_us_election_contribution_data">
<title>An Example: Making Sense of US Election Contribution Data</title>
<simpara>Let us have look at the US Presidential Campaign Finance database, which contains about 450,000 contributions to US presidential candidates. The CSV file is 60 megabytes and way too big to handle easily in a program like Excel.</simpara>
<simpara>In the first step I will explicitly write down my initial assumptions on the FEC contributions dataset:</simpara>
<itemizedlist>
<listitem>
<simpara>
Obama gets the most contributions (since he is the president and has the greatest popularity).
</simpara>
</listitem>
<listitem>
<simpara>
The number of donations increases as the time moves closer to election date.
</simpara>
</listitem>
<listitem>
<simpara>
Obama gets more small donations than Republican candidates.
</simpara>
</listitem>
</itemizedlist>
<simpara>To answer the first question, we need to <emphasis>transform</emphasis> the data. Instead of each single contribution, we need to sum the total amounts contributed to each candidate. After <emphasis>visualizing</emphasis> the results in a sorted table, we can confirm our assumption that Obama would raise the most money:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Candidate </entry>
<entry align="left" valign="top"> Amount ($)</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Obama, Barack</simpara></entry>
<entry align="left" valign="top"><simpara>72,453,620.39</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Romney, Mitt</simpara></entry>
<entry align="left" valign="top"><simpara>50,372,334.87</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Perry, Rick</simpara></entry>
<entry align="left" valign="top"><simpara>18,529,490.47</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Paul, Ron</simpara></entry>
<entry align="left" valign="top"><simpara>11,844,361.96</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Cain, Herman</simpara></entry>
<entry align="left" valign="top"><simpara>7,010,445.99</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Gingrich, Newt</simpara></entry>
<entry align="left" valign="top"><simpara>6,311,193.03</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Pawlenty, Timothy</simpara></entry>
<entry align="left" valign="top"><simpara>4,202,769.03</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Huntsman, Jon</simpara></entry>
<entry align="left" valign="top"><simpara>2,955,726.98</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Bachmann, Michelle</simpara></entry>
<entry align="left" valign="top"><simpara>2,607,916.06</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Santorum, Rick</simpara></entry>
<entry align="left" valign="top"><simpara>1,413,552.45</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Johnson, Gary Earl</simpara></entry>
<entry align="left" valign="top"><simpara>413,276.89</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Roemer, Charles E. <emphasis>Buddy</emphasis> III</simpara></entry>
<entry align="left" valign="top"><simpara>291,218.80</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>McCotter, Thaddeus G</simpara></entry>
<entry align="left" valign="top"><simpara>37,030.00</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Even though this table shows  the minimum and maximum amounts and the order, it does not tell very much about the underlying patterns in candidate ranking. <xref linkend="FIG059"/> is another view on the data, a chart type that is called a "dot chart," in which we can see everything that is shown in the table <emphasis>plus</emphasis> the patterns within the field. For instance, the dot chart allows us to immediately compare the distance between Obama and Romney, and Romney and Perry, without needing to subtract values. (Note: the dot chart was created using R. You can find links to the source code at the end of this chapter).</simpara>
<figure id="FIG059"><title>Visualizations to spot underlying patterns (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-CC.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-CC.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>Now, let us proceed with a bigger picture of the dataset. As a first step, I <emphasis>visualized</emphasis> all contributed amounts over time in a simple plot. We can see that almost all donations are very, very small compared to three really big outliers. Further investigation reveals that these huge contributions are coming from the &#8220;Obama Victory Fund 2012&#8221; (also known as Super PAC) and were made on June 29th ($450k), September 29th ($1.5mio), and December 30th ($1.9mio).</simpara>
<figure id="FIG0510"><title>Three clear outliers (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-DD.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-DD.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>While the contributions by Super PACs alone is undoubtedly the biggest story in the data, it might be also interesting to look beyond it. The point now is that these big contributions disturb our view on the smaller contributions coming from individuals, so we&#8217;re going to remove them from the data. This transform is commonly known as outlier removal. After visualizing again, we can see that most of the donations are within the range of $10k and -$5k.</simpara>
<figure id="FIG0511"><title>Removing the outliers (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-EE.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-EE.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>According to the contribution limits placed by the FECA, individuals are not allowed to donate more than $2500 to each candidate. As we see in the plot, there are numerous donations made above that limit. In particular, two big contributions in May attract our attention. It seems that they are <emphasis>mirrored</emphasis> in negative amounts (refunds) in June and July. Further investigation in the data reveals the following transactions:</simpara>
<itemizedlist>
<listitem>
<simpara>
On May 10, <emphasis>Stephen James Davis</emphasis>, San Francisco, employed at Banneker Partners (attorney), has donated <emphasis role="strong">$25,800</emphasis> to Obama.
</simpara>
</listitem>
<listitem>
<simpara>
On May 25, <emphasis>Cynthia Murphy</emphasis>, Little Rock, employed at the Murphy Group (public relations), has donated <emphasis role="strong">$33,300</emphasis> to Obama.
</simpara>
</listitem>
<listitem>
<simpara>
On June 15, the amount of <emphasis role="strong">$30,800</emphasis> was refunded to <emphasis>Cynthia Murphy</emphasis>, which reduced the donated amount to <emphasis role="strong">$2500</emphasis>.
</simpara>
</listitem>
<listitem>
<simpara>
On July 8, the amount <emphasis role="strong">$25,800</emphasis> was refunded to <emphasis>Stephen James Davis</emphasis>, which reduced the donated amount to $0.
</simpara>
</listitem>
</itemizedlist>
<simpara>What&#8217;s interesting about these numbers? The $30,800 refunded to Cynthia Murphy equals the maximum amount individuals may give to national party committees per year. Maybe she just wanted to combine both donations in one transaction, which was rejected. The $25,800 refunded to Stephen James Davis possibly equals the $30,800 minus $5000 (the contribution limit to any other political committee).</simpara>
<simpara>Another interesting finding in the last plot is a horizontal line pattern for contributions to Republican candidates at $5000 and -$2500. To see them in more detail, I visualized just the Republican donations. The resulting graphic is one great example of patterns in data that would be invisible without data visualization.</simpara>
<figure id="FIG0512"><title>Removing outliers 2 (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-FF.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-FF.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>What we can see is that there are many $5000 donations to Republican candidates. In fact, a look up in the data returns that these are 1243 donations, which is only 0.3% of the total number of donations, but since those donations are evenly spread across time, the line appears. The interesting thing about the line is that donations by individuals were limited to $2500. Consequently, every dollar above that limit was refunded to the donors, which results in the second line pattern at -$2500. In contrast, the contributions to Barack Obama don&#8217;t show a similar pattern.</simpara>
<figure id="FIG0513"><title>Removing outliers 3 (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-GG.png" scale="86"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-GG.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>So, it might be interesting to find out why thousands of Republican donors did not notice the donation limit for individuals. To further analyze this topic, we can have a look at the total number of $5k donations per candidate.</simpara>
<figure id="FIG0514"><title>Donations per candidate (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-HH.png" scale="86"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-HH.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>Of course, this is a rather distorted view since it does not consider the total amounts of donations received by each candidate. The next plot shows the percentage of $5k donations per candidate.</simpara>
<figure id="FIG0515"><title>Where does the senator&#8217;s money come from?: donations per candidate (Gregor Aisch)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/05-II.png" scale="88"/>
  </imageobject>
  <textobject><phrase>figs/incoming/05-II.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_what_to_learn_from_this">
<title>What To Learn From This</title>
<simpara>Often, such a visual analysis of a new dataset feels like an exciting journey to an unknown country. You start as a foreigner with just the data and your assumptions, but with every step you make, with every chart you render, you get new insights about the topic. Based on those insights, you make decisions for your next steps and what issues are worth further investigation. As you might have seen in this chapter, this process of visualizing, analyzing and transformation of data could be repeated nearly infinitely.</simpara>
</section>
<section id="_get_the_source_code">
<title>Get the Source Code</title>
<simpara>All of the charts shown in this chapter were created using the wonderful and powerful software R. Created mainly as a scientific visualization tool, it is hard to find any visualization or data wrangling technique that is not already built into R. For those who are interested in how to visualize and wrangle data using R, here&#8217;s the source code of the charts generated in this chapter:</simpara>
<itemizedlist>
<listitem>
<simpara>
<ulink url="https://gist.github.com/1769733">dotchart: contributions per candidate</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://gist.github.com/1816161">plot: all contributions over time</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://gist.github.com/1816169">plot: contributions by authorized committees</ulink>
</simpara>
</listitem>
</itemizedlist>
<simpara>There is also a wide range of books and tutorials available.</simpara>
<simpara>&mdash; <emphasis>Gregor Aisch, Open Knowledge Foundation</emphasis></simpara>
</section>
</section>
</section>
<section id="_データを提供する">
<title>データを提供する</title>
<informalfigure role="informal">
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-00-cover.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-00-cover.png</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>データをよく見て、執筆にあたって興味深いものがあるとしたら、どのようにそれを公にすべきだろうか？この項では、データジャーナリズムの第一人者たちが読者にどのようにデータを提供したのか、インフォグラフィックスからダウンロードリンクへのオープンデータプラットフォームなどを用いた逸話を最初に紹介する。その後、ニュースアプリの構築の仕方とデータビジュアライゼーションの内実と表面を見ることにする。最後に、あなたのプロジェクトと読者を関連付けるためにできることについて見てみよう。</simpara>
<section id="_データを世間に公開する">
<title>データを世間に公開する</title>
<simpara>データを公開する方法には様々な方法があります。生のデータセットと共にその物語を公開する方法、美しいビジュアライゼーションやインタラクティブなウェブアプリケーションをつくって公開する方法など。そこで私たちはデータを駆使するジャーナリストたちに公開方法の秘訣を尋ねました。</simpara>
<section id="_ビジュライゼーション_するか否か">
<title>ビジュライゼーション、するか否か</title>
<simpara>データが言葉や文字よりもニュースを物語ることができると考えられるようになると、「新しいアプリケーション」とか、「データビジュライゼーション」といったバズワードがニュースの現場でも聞かれるようになります。さらに、（多くの場合無料の）新しいツールが注目を浴び、データに扱いなれていないジャーナリストでも簡単にビジュアライゼーションができるようになりました。</simpara>
<simpara>Google FUsion Tablesや、Many Eyes, Tableau, Dipityといった新しいテクノロジーが地図やチャート、グラフさらにはかつて専門家にしかできなかったような＿＿＿データアプリケーションもがずっと簡単にできるようになりました。しかし、誰もが手っ取り早くこうしたツールを使えるようになったことでジャーナリストが直面した問いは、データセットをビジュライゼーションできるかどうか、ではなく、そもそもデータをビジュアライズするべきなのか、ということでした。悪いデータビジュアライゼーションは全くビジュアライゼーションをしなかったよりもあらゆる点で劣ってしまうのです。</simpara>
<simpara>&mdash; <emphasis>Aron Pilhofer, New York Times</emphasis></simpara>
</section>
<section id="_動的なグラフィックを使う">
<title>動的なグラフィックを使う</title>
<simpara>スクリプトやアニメーションを上手に用い、明快な解説とともに動的なグラフィックを使うことで複雑な数字や概念も、生き生きとしたストーリーとして読者（視聴者）の関心を導くことができます。Hans Roslingの解説ビデオを見れば、スクリーン上でデータがストーリーを伝える良い事例を知ることができる。この方法に同意する人もそうでない人も、エコノミストのShoe-thrower’s indexをご覧いただきたい。こちらも、ビデオを用いて数字ベースのストーリーを伝える良い事例だ。こうしたニュースは、静的な画像として公開すべきではない。いろいろなことが起きているということを静止画では伝えることができないからだ。一つずつ組み立てていって、どうしてこのインデックスがこの形になったかわかるようになるだろう。動画やアニメーションを使えば、視聴者にわかりやすいビジュアルとともに解説のナレーションをつけ、パワフルで記憶に残るストーリーテリングが実現できる。</simpara>
<simpara>&mdash; <emphasis>Lulu Pinney, freelance infographic designer</emphasis></simpara>
<?dbfo-need height="1in"?>
</section>
<section id="_世界に伝える">
<title>世界に伝える</title>
<simpara>私たちの作業手順は、エクセルからはじまることがほとんどです。データに面白いものがみつかったら手っ取り早く取り掛かることができます。意味のあるストーリーがデータの塊から見つかったら、デスクに連絡します。ガーディアンの、メインのニュースデスクのすぐ隣に席がある我々は本当にラッキーだと思います。デスクに伝えたら、次にページでの見せ方を考えます。そしてそれにあわせた記事を執筆します。そうして記事を書くときはたいがい、テキストエディターのすぐそばにスプレッドシートの縮小版を置いています。書きながら、ちょっとした分析をして面白いことを見つけたりするためです。一度記事をpublishしたら、もうしばらくツイッターで記事のことをつぶやいたり、適切な人に記事のことをメールしたりして時間を過ごします。自分の記事が適切な場所からリンクされるようにためです。</simpara>
<simpara>記事へのアクセスの半分はツイッターやフェイスブックを通してきます。ガーディアンの記事の平均滞在時間が1分なのに対し、私たちの記事であるデータブログへの、ページ滞在時間が平均6分であることを自負しています。6分という数字は、ウェブページの滞在時間としてはかなりいい数字です。ページの滞在時間というのは、アクセス解析において重要な指標の一つです。</simpara>
<simpara>こうしたことが、同僚に自分たちの仕事の価値を納得してもらうのに役立っています。それから、私たちが取り組んだビッグデータを元にした記事はニューズルームの誰もが知るところとなります。―COINS、ウィキリークス、イギリス暴動。COINSでは、イギリス政府が発行したデータについて、5、6人の専門レポーターが私見を述べてくれました。さらに政府が£25k の支出データを公開したときは、著名なレポーターであるPolly Curtisを含む5、6人のチームが一緒に取り組んでくれました。ウィキリークスも、イラクやアフガニスタンに関する大量のニュースを持っていました。イギリス暴動の記事も、2日間で550kのアクセスがある大きなニュースでした。短期的なトラフィックの増大だけではなく、信頼でき手役立つ情報源となることが大切です。私たちは報道しているトピックについて良質で価値のある情報を届けられるよう努力しています。</simpara>
<simpara>But it is not just about the short term hits: it is also about being a reliable source of useful information. We try to be the place where you can get good, meaningful information on topics that we cover.</simpara>
<simpara>&mdash; <emphasis>Simon Rogers, the Guardian</emphasis></simpara>
</section>
<section id="_データをpublishするときには">
<title>データをpublishするときには</title>
<simpara>多くの場合、我々はデータをサイトにビジュアライゼーションして組み込み、データセットのダウンロードが容易な形式で提供しています。そうすることで読者もニュースの裏側のデータをビジュアライゼーションを動かしながら知ることができるほか、データそのものを使うことができます。どうしてこれが重要かというと、シアトルタイムズの透明性を高めるためです。読者に我々が辿り着いた物語の結論のもととなったデータを見せることができます。そうすれば批評家も使うでしょうが、この記事や派生するニュースに興味を持っているジャーナリストも使うことができる。データを利用可能な状態にすることで、一般読者や批評家たちからヒントとなるコメントをもらうことができます。我々が気づかなかったことや、もっと調査すべきことがあればそれを知らせてくれます。こうしたことは意義あるジャーナリズムを追い求めるうえで非常に価値あることです。</simpara>
<simpara>&mdash; <emphasis>Cheryl Phillips, The Seattle Times</emphasis></simpara>
</section>
<section id="_データをオープンにする">
<title>データをオープンにする</title>
<simpara>ニュースの消費者に、われわれが使ったデータへの容易なアクセスを与えることはいくつかの理由から正しいことだ。データを見せてしまえば、偏った結論にむりやり記事の内容を曲げていないという確証を与えることにもなる。データを公開することは社会科学の伝統であり、他の研究者に論文をつかって更なる議論を展開してもらうために行われてきた。ニュースの読者にデータを調べることを促せばことは、さらなるフォローアップ記事をつくるためのヒントを与えてくれるだろう。そして、データに興味をもったデータは必ずやまた記事に戻ってきてくれる。</simpara>
<simpara>&mdash; <emphasis>Steve Doig, Walter Cronkite School of Journalism, Arizona State University</emphasis></simpara>
</section>
<section id="_オープンデータのプラットフォームを設ける">
<title>オープンデータのプラットフォームを設ける</title>
<simpara>私たちの働くLa Naciónでは、オープンデータを公開することがデータジャーナリズム活動の一環として行われています。アルゼンチンでは、情報公開法がなく、国のデータを閲覧できるポータルもありません。なので、読者に記事の中で使われたデータを提供する必要があると強く感じています。</simpara>
<simpara>そこで、生の構造化されたデータをJunarプラットフォームに公開し、グーグルのGoogle Spreadsheetでも公開しています。私たちはほかの人にデータを再活用してもらうよう促すとともに、ドキュメンテーションやビデオのチュートリアルで活用方法を少しだけ説明しています。さらに、こうしたデータセットやビジュアライゼーションについてブログでも公開しています。</simpara>
<simpara>アルゼンチンにデータ公開やデータを発行するツールを伝道し、私たちがどうやってデータあをあつめたか、またデータの使い方や他の人に活用してもらうために行っています。</simpara>
<simpara>2012年の2月のプラットフォームを開設してから、データセットについてのアイディアや提案を頂きました。主に学者や研究者、そして大学生―質問に回答してあげたり、データセットを提供してあげるとと大変感謝してくれます―からです。ほかにもTableau上で私たちのデータを活用してくれたり、コメントしてくれるユーザーがいたおかげで、Tableauでコメント最多や、最も閲覧されたデータとなりました。2011年には、最もビュー数の多いビジュアライゼーショントップ100位のなかに7つがはいりました。</simpara>
<simpara>&mdash; <emphasis>Angélica Peralta Ramos, La Nación (Argentina)</emphasis></simpara>
</section>
<section id="_データをヒトにする">
<title>データをヒトにする</title>
<simpara>ビッグデータに関する議論がより広く意識されるようになりましたが、ひとつ重要な部分が抜け落ちています。それは人間の要素です。データというと多くの人は切り離されて自由浮遊の数字をイメージするでしょう。しかし実際は（多くの場合非常に人間的で）有形なものを測定したものなのです。データは現実の人々の生活を繋いだもので、数値に取り掛かるときは、そのデータのもととなっている実際の世界の仕組みを考慮する必要があるのです。</simpara>
<simpara>例えば、位置情報について考えてみましょう。位置情報は、数億の写真や携帯電話から収集されています。こうしたデータ(経度、緯度、時間）をただの、「デジタルな排ガス」ととらえがちですが、本当は人間のストーリーの一瞬を抜き取ったものなのです。スプレッドシートで見るデータは、乾いた客観的なもののようですが、その位置情報を残した人たちに地図に跡をつけてもらい、改めて道筋を辿ってもらうと、力づよい、人間的な記憶を経験を与えます。</simpara>
<?dbfo-need height="2in"?>
<simpara>現状では、位置情報はたくさんの第三者によって利用されています。アプリケーション開発者、大手ブランドや広告代理店など。セカンドパーティーにあたる通信会社やディバイスマネージャーがデータを握り、所有しており、ファーストパーティー―つまりあなた―はこの情報について何のコントロールもできなければ情報を手に入れることもできないのです。ニューヨークタイムズのR&amp;D部では、プロトタイプの事業OpenPaths(openpaths.cc)を開始し、一般の人々に自分自身の位置情報を探索してもらうとともに、データの所有権についてその概念を体験してもらおうとしています。なんといっても、自分自身の生活や経験につながるこうしたデータの数値を自身でコントロールするべきでしょう。</simpara>
<simpara>ジャーナリストはデータの持つ固有の人間性に光を当てる重要な役割を担うのです。そのことで、データと数値が洗われる仕組み両方において世間一般の人々の理解をシフトさせる力を持っているのです。</simpara>
<simpara>&mdash; <emphasis>Jer Thorp, Data Artist in Residence: New York Times R&amp;D Group</emphasis></simpara>
</section>
<section id="_オープンデータ_オープンソース_オープンニュース">
<title>オープンデータ、オープンソース、オープンニュース</title>
<simpara>2012年は、オープンニュース元年になることだろう。オープンデータは、いまや編集上イデオロギーの中心であり、ブランディングのキーメッセージでもある。そんな中で、データドリブンジャーナリズムのためのオープンプロセスが必要なのは明白である。オープンデータによって促進されるだけでなく、オープンなツールによって可能にさせられるプロセスでなければならない。年末までに、全てのビジュアライゼーションに元となったデータと、コードの両方を公開できるようにしたいと思っている。</simpara>
<simpara>今日、ビジュアライゼーションに使われている多くのツールはクローズドのソースが多い。またはデータの二次創作を禁ずる厳しいライセンスを伴ったものかのどちらかだ。オープンソースのライブラリはある一つの問題を解決してくれるが、より広い方法論は提供しそこなっている。こうした背景から、互いの作品を元にさらにストーリーを組み立てていくということが非常にやりづらい状況にある。会話をオープンにするものよりも、閉じてしまうものばかりという現状に対し、我々はインタラクティブなストーリーテリングを可能にするMiso Projectを開発している。</simpara>
<simpara>このプロジェクトはほかの様々なメディアと共に話し合い、行っている。オープンソースソフトウェアの最大のポテンシャルを実現するにはコミュニティーの参画なしにはできない。これが成功すれば、読者にまったく新しい機能を提供できることだろう。コメントだけでなく、フォークしたり、バグをフィックスしたり、予想を超えるデータの活用がなされるなど、様々な方法での寄与が可能になるだろう。</simpara>
<simpara>&mdash; <emphasis>Alastair Dant, the Guardian</emphasis></simpara>
</section>
<section id="_ダウンロードリンクを追加する">
<title>ダウンロードリンクを追加する</title>
<simpara>ここ数年、数ギガバイトのデータをつかった記事に取り組みました。1960年代のタイプライターで書かれた文書をスキャンする作業から、ウィキリークスが発行した1.5ギガバイトにもおよぶケーブルの処理まで。いつも、編集者にオープンでアクセス可能な形式で、システマチックなソースデータの提供が必要だと納得させるのに苦労しました。その問題を飛び越えて、「データをダウンロードする」というリンクを記事の中に追加し、関係あるデータのアーカイブをグーグルドライブで手に入れられるようにしました。データのリユースをしてくれそうなユーザーの関心はは政府助成プログラムとだいたい同じくらいでした。（つまり、とても低い）しかし、限られた少数の活用事例は新たなインサイト（洞察）を提供し、会話に拍車をかけてくれました。プロジェクトごとほんの数秒の+αの努力の損はなかったと思います。</simpara>
<simpara>&mdash; <emphasis>Nicolas Kayser-Bril, Journalism++</emphasis></simpara>
</section>
<section id="_スコープを把握する">
<title>スコープを把握する</title>
<simpara>スコープを把握することです。スケールやパフォーマンスのためのハッキングと、遊びのハッキングは別物です。プロジェクトのための適切なスキルを持った人たちとパートナーシップを組ようにしましょう。ユーザビリティ、UX、そしてプレゼン資料のデザインを忘れてはいけません。これらはプロジェクトの成功を左右する重要な要素です。</simpara>
<simpara>&mdash; <emphasis>Chrys Wu, Hacks/Hackers</emphasis></simpara>
</section>
</section>
<section id="_ニュースアプリの作り方">
<title>ニュースアプリの作り方</title>
<simpara>ニュースアプリケーションはニュースストーリーの裏窓のようなものです。検索可能なデータベースや素敵なビジュアライゼーション、他のものを一緒にしたものなど。どんな形であっても、ニュースアプリは読者にとって意味のある文脈でデータと対話することを促します。例えば、地域の犯罪の傾向や地元の医者の安全記録を確認したり、候補者を選んでその候補者の政治的寄与を探すことができる。</simpara>
<simpara>ハイテクなインフォグラフィックに限らず、最高のニュースアプリは長持ちするものです。ニュースのライフサイクルとは別の流れで、実世界の問題を解決するよう読者を手助けし、質問に答え役に立つことで恒久的な情報源として利用されるでしょう。プロパブリカのジャーナリストたちは、肝臓透析の安全記録を調べるべく、読者の各々が住む地域の病院の安全性を確認できるアプリをつくりました。こうした重大で生活に関わるサービスを提供することでk時ひとつでは構築できなかったユーザーとの関係を築くことができるのです。</simpara>
<simpara>新進気鋭のニュースアプリをつくるには挑戦と約束がつきものです。永続的な価値を持ったものを作ること。それは開発者であってもマネージャーであっても、すばらしいニュースアプリをつくる話し合いは、製品開発のメンタリティから始めるべきです。ユーザーに的を当て、work to get the most bang for your buck. 開発を始める前に次の三つの質問を自分に問いかけるといいでしょう。</simpara>
<figure id="FIG062"><title>Dialysis Facility Tracker (ProPublica)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-AA.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-AA.png</phrase></textobject>
</mediaobject>
</figure>
<section id="_視聴者は誰か_視聴者のニーズは何か">
<title>視聴者は誰か、視聴者のニーズは何か</title>
<simpara>ニュースアプリそのものは記事のために存在しているのではありません。ユーザーのためです。プロジェクトによりますが、ユーザーは自分の通う病院の安全性を確認したい透析患者かもしれませんし、地震災害に気づかない家の所有者かもしれません。どんな人であっても、ニュースアプリをつくるための議論は、いい製品を作るための議論と同じように、誰が使うか、を定義するところから始めなければなりません。</simpara>
<simpara>シングルアプリ（一つのアプリ）がたくさんのユーザーにサービスを提供することもあります。例えば、Curbwiseというネブラスカ州のオマハにあるオマハワールドヘラルド紙がつくったアプリでは、課税が過多であると感じる家の所有者に役立っています。それだけでなく、近所の不動産価格が気になった住民や、最新の売り上げが気になる不動産で働く人などにも使われています。いずれの場合も、ユーザーがたびたび使えるような特定のニーズに合致しているのです。</simpara>
<simpara>例えば、家の所有者は近隣の不動産についての情報を集めて自分たちの税金が不当に多いか議論するために、情報収集の手助けが必要でしょう。そういったすべての情報を集積するのは時間のかかる複雑な作業です。Curbwiseは、ユーザーが課税額について地域の当局に問い合わせるのに必要なすべての情報を集め、ユーザーフレンドリーなレポートを提供することでソリューションとなっているのです。Curbwiseのレポートは20ドルの課金販売をしていて、このレポートが実生活の問題を解決してくれるからこそ人々はレポートを購入するのです。</simpara>
<simpara>アプリがCurbwiseのように実生活の問題を解決してくれるものか、それとも面白いビジュアライゼーションを通して記事に付加的なストーリーを与えるものなのかは、誰が使うかを意識することでわかります。そのあとデザインや機能を彼らのニーズに合わせて作っていくのです。</simpara>
</section>
<section id="_制作にどれくらいの時間を要するべきか">
<title>制作にどれくらいの時間を要するべきか</title>
<simpara>ニューズルームにいる開発者は砂漠の水のような貴重な存在です。誰もが求めるにもかかわらず供給が少ない存在。ニュースアプリをつくるには、日々のニューズルームに必要なことと、素晴らしい製品を作るための長期のコミットメントとの間の十分なバランスを取って行うということです。</simpara>
<simpara>例えば、編集者が開発者であるあなたのところにやってきてこう言います。「来週、市議会で町の歴史的建造物を取り壊すかどうか決議をとるそうだ。歴史的建造物の場所を地図でぱっとみてわかるようなちょっとしたアプリをつくってくれないか」と。</simpara>
<simpara>開発者のあなたに与えられた選択肢は二つ。一つは、エンジニアとしての腕の見せ泥子と言わんばかりに個別のソフトウェアを使った豪勢な地図をつくる。もう一つは、Google Fusion Tablesと、オープンソースの地図のライブラリを使って数時間で完成させる。一つ目の選択肢を選べば、より良いアプリを作ることができるでしょうし、二つ目の選択肢を選べば、それ以外にもっと長いインパクトを与えられるような別のものを作ることができるかもしれないのです。</simpara>
<simpara>ストーリーが複雑だからと言って、必ずしもニュースアプリにする必要はありません。優先順位のバランスが重要です。どんなアプリ制作もコストがかかることを覚えておきましょう。そのコストとはつまり、もっと別の影響力の多大なアプリケーションを作ることができていたかもしれない、ということです。</simpara>
</section>
<section id="_物事をさらにレベルアップさせるには">
<title>物事をさらにレベルアップさせるには</title>
<simpara>ハイエンドなニュースアプリは時間もお金もかかります。だからこそ結果について考えることが重要なのです。one-hitワンダーから特別なものに価値を高めるにはどうしたらいいでしょうか</simpara>
<simpara>ニュースのライフサイクルを超えた永久的なプロジェクトをつくるのも一つの方法です。その一方で、オープンソースにして、制作時間を短縮できるようなツールを作ってしまうことも時間稼ぎになります。または、自分のつくったアプリに高度な解析を行い、ユーザーについて知ることも一つの方法です。</simpara>
<simpara>多くの組織が国勢調査のデータをもとに、地図で人口の推移を自治体ごとに示すものをつくりましたが、シカゴトリビューンはワンランク上のアプリをつくりました。地図をスピーディーに作ることができ、他の団体も使えるようなツールを開発したのです。</simpara>
<simpara>私の働く調査報道センターでは、検索可能なデータベースを、イベントをトラッキングするフレームワークとともに組み合わせ、ユーザーが私たちのニュースアプリのなかで如何に偶然の発見と探索を価値づけているかわかりました。</simpara>
<simpara>数えるだけの単純作業員だと思われるかもしれませんが、投資した見返りについて必ず考えましょう。汎用性のある問題を解決し、ユーザーと対話する新しい方法を作るのです。タスクの一部をオープンソースにし、解析でユーザーの傾向を知り、Curbwiseのようにアプリが実際に収益につながるような事例を見つけてみましょう</simpara>
</section>
<section id="_終わりに">
<title>終わりに</title>
<simpara>ニュースアプリケーションの開発は、短期間の間に高い到達点に至っています。ニュースアプリの第一波はインフォグラフィック2.0のようなものでした。インタラクティブなデータビジュアライゼーションが検索可能なデータベースと共に、記事で描かれているニュースをより高度に表現できるようデザインされたものでした。いまや、こうしたアプリケーションをオープンソースのツールを使って、記者でも締め切りに間に合うように作ることができます。そのおかげで、開発者はそれ以外の大きな課題について考える余裕ができました。</simpara>
<simpara>ニュースアプリの第二波News App 2.0は、ストーリーテリングとジャーナリズムの公共奉仕の強みを、製品開発の鍛錬と共に技術の世界の専門性とを組み合わせて生み出す方向に業界は向かっているでしょう。これがもたらすものは、データが関連性を持った、読者にとって役立つようなイノベーションの劇的な増加を生むとともに、きっとジャーナリズムを手助けしていくことでしょう。</simpara>
<simpara>&mdash; <emphasis>チェイス・デイビス Center for Investigative Reporting</emphasis></simpara>
</section>
</section>
<section id="_プロパブリカのニュースアプリ">
<title>プロパブリカのニュースアプリ</title>
<simpara>ニュースアプリケーションは膨大なインタラクティブなデータベースでニュースのストーリーを伝えるものです。他のジャーナリズムの作品と同じようなものだと考えてみてください。ただ違うのは文字や写真ではなくてソフトウェアを使うところだけです。</simpara>
<simpara>読者に特定のデータを公表することで、ニュースアプリは読者一人一人にとって意義のある方法でストーリーを理解させることができます。国全体の現象について読者個人のつながりを見つけ、全体像を理解する手助けになることや、個人が知っていたこと、知らなかったことを添えて、抽象的な概念の理解を深めることができることができます。</simpara>
<simpara>データがある、またはデータを手にしたと思った時にニュースアプリを作るわけですが、国レベルのデータがあっても、細部の意味は荒っぽいデータであることが多いです。</simpara>
<simpara>ニュースアプリはストーリーを伝えなければいけません。これはほかの良記事を作るときと同じで、見出しや、小見出し、リード、グラフが必要です。インタラクティブなソフトウェアを使った記事でこうした概念を見つけるのは難しいですが、じっくり見るとそこには存在しています。</simpara>
<simpara>また、ニュースアプリはジェネラティブである必要があります。ジェネラティブとは、生成的で、さらなるストーリーやレポを生むべきであるという意味です。プロパブリカのアプリは地域の報道をする基盤として使われています。</simpara>
<simpara>例えば、Dolloar for Docsという私たちのニュースアプリを見てみましょう。製薬会社の数百ドルもの支払がどのように使われたかトラッキングしたものです。（例、コンサルティング、講演会、など）このニュースアプリは読者が自分の医者がどのような支払いを受けているか見つけるために作られました。他の組織にいる記者もこのデータを使っています。ボストングローブやシカゴトリビューン、セントルイスポストディスパッチを含む125を超える地方の新聞社がDollar for Docsを使って独自の調査報道を行いました。</simpara>
<simpara>正式なパートナーシップを組んでいるのはほんの一部で、私たちのアプリケーションを使ってニュースストーリーを作っているということは完成した記事が世に出るまで知らなかった、というケースもありました。ほとんどは自主的に行われた報道でした。小規模ですが全国規模で活動している私たちのようなニュース組織にとってこうしたことは、非常に重要なことです。125もの都市でどのようなことが起きているか私たちはわかりませんが、私たちのデータが地域に精通しているローカルのレポーターに使われ、影響力のあるストーリーを伝えることができるのなら、それは私たちのミッションを達成していることに変わりありません。</simpara>
<simpara>私のお気に入りのニュースアプリケーションはLAタイムズのマッピングLAです。これは、ロサンゼルスの様々な地域をクラウドソーシングしてマッピングしようと始めたもので、それまでは、独立した、誰もが認める境界線というのがなかったのです。最初のクラウドソーシングプロジェクトを経て、LAタイムズは近隣地区のデータを使った報道をどんどん増やしていくことができました。地区ごとの犯罪率、学校の質などこれまでできなかったことがわかるようになりました。マッピングLAは幅広いと同時に非常に限定されたジェネラティブなアプリケーションとなり、人々に自信の物語を伝える手段をつくったのです。</simpara>
<simpara>ニュースアプリケーションを作るのに必要なリソースは広範囲にわたります。ニューヨークタイムズは12人以上のスタッフがインタラクティブなグラフやニュースアプリケーションに従事しています。それに比べてTalking Points Memoは、コンピューターサイエンスの学位を持たないたった二人のスタッフによってつくられた新進気鋭の世論調査トラッカーアプリです。</simpara>
<simpara>ニュースルームにいるコーダーたちと同じように、私たちも（モディファイド）アジャイルな方法でアプリを作っています。私たちは下書きを作っては編集室のほかの人たちに見せて、また修正するという繰り返しを行っています。最も重要なことはレポーターと綿密に企画案から話し合っていくことです。最も最初の下書きであっても、です。私たちはこれまでのプログラマに比べたら圧倒的にレポーターのように行動しています。コードを書くだけでなく、情報源に電話したり、情報収集をして専門性を高めていきます。わからないことについていいニュースアプリをつくるのは難しいからです。</simpara>
<simpara>ニュースルームはデータドリブンのニュースアプリを作ることにどうして興味を持たなければいけないか。それは、3つの理由があります。まず素晴らしいジャーナリズムを生むということ。そして大変に好評であるということ（プロパブリカの最も人気の機能はニュースアプリケーションである）、そして最後にもし作らなければ他の人がつくってしまうということ。つくらなかったら重大なスクープを見逃してしまうわけです。一番大事なことは、どのニュースルームをデータドリブンのアプリケーションをつくることができる、といことをわかるべきです。思っているよりずっと簡単ですよ。</simpara>
<simpara>&mdash; <emphasis>Scott Klein, ProPublica</emphasis></simpara>
</section>
<section id="_データジャーナリズムの馬車馬としてのビジュアライゼーション">
<title>データジャーナリズムの馬車馬としてのビジュアライゼーション</title>
<simpara>チャートやマップにデータを投入しようとする前に、あなたのジャーナリズムの中で静的およびインタラクティブなグラフィックの要素が演じる多くの役割について、すこし時間をとって考えてみてほしい。</simpara>
<simpara>レポーティングの段階において、ビジュアライゼーションは:</simpara>
<itemizedlist>
<listitem>
<simpara>
あなたの報道以外に対してテーマや疑問を見分けるのに役にたつ
</simpara>
</listitem>
<listitem>
<simpara>
データの中の良いストーリーとなるはずれ値や確実でないエラーを見分ける
</simpara>
</listitem>
<listitem>
<simpara>
代表例の発見を手助けする
</simpara>
</listitem>
<listitem>
<simpara>
あなたの報道の全体像をみせる
</simpara>
</listitem>
</itemizedlist>
<simpara>ビジュアライゼーションもまた公開中に多くの役割を演じる。それらが演じるのは、</simpara>
<itemizedlist>
<listitem>
<simpara>
ストーリーの中で作られたポイントをより強制力のある方法で描く
  散文から不必要な技術的な情報を排除する
</simpara>
</listitem>
<listitem>
<simpara>
それらがインタラクティブかつ探索を許すときは特に、あなたの読者にあなたの報道のプロセスについて透明性をもって提供できる
</simpara>
</listitem>
</itemizedlist>
<simpara>電子的なデータや記録を使って始める始めないに関わらず、報道のなかでのビジュアライゼーションを素早く、頻繁に手始めにすべきであることをそれらの役割は示している。段階を飛ばしていることなど気にすることなく、ストーリーがおおかた書かれた後で気にする方がよい。この効果はあなたの報道の助けになる。</simpara>
<simpara>始めるときは、ビジュアルフォームを既に取り入れたノートを当てはめることを意味する。2006年にワシントンポストが提供した<xref linkend="FIG064"/>について考えてみよう。</simpara>
<figure id="FIG064"><title>農家の助成金年鑑（ワシントンポスト）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-MM.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-MM.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>のべ過去45年で助成金や重要なイベントに関連した農家の所得を月ごとに構築したものを示す。時間軸のなかで同様の定義と意味付けをもつデータを探すことが課題であった。山や谷のすべてを調査することは、私たちの報道以外の文脈を読み解く手助けとなる。それはまたストーリーが書かれる前に雑用がほとんど完了していたことを意味する。</simpara>
<simpara>データセットを探索し始めようとするために、ビジュアライゼーションを使うためのいくつかの小話をここに書いておきます。</simpara>
<section id="_tip_1_大規模なデータセットを小さな倍数ですばやくあなた自身に合わせる">
<title>Tip 1:大規模なデータセットを小さな倍数ですばやくあなた自身に合わせる。</title>
<simpara>ジョージ・ブッシュ政権が政治的、実質的ではない、根拠に基づいて助成金を授与された話について調べていたときに、このテクニックをワシントンポストで利用していた。援助プログラムのほとんどは数式によってなされており、他人は長年に渡って蓄えられてきた。だから、私たちが1500近くある異なった任意の文脈をみることでパターンを見いだすかどうかに私たちは興味をもっていた。</simpara>
<simpara>私は、それぞれのプログラムのためのグラフを作成し、大統領選の年を示す赤い点や議員選挙を示す緑の点を用いた。問題は、大統領選の前の６ヶ月ごとの釘がいくつかの問題としてあることだ。ピークの赤い点の数点がそれらに近づくときがあるが、しかしそれは、選挙の年ではない。そのパターンは、2004年ではなくアル・ゴアとジョージ・ブッシュの間の2000年の大統領選の間で現れる。</simpara>
<figure id="FIG065"><title>HHS Grants:ストーリーの位置付けにおける折れ線ヘルプ（ワシントンポスト）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-NN.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-NN.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>たくさんのテーブルを見ることや私たちに様々な許諾や地域、所属機関などを答えさせるインタラクティブフォームよりむしろ、一連のグラフを見る方が簡単である。小さな多機能のなかのマップは時間や場所をインタラクティブより比較するのが簡単に静的なイメージを見せる一つの方法である。最小限の努力で地図は時にはインタラクティブな地図よりも簡単に静的なイメージ乗で場所や時間などを比較して見せることのできる一つの方法である。</simpara>
<simpara>この例はPHPで書かれた短いプログラムで作られているが、いまやエクセルの2007と2010の折れ線機能でより簡単に作ることができる。ビジュアライゼーションのエキスパートであるエドワード・タフテは巨大なデータ・セットを見渡して情報を伝えるために、それらを「刺激的で、シンプルで言葉のようなグラフィックス」として発明した。あなたは今や、どこにいても株式市場の相場に基づいた小さなグラフからスポーツの勝ち負けの記録までそれらを見ることができる。</simpara>
</section>
<section id="_tip_2_自分のデータを隅々までみること">
<title>Tip 2: 自分のデータを隅々までみること</title>
<simpara>あなたがストーリーやデータ・セットについて理解しようとするとき、それらを凝視すること以外に正攻法はない。思い付く限りの方法をためすことで、異なった視点を得ることができる。もしあなたが犯罪についてのレポーティングをするなら、あなたは年鑑の暴力犯罪の変化のチャート群を見るかもしれないし、別の方法として割合の変化を見るかもしれない。一方で他の市との比較を行ったり、時間変化を見るかもしれない。生の数値やパーセンテージ、指標をつかって。</simpara>
<simpara>異なったスケールでそれらをみよう。X軸はゼロが存在するべきだというルールに従うようにしよう。それからルールを壊し、より発見があるかを見てみよう。変わった分布をもつデータのために対数や平方根を試してみよう。</simpara>
<simpara>ビジュアル的な観測を行うリサーチで気をつけること。ウィリアム・クリーブランドの実験は平均線が約45度の角度のときに画像の変化を目が認識することを示した。この提案は洞察的なグラフィックに向けた効果の変わりに常にゼロから始めるという訓戒を無視することを示す。別の疫学の研究では、あなたがチャートのための境界線としての目標レベルを発見することを提案する。これらの方法のそれぞれは異なった方法でデータを見ることを手助けしている。何か新しいことを伝えることをやめようとしているとき、あなたは自分がしてしまったことを知るだろう。</simpara>
</section>
<section id="_tip_3_思い込むな">
<title>Tip 3: 思い込むな</title>
<simpara>いまや、自分のデータを様々な方法で見ることができるようになったが、あなたは正しいと思えない記録を見つけてしまっているかもしれない。あなたは、初期の部分でデータのミスのようにいくつかのはずれ値をみていたり、または、後に続く傾向として意味があると理解していないかもしれない。</simpara>
<simpara>もし、あなた自身の初期の探索や、すでに公開されているビジュアライゼーションに基づいたものを公開したいなら、これらの質問を解決しなければならないし、仮説を作ることはできない。それらはむしろ、おもしろい物語や間違いであり、面白いチャレンジが共通の知見や間違った理解になるだろう。</simpara>
<simpara>地方行政がエラーで満たされたスプレッドシートを提供することは珍しくない。そして、データ・セットの中で行政の専門用語を間違えて理解することは容易い。</simpara>
<simpara>最初に、自分自身の作品を振り返ってみよう。文書作成は完了しているか、データのオリジナルバージョンに警告や問題が存在していないだろうか。もしあなたの終点の全てが正しいように見えるなら、電話をかける時かもしれない。もしそれを使う計画があるなら、それを解決しなければいけないだろうし、すぐに取りかかるべきだ。</simpara>
<simpara>必ずしもすべのミスは重要ではない。選挙資金の記録では、十万レコードのデータベースに存在しない数百の郵便番号を持つことが一般的です。同じ都市のなかに存在するものでもなく、候補者に属するものでもないように、時折不正データがあっても重要な問題ではない。</simpara>
<simpara>自分自身へ尋ねるときの質問は、もしこれをつかっていなければ、読者はデータが何を示すのかという基礎的な洞察的で正確な視点を得ていただろうか、である。</simpara>
</section>
<section id="_tip_4_正確性について悩むことを避ける">
<title>Tip 4: 正確性について悩むことを避ける</title>
<simpara>それが重要となる前に十分な疑問を必要としないぽっと出の側面は正確性について悩みの種になる。あなたの探索的なグラフは一般的に正しくあるべきだが、しかしデータを丸める作業に色々なレベルがあるか、100％の正確性に追いつく必要がない場合やあなたが20以上の内の１、２年後のデータを失うかどうかについて心配しなくてよい。これは探索のプロセスの部分に占めることが大きい。あなたは、いまだ大きな流れを見ることができ、公開するまでに何を正さなければならないのか知るだろう。</simpara>
<simpara>実際に、あなたはラベルやマーカーのスケールを取り除くことを考えるかもしれないが上のチャートのようなもののほとんどは、データの意味をより得ることができる。</simpara>
</section>
<section id="_tip_5_事例や出来事の年譜をつくる">
<title>Tip 5: 事例や出来事の年譜をつくる</title>
<simpara>複雑なストーリーを始めるとき、重要なイベントや事例の年譜を立て始める。エクセルやワードやタスクのためのTimeFlowのような特別なツールを使えるが、重要なのは後ろに重ねることのできるデータ・セットを見るけることである。定期的なデータ・セットの読み込みがあなたに、提出しなければならない報道での全体像をしめす。</simpara>
</section>
<section id="_tip_6_グラフィックス部門と迅速に何度も打ち合わせする">
<title>Tip 6: グラフィックス部門と迅速に何度も打ち合わせする</title>
<simpara>ニュースルームの中でアーティストやデザイナーとともに可能なグラフィックスのブレインストームを行う。それはあなたのデータを見るのにとても良い方法であり、いかにしてインタラクティブに作用させるかの提案であり、いかにしてデータとストーリーを結びつけるか知ることができる。何を最初に集めるべきかを知っているか、データを集めることができなかったときにグラフィックが作れないチームに警告を出せるかどうかで、あなたの報道はよりよいものとなる。</simpara>
</section>
<section id="_公開のためのtips">
<title>公開のためのTips</title>
<simpara>探索のために２、３日や２、３時間しか費やせないかもしれないし、またはあなたのストーリーは報道するために数ヶ月も掛かるかもしれない。しかし公開への移行のタイミングになったとき、二つの重要な側面がある。</simpara>
<simpara>あなたの早期の探索において年代のミスがあったとき覚えておいてほしいことがある。突然、それなしには何も出来なくなってしまう。すべては報道の中で悪いデータを無視していなかったか。それはあなたを後戻りさせることになるだろう。理由として、悪いデータまわりについて書かなかったからである。グラフィックスにとって、中間層もなければ、あなたが必要とするしないに関わらず、すべてのものを書く必要がある。</simpara>
<simpara>インタラクティブグラフィックとデータ集合への努力をあわせる
  インタラクティブグラフィックスにおいて隠すものはない。もしあなたが本当に読者の望むいかなる方法でもデータの探索を提供するつもりなら、要求された全てのデータ要素があるべきだ。ユーザはいつでもエラーを発見でき、それはあなたを多数の年月を費やさせることになるだろう。もし、独自のデータベースを構築したら、校正し、事実確認をし、データベース全体の整理をしなければいけないことが予測できるだろう。行政の記録を使うならば、あなたがすべき部分的なチェックはどれくらいか、再編集が必要なエラーを発見したときにどう対処するか決める必要がある。</simpara>
<variablelist>
<varlistentry>
<term>
２タイプの読者のためのデザイン
</term>
<listitem>
<simpara>
  スタンドアロンなインタラクティブ型、あるいはストーリーと一緒になった静的なビジュアライゼーション型のどちらかのグラフィックスは２種類の異なった読者を満足させるべきだ。一目みて理解しやすいようにするべきであるが、より深く知りたい人々を満たすような十分な複雑性をもつ必要もある。もしインタラクティブなものをつくるなら、読者に対して単一の数や名前を得るのではなくより多くの何かを得られるようにするべきた。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ひとつのアイディアを伝える、それから単純化する
</term>
<listitem>
<simpara>
  あなたが人々に見せたいたった一つのものがあるか確かめよう。あなたが読者に得てほしい圧倒的な印象に決定づけられ、そしてその他のすべてが消えていく。多くの場合、インターネットがあなたに全てを提供することを認めたときでさえ、情報を取りこぼしていることを意味する。あなたの主な目的が報道の浸透でない限り、あなたのタイムラインや年譜上であなたが集めた詳細なデータのほとんどはあまり重要ではない。静的なグラフィクにおいては、無駄なものになるだろう。インタラクティブなグラフィックでは退屈なものになるだろう。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>&mdash; <emphasis>サラ・コーエン, デューク大学</emphasis></simpara>
</section>
</section>
<section id="_可視化を利用して知見を見つける_2">
<title>可視化を利用して知見を見つける</title>
<simpara>データビジュアライゼーションはいくつかの理由で考慮するメリットがある。驚くほどに美しく注目(共有や読書を惹きつけるのに価値ある社会的価値)を集めるだけでなく、強力な認知利点も活用する。人間の脳の優に半分は、視覚情報を処理するために向けられている。あなたはインフォグラフィックでユーザーにプレゼンをする時、あなたは心の最も多くを占める領域を通してユーザーに触れている。良いデザインのデータビジュアライゼーションは聴取者にすぐに深い印象を与えることができ、要点を理解するために複雑な話の混乱を切り崩すことが出来る。</simpara>
<simpara>しかし、このような写真やビデオのほかの視覚メディアと違って、データビジュアライゼーションもまた測定出来る事実に深く根付いている。 審美的な魅力が、あまり感情的にならず、より事実に関心を得られる。 変化する時代において:ある視点で視聴者に合わせられている[&lt;phrase role=<emphasis>keep-together</emphasis>&gt;狭く-&lt;/phrase&gt;]焦点をおかれたメディア , データビジュアライゼーション(そして一般的にはデータジャーナリズム)は狂信でなく事実に基づかれたストーリテリングのための興味をそそられる機会を提供している。</simpara>
<simpara>さらに、物語りジャーナリズムの他の形態のように、データジャーナリズムはニュース速報(事故の位置や志望者数のような新情報を早く伝える事）や呼び物記事の両方にとって有効になりえて、完全に新しい方法で見慣れたものの理解を理解を助けるために、データジャーナリズムは話題により深入りすることができ、新しい考え方を提供できる。</simpara>
<section id="_新しい方法で馴染みのものを見ること">
<title>新しい方法で馴染みのものを見ること</title>
<simpara>実際、世界的な経済危機が始まった1年後、一般通念を検証するためのデータビジュアライゼーションの能力は2009年後半にニューヨークタイムズによって発行された <ulink url="http://nyti.ms/employment-lines">インタラクティブなグラフ</ulink> によって 例示されている。米国の失業率が9%近くでさまよっていると、ユーザーは様々な人口統計や学歴フィルターによって、米国人口を選別することが出来た。結局のところ、その内訳は学士号より上の学位を持つ中年女性から高校を卒業していない若い黒人男性の全体の半分近くで4%未満を占められていて、この格差は真新しくなかった。それは、これらのグループのそれぞれに対する歴史的な価値を示された熱線により強調された事実である。</simpara>
<figure id="FIG066"><title>あなたのような人々のための失業率 (New York Times)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-GG-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-GG-01.png</phrase></textobject>
</mediaobject>
</figure>
<?dbfo-need height="1in"?>
<simpara>それを見終わったあとでさえ、良いデータビジュアライゼーションは頭の中に入り、事実、傾向またプロセスの持続的なメンタルモデルが残る。どれだけ多くの人々が　2004年12月の <ulink url="http://1.usa.gov/tsunami-animation">津波研究者によるアニメーション</ulink> を見たのだろうか。それは、南アジアと東アフリカで何百万もの海岸の居住者を脅かして、インド洋を横切ってインドネシアの地震から外へ広がる滝のような波を示していた。</simpara>
<simpara>中核地域を占めていた「赤い」共和党と「青い」民主党が北東部と遠い西洋で分かれた時、データビジュアライゼーション(及びそれらがもたらす審美的な連想）は、2000年と2004年の選挙後の合衆国における深い政治的分裂の表現のような文化的な基準にさえなり得る。2000年以前の合衆国メディアでは、主な放送局が4年毎に交互に選択しているそれぞれの政党を表す赤と青を自由に切り替えていたことを気にかけない。したがって、いくらかのアメリカ人は1984年の共和党のための Ronald Reaganの <ulink url="http://bit.ly/infobarrel-map">壮大な49州の&#8216;`青色&#8217;'圧勝</ulink> を記憶している。</simpara>
<simpara>しかし、ビジュアルの決まり文句を生み出すそれぞれのグラフィックにとって、別のものは人脈と再配置プログラムを混合によって大陸に散らばった強力な事実の証明を提供する。それは、ニューオーリンズの何十万もの避難民を現すための異なったサイズの円を用いているNew York Timesの<ulink url="http://nyti.ms/diaspora-graphic">2006年の地図</ulink>のようである。これらの「行き詰まった」避難民はいつか帰宅するのだろうか？</simpara>
<simpara>なので、今、私たちはデータビジュアライゼーションの強力さを議論してきた。それは尋ねるのに公平である。私たちがそれを利用すべきだろうか？利用しないべきであろうか？まず、私達は読者へ物語りを伝えるときにデータビジュアライゼーションが役立つかもしれないいくつかの例を見てみる。</simpara>
</section>
<section id="_時間と共に変化することを示す">
<title>時間と共に変化することを示す</title>
<simpara>おそらく、（humble fever chartの象徴としての）データビジュアライゼーションの最も一般的な利用は値が時間とともにどのように変わったか示すことです。<ulink url="http://bit.ly/google-china-population">China&#8217;s population since 1960</ulink>の成長や2009年の経済恐慌以来の失業者の曲線は良い例です。しかし、データビジュアライゼーションも他のグラフを通して時間による変化を非常に強力に表すことが出来る。ポルトガルの研究者Pedro M. Cruzは19世紀始めからの<ulink url="http://pmcruz.com/visual-experiments/visualizing-empires">ヨーロッパ西部の帝国の衰退を示す</ulink>動的な円グラフのアニメーションを利用した。総人口が大きさで、海外領が独立を達成するとともに、英国、フランス、スペインおよびポルトガルは泡のようにポップします。メキシコ、オーストラリア、ブラジル、インドがそこ行き、またそれを待って&#8230;そこに行く、初期の60年代にほとんど消えるフランスのアフリカ植民地がそこへ行く。</simpara>
<simpara><ulink url="http://on.wsj.com/tech-empire">Wall Street Journalによるグラフ</ulink> は収入での5000万ドルのマジックナンバーに達するのに100の起業家が何ヶ月かかったかを表す。フリーチャートとデータ分析ツールTableau Publicを利用して作られ、比較はいくらかが早く、いくらかが遅く、いくらかが重くそれぞれが描画されいて、多数の滑走路に似ている。</simpara>
<simpara>飛行機の話をすると、時系列の変化を示している他の興味深いグラフは、業界再編の数十年の間についての<ulink url="http://nyti.ms/airline-merger">米国の主要航空会社の市場占有率を描画したもの</ulink> がある。Carter政権が旅客飛行を規制緩和した後、New York Timesが描いたこのグラフのように、たくさんの国債融資が小さな地方航空会社から全国航空会社を作成しました。</simpara>
<figure id="FIG068"><title>飛行経路の収束 (New York Times)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-GG-02-b.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-GG-02-b.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>ほとんど全てのカジュアルの読者が図の水平線「X」軸を時間を表すと見るとするならば、時には、<emphasis>全て</emphasis>のビジュアライゼーションが時系列での変化を表すべきだと考えることは容易である。</simpara>
</section>
<section id="_値の比較">
<title>値の比較</title>
<figure id="FIG069"><title>戦争の人的コストの計算 (BBC)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-GG-03.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-GG-03.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>しかしながら、BhBCが実施した犠牲者のデータベースを伴う<ulink url="http://bbc.in/animated-slideshow">animated slideshow</ulink>もしくはNational Geographicの<ulink url="http://bit.ly/ngm-hearts">using a very minimalist chart</ulink>のようにイラクとアフガニスタンの争いにおけるサービスマンと女性の悲しい被害の文脈におくかどうかを、それらとベトナムで殺された何千人もの命や第二次世界大戦で無くなた何百万もの命と比較することによって、データビジュアライゼーションは読者が二つやそれ以上の値の比較のするのを助ける分野においても輝く。データビジュアライゼーションは、あなたが（５回に1回で)心臓病、(24回に1回で)発作で死ななければならないぐらい多いことを示したし、(全死亡におけるオッズを表す大きな円によって全て覆われる)死亡の相対比を示すことによって(5051回に1回で)飛行機事故,(56789回に1回で)蜂に刺されると言える。</simpara>
<?dbfo-need height="1in"?>
<simpara>さらに、機関Berg Designとの共同でBBCは、自身のコミュニティーのGoogle map上で主な世界の出来事(例えば、深海の地平線石油流出あるいはパキスタンの洪水)の概要を重ね書きさせるウェブサイト<ulink url="http://howbigreally.com/">"Dimensions"</ulink> を開発した。</simpara>
</section>
<section id="_繋がりと流れを見せること">
<title>繋がりと流れを見せること</title>
<simpara>1981年におけるフランスの高速鉄道の始まりは、文字通り国をより小さくしなかったが、巧妙なビジュアル表現は従来の路線に比べて異なる地点に到着するのにどれぐらい少ない時間になるのかを示す。以前は列車は未開拓の線路に着き、遅くならなければならなく国の上のグリッドは、``以前の<emphasis>'画像では正方形で表されていたが、そと向きの目的地が"より近く"なっていることを表すだけでなく、旅の最初において最も時間節約することを表し``以後の</emphasis>'画像ではパリへ中心に向かって押しつぶされている。</simpara>
<simpara>二つに分けられた値を比較するために、メジャーリーグベースボールチーム<ulink url="http://benfry.com/salaryper/">relative to their payrolls</ulink>のパフォーマンスが計算されているBen Fryの図を見る。左側の列では、チームは日付ことの成績によってランク付けされていて、一方右側の列は年俸の合計である。赤色(標準以下)もしくは青色(標準以上）で描かれた線は二つの値つなぎ、駄目になった年俸の高い選手に後悔しているチームオーナの便利な感覚を提供している。さらに、タイムライン全体を磨くことで、最後にシーズンの&#8220;ペナントレース&#8221; の活発なアニメーションを提供する。</simpara>
<figure id="FIG0610"><title>年棒対パフォーマンス (Ben Fry)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-GG-04.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-GG-04.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_データでデザインすること">
<title>データでデザインすること</title>
<simpara>繋がりをグラフにするの方法と同様に、流れの図もいつも通り太さ・色によって情報を線の繋がりに組み込んで符号化する。例えば、危機、およびそれらの債務を返済できない人におけるのユーロ圏で、EUメンバーに彼らの取引相手を結んでいるNew York Times <ulink url="http://nyti.ms/eurozone-crisis">sought to untangle the web of borrowing</ulink>は大西洋とアジアを隔てている。ビジュアライゼーションの一つの``状況<emphasis>'において、黄色からオレンジ色のランプは払い戻しのような``心配</emphasis>'を示していて、線の太さはある国から他国へ渡る信用度反映している</simpara>
<?dbfo-need height="2in"?>
<simpara>より幸せな話題において、National Geographicマガジンは主要なワイン生産地域に<ulink url="http://bit.ly/sankey-wine">米国の3年の接続を示す一見単純な図</ulink>&amp;mdash ニューヨーク、シカゴやロサンゼルス--を発行した。そして、それぞれの地域から製品を運送するどのような輸送手段が圧倒的に異なる炭酸ガス排出量に結論づくかもしれない。例えば、カリフォルニアよりニューヨークのワインの方がボルドーワインを環境に優しい購入になる。</simpara>
<simpara>MITのビジネススクールで始められたプロジェクト「SourceMap」は、製造した製品、構成要素や原材料に対する世界的な調達を正確に見るために流れ図を利用している。多くの研究のおかげで、利用者は<ulink url="http://sourcemap.com/view/1760">Ecco brand shoes</ulink>から<ulink url="http://sourcemap.com/view/1011">orange juice</ulink>に至るまでの製品を探索することが出来る。そしてそれがどこから供給されているかとそれに対応する炭酸ガス排出量がを見つけられる。</simpara>
</section>
<section id="_階層を示すこと">
<title>階層を示すこと</title>
<simpara>研究者Ben Shneidermanは、互いの内部で同心円上に入れ子になっている複数の箱を含む<ulink url="http://www.cs.umd.edu/hcil/treemap-history/">"ツリーマップ"</ulink>と呼ばれる新しいビジュアライゼイーションを開発した。<ulink url="http://openspending.org/">代理店や副代理店による国家予算の可視化</ulink>、部門や会社による株式市場を可視化、クラスやサブクラスによるプログラミング言語であれ、ツリーマップは、実態とその成分を表すのにコンパクトで直感的なインターフェースである。別の効果的なフォーマットはより典型的な構造図のようにみえる樹形図である。この図では、サブカテゴリーが単一の幹から分岐され続けている。</simpara>
<figure id="FIG0612"><title>OpenSpending.org (Open Knowledge Foundation)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-GG-06.png" scale="80"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-GG-06.png</phrase></textobject>
</mediaobject>
</figure>
<?dbfo-need height="2in"?>
</section>
<section id="_大きなデータセットをブラウンジングする">
<title>大きなデータセットをブラウンジングする</title>
<simpara>時々、データビジュアライゼーションはよく知られている情報を話す時や新しいものを示す時とても効果的であるが、人々が検索したい真新しい情報をあなたが受け取った時に、何が起こるだろうか？Eric Fischerの優れた<ulink url="http://bit.ly/flickr-analysis">Flickrのップ写真の地理的な分析</ulink>から以前の何千ものニューヨーク市のリリース <ulink url="http://projects.wsj.com/nyc-teachers/">機密の教師評価</ulink>まで、データの時代はほぼ毎日、驚くべき新しい発見をもたらす。</simpara>
<simpara>ユーザがとても適切に情報を掘り下げることが出来る時に、これらのデータセットは彼らの最も強力なものである。</simpara>
<simpara>2010年の前半に、New York TimesはNetflixでどの映画がどの地域で最も借りられているかの通常個人的な記録にアクセスしていた。Timesはユーザに郵便番号レベルで分解された12米国都市でのトップ100位のレンタルを閲覧させる<ulink url="http://nyti.ms/interactive-database">魅力的なインタラクティブなデータベース</ulink>を作成した。色分けされた「ヒートマップ」は各コミュニティで素早くざっと見でき、特的のタイトルが最も人気のあった場所を見ることが出来るように重ねられている。</simpara>
<simpara>同年の終わりに向けて、リリースされた後の僅か数時間で、Timesは<ulink url="http://nyti.ms/census-explorer">米国の10年ごとの国勢調査の結果を発表</ulink>&mdash;した。Adobe Flashを組み込まれたインターフェースは、数多くのビジュアライゼーションのオプションとユーザが人種、収入、教育ごとの居住者の分布を見るためにの(8.2万を超える)国家の各国勢調査ブロックまで閲覧出来るものをを提供した。そのようなものは、公開後の最初の時間でデータセットに目を通しているというデータの分析でした。あなたは、データの一角を調査する世界で最初の人になれかもしれないと思った。</simpara>
<simpara>データベースのフロントエンドとしてビジュアライゼーションの同じような賞賛に値する用途は、BBCの<ulink url="http://bbc.in/road-deaths">交通死亡の調査</ulink>やWikiLeaksにあるイラクやアフガニスタンの戦争記録の開示のような大きなダンプデータを素早くインデックスするという多くの試みがある。</simpara>
<sidebar>
<title>The 65k Rule</title>
<simpara>WikiLeaksからアフガニスタンの戦争記録の最初のダンプを受け取ることで、チームが処理するデータは彼らが65000の軍事記録にアクセスしなければならなかったことがどれほど興奮させるかについての話が始まった。</simpara>
<simpara>これはMicrosoft Excelの経験を持った人々でアラームが鳴るようにすぐセットしました。行が割り当てられるという方法において歴史的な制限のおかげでエクセルの読み込みツールは、65,536行以上を処理しなかった。この場合においては、25000行以上の列が欠損していたことが明らかであった！</simpara>
<simpara>（そのようなタスクでエクセルを利用を避けることはさておき）この話の教訓は、65000行のデータについて自慢する誰もをいつも疑うっているということです。</simpara>
<simpara>&mdash; <emphasis>Alastair Dant, the Guardian</emphasis></simpara>
</sidebar>
<figure id="FIG0613"><title>1999年から2010年イギリスの路上におけるすべての死(BBC)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-GG-07.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-GG-07.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_代替結果を想定する事">
<title>代替結果を想定する事</title>
<simpara>New York Timesにおいて、何年にも渡る<ulink url="http://nyti.ms/porcupine-graph">悲惨なほど楽観的な米国の赤字予測</ulink>のAmanda Coxの「ヤマアラシ図」は起こらなかったことより面白くないことが起きたことがどれほどあるか示している。戦争と減税の十年の後に財政赤字が急増していることを示しているCoxの熱線は将来の期待が起きることがどれほど非現実的かを示している。</simpara>
<figure id="FIG0614"><title>現実に対する予算見通し (New York Times)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-GG-08.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-GG-08.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>長い間Apple社のインターフェースデザイナー（そして定量的な情報を通信するためのビジュアライゼーション理論「kill math」の考案者）である、Bret Victorさんが_http://worrydream.com/#!/TenBrighterIdeas[反応する文書]_のようなものを試作している。彼の例では、アメリカ人の2基から40基の石炭発電所の出力を省くことが出来る空室の明かりを止めることのような単純な手順によって、省エネのアイディアは変更可能な施設を含んでいる。テキストの段落の中央部に参考文献として載せられた割合を変更することで、ページの残りの中のテキストをそれに応じて変更させる。</simpara>
<simpara>ここに地図やインタラクティブなグラフ<ulink url="http://bit.ly/ericson-links">New York TimesのMatthew Ericsonがまとめた</ulink> ビジュアライゼーションのための異なる用途のリストがある。</simpara>
</section>
<section id="_データの可視化を使用しないとき">
<title>データの可視化を使用しないとき</title>
<simpara>最後に、効果的なデータのビジュアライゼーションは、良く、クリーンで、正確で、意味のある情報に依存している。ちょうど良い多さの引用で、事実に基づき、要約されている良い物語のあるジャーナリズムに力があるように、データのビジュアライゼーションはそれに燃料を供給するデータと同じぐらい良い。</simpara>
<variablelist>
<varlistentry>
<term>
あなたの物語が文章やマルチメディアを通して語られるとより良くできるとき
</term>
<listitem>
<simpara>
  データ一人では、最も魅力的な方法で物語を語らない時がある。傾向線や要約統計量を描いている単純な図は有用であるが、現実世界の問題の結果を関連づける物語は読者により早くインパクトを与えることが出来る。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
あなたが非常に少ないデータしか持っていない時
</term>
<listitem>
<simpara>
  「単独の数字は何も意味がない。」と言われています。引用された統計へ反応するニュース編集者からの社記一般の話は、「何かと比較されているか？」。傾向は上がっているか下がっているか？通常は何か？
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
データにとても小さなばらつきがあるときの不明瞭な傾向もしくは結論
</term>
<listitem>
<simpara>
  あなたはエクセルや似たような作図ソフトでデータをプロットし、情報がノイズであること、もしくは多くの変数を持っているか、もしくは比較的水平な傾向を持っていることを発見する時がある。あなたは線により形を与えるためにゼロから最も低い値までベースラインを上げるだろうか？そんなことはない！あなたが曖昧なデータを持っており、より深い探索と分析をする必要があるように聞こえる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
地図が地図でない時
</term>
<listitem>
<simpara>
  空間要素は意味や説得力が無い時がある、または時間による変化または非隣接地域間の類似性を示しているようにより適切な数値の傾向から目をそらすことがある。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
表で表現する時
</term>
<listitem>
<simpara>
  もしあなたが関連のある少ないデータしか持っていないが、読者の何人かが利用するかもしれない情報を持っているならば、表形式でデータを表現することを考慮しよう。それは、クリーンで読みやすく、「物語」の非現実的な期待を作りません。実際、表は基本的な情報に対してとても効率的で上品な表現になりえる。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>&mdash; <emphasis>Geoff McGhee, Stanford University</emphasis></simpara>
</section>
</section>
<section id="_異なる図は_異なる結果を意味する">
<title>異なる図は、異なる結果を意味する</title>
<simpara>実にリアルな3D体験までできてしまうような、今日のデジタル世界にいると、もうずいぶんと長い間、紙に印字したものしかない時代を過ごしてきたことをつい忘れがちになってしまう。今となっては紙は静的で平坦で、ちょっと劣ったメディアだと思ってしまうけれど、実のところはもう何百年もの間にわたって、紙に書いて、印刷をすることで、信じられないほどの豊かな知識とデータをなんとかその紙に示すことを我々は成し遂げてきたわけである。いま流行りのインタラクティブ・チャートやデータ・ビジュアライゼーション、そしてインフォグラフィクスも、もとは我々が学んできた多くのベスト・プラクティスのもとに成り立っている。過去に作り上げられてきた図とグラフを振り返ることで初めて、我々はその知識を理解することができ、そしてまたそれを新しいメディアに持ち込んでいくことができるのである。</simpara>
<simpara>代表的な図やグラフの一部は、難解な表データをよりわかりやすく説明するために生まれたものである。1700年代の後半から1800年代の初頭に生きた、多言語に通じたスコットランド人のウィリアム・プレーフェアは、今日でも同じように使われている図やグラフのほとんどを、たった一人で世界に送り出した人物である。1786年の彼の本、「Commercial and Political Atlas（商業と政治の地図）」のなかで彼は、棒グラフという全く新しく、視覚的な手法を用いて、スコットランドの輸出入量を明快に示したのである。</simpara>
<simpara>そして彼は、1801年の本、「Statistical Breviary（統計的な聖務日課書）」の中で、世にも恐ろしい円グラフを世に広めた。 これらの新しい形の図とグラフは、商業的なニーズから生まれたものであったが、時間が経つにつれて、別の者が現れて、人の命を救うために使うようになった。1854年、ジョン・スノウは今日では有名な「ロンドンのコレラ地図」を、発症が報告された地域に小さな黒い棒をつけて作成した。徐々に時間が経つに連れ、明らかに発症密度が高い地域がわかるようになり、問題の抑制措置が取ることができた。</simpara>
<simpara>時間が経つに連れて、これらの新しい図とグラフの使い手たちは、より大胆かつ実験的になり、そして今日のメディアになるまで押し進めていった。アンドレ＝ミッシェル・グエリーは、地図に何らかの変数に応じて、地図の各々の地域を違う色で塗り分けるというアイデアを最初に世に出した人物である。彼は1829年に、犯罪レベルに応じてフランスの地図の各地区を影付けをして、初めてのコロプレス地図を作成した。今日、これらの地図は、例えば選挙区ごとに誰が誰に投票したかや、富の分布、その他の多くの地理的な要因に結びつく変数を説明するときに使われている。非常にシンプルなアイデアに見えるが、上手に使えるように習熟するのは難しく、またそうでないと、理解しづらいものになってしまう。</simpara>
<figure id="FIG0615"><title>初期の頃の棒グラフ（ウィリアム・プレーフェア）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-TT-01.gif" scale="83"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-TT-01.gif</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG0616"><title>ロンドンのコレラ地図（ジョン・スノウ）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-TT-02.jpg" scale="81"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-TT-02.jpg</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG0617"><title>犯罪レベルを示すフランスのコロプレス地図（アンドレ＝ミッシェル　グエリー）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-TT-03.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-TT-03.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>心あるジャーナリストがビジュアライゼーションを行う上で理解している必要があり、持っているべきツール類は沢山あるが、難しいことに首を突っ込む前に、素晴らしい基礎である、図とグラフを押さえることが重要である。作ろうとするものが何であっても、まずはほんの少数の図とグラフから始める必要がある。こういう基本をしっかりとマスターしたうえで、それらの基礎的な要素を組み合わせた、より複雑なビジュアライゼーションに進んでいくことができるのである。</simpara>
<simpara>もっとも基本的な2つのタイプの図表は、棒グラフと折れ線グラフである。この2つは使われ方も非常に似ているものの、その意味合いは互いに大きく異る。例えば、その年の会社の月別の売上を例にしよう。12本の棒が、各月ごとにあがった売上の金額を示している。(<xref linkend="FIG0618"/>).</simpara>
<figure id="FIG0618"><title>シンプルな棒グラフはそれぞれ個別のものを表現するのに役立つ。</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-TT-04.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-TT-04.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>では、なぜこの場合には折れ線グラフではなくて棒グラフが良いのか見ていこう。折れ線グラフは継続的なデータにとって理想的なグラフである。この売上の数字は、各月の売上の合計であり、継続的なものではない。棒グラフからは、会社が1月に100ドル、そして2月には120ドルの売上を上げたことがわかる。もしこれを折れ線グラフで描いた場合でも、最初の2ヶ月に100ドルと120ドル売り上げたことは同様に示す。しかし、折れ線では15日の時点で110ドル会社が売り上げているように見えてしまう。これは事実ではない。このように、棒グラフは個別に独立して数える単位のもを示すのに役立ち、そして一方で折れ線グラフは気温のような継続的な値を示すのに役立つのである。</simpara>
<figure id="FIG0619"><title>シンプルな折れ線グラフ。継続的な値を示すのに役立つ。</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-TT-05.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-TT-05.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>グラフから、8:00の時点で気温は20度であり、9:00の時点では22度であったことがわかる。気温は継続的な値であり、各時点での他の値の合計ではないため、もし折れ線グラフから8:30時点での気温を推測しようとすると、おそらく21度であると推測される。折れ線グラフは各時点での正確な値を指し示すとともに、2つの時点の間の値の推計値も示すのである。</simpara>
<simpara>棒グラフと折れ線グラフは両方とも一連の変数を持つものである。（<xref linkend="FIG0621"/>）これはそれぞれ違う方法で使える、素晴らしい物語ツールである。それでは3つの拠点がある会社の例を見てみよう。</simpara>
<simpara>各月ごとに、各店舗ごとに3つの棒グラフがあり、年間で36本の棒グラフがある。それらを互いに隣同士におくことで、 （<xref linkend="FIG0620"/>）どの月に、どの店舗がもっとも稼いだかを瞬時に知ることができる。これは有益な見方であり、興味深い一つのストーリーであるが、同じデータにはもうひとつの隠れたストーリがある。もしこのバーを重ねあわせたら、各月ごとの棒グラフは一本になり、店舗別にどこが最も稼いだのかを見ることはできなくなるが、今度は会社全体としてもっとも稼いだのはどの月かがわかるようになる。</simpara>
<figure id="FIG0620"><title>棒グラフのグループ。</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-TT-06.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-TT-06.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG0621"><title>積み上げられた棒グラフ</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-TT-07.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-TT-07.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>このどちらも同じ情報の有益な見せ方であるが、同じデータを用いていても2つのストーリーは別である。ジャーナリストとしてデータを扱うにあたってもっとも重要なことは、伝えたいストーリーを選ぶことである。伝えたいことはどの月のビジネスがもっと好調だったかなのか、それともどの店舗が旗艦店であるかなのか？これはひとつの例にすぎないが、この点はデータ・ジャーナリズムが全体を通して本当に重視している点である。遥か先に進んでしまう前に、正しい質問をすることが重要である。ストーリを選ぶことで、どういったビジュアライゼーションを選ぶべきかも見えてくるのである。</simpara>
<simpara>棒グラフと折れ線グラフは、どんなデータ・ジャーナリズムにとっても、まさに食事におけるパンとバターのような関係のものである。そこからヒストグラムや、面グラフ、スパークライン、ストリーム・グラフなどに展開していくこともできる。これらは似たような性質を持ちながらも、データ量やデータ・ソース、文章のどの位置にグラフを入れるのかなど僅かな場面の違いよって、適しているものが変わってくるのである。</simpara>
<simpara>ジャーナリズムにおいて、最もよく使われる図のひとつに地図がある。時間、量、そして地形は地図に共通したものである。知りたいことはいつも、ある地域と他の地域とでどのくらい差があるのかだったり、データがある地域からから別の地域にどう流れているかだったりする。ジャーナリズムにおけるビジュアライゼーションを行う際に、フロー図とコロプレス図をうまく使えるスキルをもっていると非常に便利である。どのように読者に誤解を与えずに適切に地図を塗り分けるかが鍵である。政治地図であれば、ある地域はいずれかの政党の色で完全に塗られるか無地かのどちらかで、たとえ候補者がたった1%の支持率の差でその地域で勝っているだけだとしてもそのようにするのか一般的である。ただし、必ずしも色付けは二者択一でなされなければならないわけではなく、注意すればグループごとに階調別に塗り分けたりすることもできる。地図を理解することはジャーナリズムにおいて大きな部分を占める。いわゆる5Wの疑問のうち、WHERE＜どこ？＞という疑問に対して、地図は端的に解答をくれるのである。</simpara>
<simpara>基本の図とグラフをマスターしたら、もっと手が込んだデータビジュアライゼーションを作ることもできるようになる。ただ、もし基本をきちんと理解していないと、不安定な土台に建物を建てることになってしまう。いい書き手になるために学んできたこと、例えば文を短くする、常に読み手を意識する、自分を賢く見せるために必要以上に難しくしたりせず、意味を読み手に伝えることに重きをおくこと。そういった事柄から逸脱しないことは、データに関しても同じである。物語を伝える上で、もっとも効率的な方法はまずは小さく始めることである。そして、必要に応じてゆっくり付け足して行けばいいのである。</simpara>
<blockquote>
<attribution>
ウィリアム・ストランク・ジュニア、Elements of Style（表現方法の要素） (1918)
</attribution>
<simpara>良い文章とは簡潔なものである。不必要な言葉を文章は含むべきではなく、不必要な文章を段落は含むべきではなく、同様に絵画には不必要な線はあるべきではなく、機械には不必要な部品はあるべきではない。ただしこれは書き手はすべての文章を短くしなければならないということでも無ければ、はすべての詳細を省いたり、すべてのテーマについて概要のみ取り扱うように、ということではない。すべての言葉は何かを伝えるためのものでなくてはならない、ということである。</simpara>
</blockquote>
<simpara>すべてのデータをストーリの中に入れ込む必要があるけわではない。簡潔にすることに対して許可を求めるようなことは必要なく、それはあくまでルールとしてあるべきことである。</simpara>
<simpara>&mdash; <emphasis>Brian Suda, (optional.is)</emphasis></simpara>
</section>
<section id="_データ_ビジュアライゼーション_diy_便利なツール">
<title>データ・ビジュアライゼーション・DIY：便利なツール</title>
<simpara>誰もが無料で使えるビジュアライゼーションツールはウェブ上にどれだけあるのだろうか。たとえば上の図はガーディアンのサイト「Datablog and Datastore」にあったものだ。ウェブにある無料のツールを利用して、できるだけ同じものを作ってみよう。</simpara>
<simpara>ただしこれは少々、意地が悪く聞こえるかもしれない。というのも我々はガーディアンが持つ驚くべきグラフィックやインタラクティブなチームを利用できるからだ。それらがあれば、「map of public spending」（http://bit.ly/guardian-spending アドビのイラストレーターを利用）や「Twitter riots interactive」（http://bit.ly/guardian-riots）なども少しの時間で作れるはずだ。</simpara>
<simpara>しかし日常業務において我々は、誰でも使えるツールを使い、誰でも作れるグラフィックを作ってしまいがちだ。</simpara>
<simpara>では、いったい何を使えばいいのだろうか。</simpara>
<section id="_google_fusion_tables">
<title>Google Fusion Tables</title>
<simpara>このGoogleによるオンライン・データベースおよびマッピングツールは、素早く詳細なマップを作るためのデフォルトツールになっている。ズームの動きが必要な場合には特に欠かせない。すべてのGoogleマップをハイレゾで利用できる。しかも100MBという大量のCSVを一瞬で開くことができる。我々はFUSION TABLEを使ってこのイラク上空のマップ（FIG0622）を作ったり、ホームレスの境界線を描いたマップ（FIG0623）を作った。</simpara>
<figure id="FIG0622"><title>ウィキリークスの戦争記録 (the Guardian)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-LL-01.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-LL-01.jpg</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG0623"><title>Homelessness interactive map (the Guardian)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-LL-02.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-LL-02.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>もっとも優れたところはその柔軟性だ。地域の境界を示すKMLファイルをアップすれば、それをデータテーブルと統合できる。もちろん使いやすいユーザーインターフェースも提供される。</simpara>
<simpara>これを作るのにプログラマーである必要はない。また、このFusion layers toolを使えば、異なる地図を一緒に並べたり、検索・フィルタといったオプションを加えたりできる。それをブログやウェブサイトに貼り付けることも可能だ。</simpara>
<simpara>Gooogleのキャサリン・ハーレイによる素晴らしいチュートリアルがある。これはスタートポイントに最適だ。</simpara>
<?dbfo-need height="2in"?>
<note>
</note>
</section>
<section id="_tableau_public">
<title>Tableau Public</title>
<formalpara><title>shipファイルをFusion tables形式に変換するのならshpescapeが使える。一方で地図が複雑になりすぎてしまうところに注意したい。Fusion tableは1セルあたり100万ポイント以上になると処理しきれない。</title><para>Tableau Publicもプロ版の容量無制限サービスを使わないならば無料だ。シンプルに、しかも簡単にビジュアライズできる。10万項目の生データまで扱える。これは異なる形式のチャートを統合するときに使う。たとえば「世界で最も税率の高い地域」は地図に加えて棒グラフも併せ持っている。</para></formalpara>
<simpara>あるいはデータ探索のためにも使える。たとえば、http://datajournalismhandbook.org/1.0/en/delivering_data_7.html　ここで我々が行ったことが当てはまる。無料版で与えられている容量は使い果たしてしまったが、そこは注意しておこう。またTableauを使い倒すには、特殊な方法でフォーマットしたデータが必要になる。だがそこさえ理解できていれば、あとは直感的に作業が進むようになるだろう。　たとえば、アルゼンチンのNACION Data（http://blogs.lanacion.com.ar/data/）はTableauを使って完璧なデータジャーナリズムを組み立ててきた。</simpara>
<figure id="FIG0624"><title>2012 Presidential Campaign Finance (the Guardian)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-LL-03.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-LL-03.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>Tableauにはよくできたオンライン・チュートリアルがあります。まずはこちらから始めましょう。http://www.tableausoftware.com/learn/training</simpara>
<note>
<simpara>TableauはWindows向けに作られています。Mac版は計画中とのことですので、Macで動かすためにはParallelsのようなソフトウェアを使いましょう。</simpara>
</note>
</section>
<section id="_google_spreadsheet_charts">
<title>Google Spreadsheet Charts</title>
<simpara>Google Spreadsheet Chartsはこちらからアクセス。 <ulink url="http://www.google.com/google-d-s/spreadsheets/">http://www.google.com/google-d-s/spreadsheets/</ulink></simpara>
<figure id="FIG0625"><title>UK government spending and taxation (the Guardian)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-LL-04.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-LL-04.jpg</phrase></textobject>
</mediaobject>
</figure>
<simpara>棒グラフ、折れ線グラフ、円グラフのような単純なサンプルだけでなく、Google spreadsheets（Googleアカウントがあれば作れる）でもっと素晴らしいグラフが作成できることに気づくだろう。Hans Roslingによる「Gapminder」 <ulink url="http://www.gapminder.org/">http://www.gapminder.org/</ulink> のようにバブルがアニメーションするようなものだってできる。charts API <ulink url="https://developers.google.com/chart/?csw=1">https://developers.google.com/chart/?csw=1</ulink> と違って、コードについて悩む必要もない。エクセルでグラフを作るのによく似ている。データをハイライトして、グラフのウィジェットをクリックするだけだ。カスタマイズオプションは試す価値がある。色や項目、目盛りを変えられる。これらはとても控えめなデザインなので、小さいグラフの場合には便利だ。折れ線グラフにも良いオプションがあって、「注釈」をつけることができる。</simpara>
<note>
<simpara>グラフのカスタマイズオプションに時間を割いてみよう。自分なりのカラーパレットを作ることができる。</simpara>
</note>
</section>
<section id="_datamarket">
<title>Datamarket</title>
<simpara>データ提供者としての方が有名だが、<ulink url="http://bit.ly/datamarket-explore">Datamarket</ulink> は数値を可視化するのにとても素晴らしいツールでもある。自分のデータをアップロードしてもよいし、サイトが提供しているたくさんのデータセットのいくつかを使うこともできるが、プロアカウントを購入するとよりよい選択肢が得られるだろう。</simpara>
<note>
<simpara>Datamarket は時系列データについて最もうまく機能する。ただし、広範なデータ範囲には留意すること。</simpara>
</note>
</section>
<section id="_many_eyes">
<title>Many Eyes</title>
<simpara>たくさんの思いやりのある世話を必要としているサイトがあるとすれば、それは IBM の<ulink url="http://ibm.co/ibm-manyeyes">Many Eyes</ulink> だろう。<ulink url="http://fernandaviegas.com/">Fernanda B. Viégas</ulink> と <ulink url="http://www.bewitched.com/">Martin Wattenberg</ulink> に作られたこのサービスが始まった時、利用者が単にデータセットをアップロードするだけで可視化できるというのは他に例を見ない試みだった。現在は、その製作者たちが Google で働くようになったためか、くすんだ色調のサイトは心なしか愛想をつかされているように見える。可視化についてはここのところあまり更新が見られない。</simpara>
<figure id="FIG0627"><title><ulink url="http://bit.ly/guardian-dr-who">Doctor Who villains</ulink>; the Guardian</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-LL-06.jpg"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-LL-06.jpg</phrase></textobject>
</mediaobject>
</figure>
<note>
<simpara>一度アップロードしたらデータを編集することはできないので、作成前に正しく用意できているか確認したほうが良い。</simpara>
</note>
<?dbfo-need height="2in"?>
</section>
<section id="_color_brewer">
<title>Color Brewer</title>
<simpara>厳密には可視化のツールではないが、<ulink url="http://colorbrewer2.org/">Color Brewer</ulink> は地図の色を選ぶのに非常に有用だ。ベースとなる色を選んだら、パレット全体の色コードが得られる。</simpara>
</section>
<section id="_その他">
<title>その他</title>
<simpara>もし、これらで満足できなければ、 <ulink url="http://bit.ly/dailytekk-infographic">DailyTekk piece</ulink> もチェックしてみる価値がある。さらに多くの選択肢が提示されている。ここまで上げた選択肢が全てではなく、私たちが頻繁に使うものを紹介しただけだ。他にも沢山ある。例えば:</simpara>
<itemizedlist>
<listitem>
<simpara>
<ulink url="http://chartsbin.com/">Chartsbin</ulink>, クリックできる世界地図をつくるためのツール
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="http://www.icharts.net/">iCharts</ulink> 小さなグラフウィジェットに特化している
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="http://geocommons.com/">Geocommons</ulink> 世界地図やローカルな地図を作るためのデータと境界線データを共有してくれている
</simpara>
</listitem>
<listitem>
<simpara>
おっと、これもあった <ulink url="http://piktochart.com/">piktochart.com</ulink> 。今人気があるテキストや数字の可視化のためのテンプレートを提供してくれている。
</simpara>
</listitem>
</itemizedlist>
<simpara>&mdash; <emphasis>Simon Rogers, the Guardian</emphasis></simpara>
</section>
</section>
<section id="_ヴェルデンス_ガングではデータをどう使っているか">
<title>ヴェルデンス・ガングではデータをどう使っているか</title>
<simpara>ニュースジャーナリズムとは、新しい情報をできるだけ迅速に読者に届けることである。最も早い手段として、ビデオ、写真、文章、グラフ、表、それらの組み合わせが考えられる。ビジュアライゼーションに関心を向ける目的も同じであろう。つまり、素早く理解できる情報を届けるためである。データに関する新たなツールを使うことで、そのツールでなければ見つけることのできないストーリーを見つけ出すことや、今あるストーリーに新たな文脈を与えることが可能となる。ここではノルウェーで最も読まれている新聞「ヴェルデンス・ガング」の事例を紹介する。</simpara>
<section id="_数値">
<title>数値</title>
<simpara><ulink url="http://bit.ly/vg-lotto">この記事</ulink>はノルウェー統計局、納税者、国営ロト企業のデータを元に書かれている。このインタラクティブなグラフを使い、ノルウェーの地域や地方自治体の様々なデータを見ることができる。このグラフの元データを見ると、税収の数パーセントがロトによるものであることが分かる。このグラフはAccess, Excel, MySQL, Flashといった技術を使って作成された。</simpara>
<?dbfo-need height="2in"?>
</section>
<section id="_ネットワーク">
<title>ネットワーク</title>
<simpara>我々は、ソーシャルネットワークの分析を行い、ノルウェーで最もお金持ちだった人物の157人の子孫の関係を調査した。我々の分析結果によると、相続人たちはお金だけではなく、親のネットワークも相続していることが分かった。26,000以上のつながりがあったが、全てフォトショップで手描きして図を作成した。その際、Access, Excel, メモ帳、ソーシャルネットワーク分析ツール <phrase role='keep-together'>Ucinet</phrase>を使用した。</simpara>
<figure id="FIG0631"><title>納税者と国営ロトのデータをマッピングしたもの （ヴェルデンス・ガング）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-RR-01.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-RR-01.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="FIG0632"><title>類は友を呼ぶ （ヴェルデンス・ガング）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-RR-02.png" scale="95"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-RR-02.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_マップ">
<title>マップ</title>
<simpara>この<ulink url="http://bit.ly/vg-heatmap">バーチャートを合成して作った、動的なヒートマップ</ulink>で、週末のオスロのダウンタウンで一時間毎に起こった犯罪の件数を、数か月分、見ることができる。また、このヒートマップで、その時間帯に何人の警察官が働いていたのかを確認することができる。事件が発生してしまうのは、警察官の数が原因なのだ。このヒートマップは、ArcViewとSpatial Analystによって作成された。</simpara>
<figure id="FIG0633"><title>動画形式のヒートマップ （ヴェルデンス・ガング）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-RR-03.png" scale="96"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-RR-03.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_テキストマイニング">
<title>テキストマイニング</title>
<simpara>我々はノルウェーにある7政党の党大会の講演内容をテキストマイニングし、<ulink url="http://bit.ly/vg-vis">公開</ulink>しました。全てのスピーチが分析され、様々なストーリーに利用されました。どのストーリーもグラフにリンクしていて、読者は政治家の言葉を調べたり調べることができたのです。これはExcel, Access, Flash, Illustratorで作成されました。もし2012年であれば、Javasciptでインタラクティブなグラフを作ったことでしょう。</simpara>
<figure id="FIG0634"><title>党代表のスピーチをテキストマイニングしたもの （ヴェルデンス・ガング）</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-RR-04.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-RR-04.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_結論">
<title>結論</title>
<simpara>どんなときにストーリーをビジュアライズすればよいのだろうか？読者の理解を助けたいという場合を除き、たいていの場合は必要ない。ストーリーには大量のデータが含まれているので、ビジュアライザーションが必要となるときがあるのだ。どのデータをビジュアライズするかは非常に重要である。我々が何かについて報道するとき、そこに含まれるものについては何でも分かっている。だが読者がストーリーを把握するために本当に必要なものは何であろうか？ある年からある年までの発展を見せるのであれば、おそらく表や単純なグラフで十分だろう。データジャーナリズムの仕事をするとき重要なのは、大量のデータを見せることではない。データジャーナリズムは、あくまでジャーナリズムなのだ！</simpara>
<simpara>読者が異なるテーマを掘り下げることができるようにするため、インタラクティブなグラフや表を作るというトレンドが、この2-3年明確に続いている。よいビジュアライザーションというのは、よい写真のようなものだ。それが何であるか、見た一瞬あるいは少しの間に理解することができる。ビジュアルを見れば、それだけ理解することができるということだ。読者が使い方を理解できないビジュアライゼーションはよくない。詳細に関する情報が多すぎるのもそうだ。この事例は、テキストで構成するのが良いと考えたのだが、どうだろうか？</simpara>
<simpara>ジョン・ボーンズ, ヴェルデンス・ガング</simpara>
</section>
</section>
<section id="_パブリックデータがソーシャルになる_public_data_goes_social">
<title>パブリックデータがソーシャルになる（Public Data Goes Social）</title>
<simpara>データははかりしれないほど貴重だ。データへのアクセスは争点に結果をもたらす方法で光を当てる、潜在的な力を持つ。しかしながらデータを下手に扱うと、何事も伝えない、曖昧な構造の中に事実を置いてしまう。もしデータが議論を促進したり文脈の理解を提供しないならば、データは公衆にとってわずかな価値しかないかもしれない。</simpara>
<simpara>ナイジェリアは長期にわたる軍政の後、1999年に民主政に復帰した。データの背後にある事実を調査することは権力者に侮辱と受け取られ、軍事政権の汚れた評判にさらに疑問を投げかけようとするものと見られた。公務員秘密保護法は公僕に政府情報を共有させないように強制した。民主化復帰から13年経った後でも、パブリックデータにアクセスすることは困難な任務でありえる。公共支出に関するデータは、会計と複雑な計算に精通していない大部分の公衆には、ほとんど何も伝えない。</simpara>
<simpara>モバイル端末の発達とナイジェリア人のインターネット利用人口の増加に伴い、我々はBudgITで、データ視覚化技術を用いて人々に公共支出について説明し関与させる大きな機会を見出した。このために、我々は全てのプラットフォームをまたがってユーザーと関わり、NGOを通じて人々と接触する必要があった。このプロジェクトはパブリックデータを公共物とし、変化を求める広範囲なネットワークを構築するものだ。</simpara>
<figure id="FIG0635"><title>予算削減アプリ (BudgIT ナイジェリア)</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="figs/incoming/06-YY.png"/>
  </imageobject>
  <textobject><phrase>figs/incoming/06-YY.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>うまくユーザーと関わるためには、我々は彼らが何を欲しているかを理解する必要がある。ナイジェリア市民は何を気にかけているのか？彼らはどこに情報ギャップを感じているのか？我々はどのようにしてデータを彼らの生活に関連づけることができるか？BudgITの当面のターゲットは、オンラインフォーラムやソーシャルメディアに接続した平均的な読み書き能力を持つナイジェリア人である。広範な興味（ゲーム、読むこと、友達づきあい）にひたっているユーザーの限られた注意力に対抗するため、我々はデータを手短に簡潔な方法で見せる必要がある。ツイートやインフォグラフィックでデータのスナップショットを拡散した後には、ユーザーにより大きな絵を見せるため、より双方向な経験によるより持続的な参加の機会がある。</simpara>
<simpara>データを視覚化する時は、我々のユーザーのデータリテラシーのレベルを理解することが重要だ。レベルと同じだけ美しく洗練されていてもよい。複雑なダイヤグラムや双方向アプリケーションは、以前のデータ理解経験にもとづく我々のユーザーに十分に伝えることができないかもしれない。よい視覚化はユーザーに対して、彼らが理解できる言語で語りかけ、彼らが簡単に関わりをもつことができるストーリーを生み出すものだ。</simpara>
<simpara>我々は予算について10,000人以上のナイジェリア人と関わってきた、そして最大の価値をもたらすことを確実にするために、我々は彼らを3つのカテゴリーにプロファイルした。カテゴリーは簡単に以下のとおり説明される。</simpara>
<variablelist>
<varlistentry>
<term>
偶発的ユーザー（Occasional users）
</term>
<listitem>
<simpara>
  これらは情報を簡単かつ素早く欲するユーザーである。彼らはデータのイメージを得ることに関心があり、詳細な分析には関心がない。我々は彼らとツイートや双方向グラフィックを通じて関わることができる。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
活動的ユーザー（Active users）
</term>
<listitem>
<simpara>
  議論に刺激を与え、取り上げられた地域に関する知識を増やすためにデータを使い、データの仮定に挑戦するユーザーである。こうしたユーザーには、我々はフィードバックメカニズムと、ソーシャルネットワーク上で彼らの仲間と洞察を共有する可能性を提供したい。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
データ食らい（Data hogs）
</term>
<listitem>
<simpara>
  これらのユーザーは視覚化や分析のために生データを欲している。我々は単純に、彼らの目的のためにデータを渡す。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<?dbfo-need height="1in"?>
<simpara>BudgITでの、我々のユーザーとの関係性は次のことに基礎をおいている。</simpara>
<variablelist>
<varlistentry>
<term>
最近のトレンドに関連した議論を刺激すること（Stimulating discussion around current trends）
</term>
<listitem>
<simpara>
  BudgITはオンラインとオフラインの議論を追跡し続け、これらのトピックにデータを提供しようとしている。例えば、2012年1月の燃料ストライキでは、燃料補助金を元に戻し贅沢で不必要な公共支出を削減する必要性について、抗議者の間から絶えず扇動があった。BudgITはソーシャルメディア上の議論を追いかけ、36時間後には、市民がナイジェリアの予算を再編成することを可能にするアプリを構築した。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
良好なフイードバックメカニズム（Good feedback mechanisms）
</term>
<listitem>
<simpara>
  我々は議論のチャンネルとソーシャルメディアを通じてユーザーを関わっている。多くのユーザーはデータの背後にあるストーリーを知りたがっており、多くは我々の意見を求めている。我々は、我々の応答がデータの背後にある事実を説明しているだけであり、我々の個人的な見解や政治的な見解によって偏らされていないことを確認した。我々は、データの周りに築かれたコミュニティが存続することを確かにするために、フィードバックチャンネルを開け続け、活発にコメントに応答しユーザーと創造的に関わる必要がある。
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ローカル化せよ（Make it local）
</term>
<listitem>
<simpara>
  特定の集団を対象にしたデータセットのため、BudgITはコンテンツをローカライズし、ユーザーの中の特定グループのニーズと興味につながる議論のチャンネルの発展を目指している。特に、ショートメッセージングサービス上でユーザーが気にかけている争点の周囲にいるユーザーと関わりを持つことに、我々は関心を抱いている。
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>支出データをyourbudgit.comで利用可能にした後、我々は様々なNGOを通じて市民に接触している。我々は、市民と政府機関がタウンホールで会合し、優先順位をつける必要がある予算のキー項目を定義することができる、参加的な枠組みを発展させようとも計画している。</simpara>
<simpara>このプロジェクトは、<ulink url="http://bit.ly/cp-africa-budget">CP-Africa</ulink> から <ulink url="http://bbc.in/africa-budget">BBC</ulink>までの地域と外国メディアで報道された。我々はAP記者Yinka Ibukunのために、2002年から2011年までの防衛部門の予算の検査を請け負った。ほとんどのメディア組織は「データ食らい」であり、ルポルタージュに使うため我々にデータを求めてきた。我々は来月に、ジャーナリストやニュース組織とのさらなる協働を計画している。</simpara>
<simpara>&mdash; <emphasis>Oluseun Onigbinde, BudgIT ナイジェリア（Nigeria）</emphasis></simpara>
</section>
<section id="_データに人を惹きつける">
<title>データに人を惹きつける</title>
<simpara>データを公開するというのは、読者から反応をもらうのと同じくらい重要なことである。あなたは人間なので、間違いもおかすし、何か見落としたりもする。時々は間違った考えをすることだってある。読者はあなたが手に入れた資産の中でも最も有用なものだ。あなたが気づかなかった事実確認や指摘をしてくれるのが彼らなのだ。</simpara>
<?dbfo-need height="1in"?>
<simpara>だが、読者を引きつけるというのはなかなかの難題だ。あなたが相手にしているのは、ウェブサイトからウェブサイトへと飛び回り、通った後には皮肉交じりのコメントしか残さない、そんなことを何年もやっているような連中だ。あなたとユーザの間に信頼を構築することはきわめて重要である。彼らは自分達が得られるものが何なのか知りたいと思っているし、その内容についてレスポンスする手段を知りたいと思っている。そして、レスポンスの中身をきちんと読んでもらいたいとも思っているのだ。</simpara>
<simpara>だが、あなたがまず考えなければいけないのは、既にいる読者や、これから読者になってくれる人達のことだ。彼らは、あなたが取り扱うようなデータの提供者になるかもしれないし、データの利用者になるかもしれない。もし、あなたの記事が特定の業種に関するものであれば、あなたは業界固有のコミュニケーション経路について知りたいと思うのではないだろうか。あなたはよりたくさんの読者に読んでもらうべく記事を作った。それを周知してくれるであろう業界団体と関係を深めているだろうか？　関係構築したいと思うコミュニティサイトやフォーラムはあるか？　あなたがデータから導き出したストーリーを掲載してもらいたいと思う、業界紙があるだろうか？</simpara>
<simpara>ソーシャルメディアも重要なツールだが、これも、あなたが使っているデータ次第というところがある。例えばあなたが国際貿易の統計を調査していたとして、あなたのやっていることに関心を示すFacebookグループやTwitterユーザを見つけることは難しいだろう。一方、もしあなたが世界の経済指標や地元の犯罪統計から有益な情報だけ選り分けたのであれば、より多くの読者の興味を引くだろう。</simpara>
<simpara>Twitterで最適なアプローチとして、人目を引くようなプロフィール、あなたのやったことの重要さが分かる簡潔な説明、それからリンクを含める、というのがある。運が良ければ、Twitterユーザは彼らのフォロワーに対してリツイートを行ってくれる。それは、あなたの仕事が人目に触れる機会を、最小の労力で最大化する素晴らしい方法だ　――しかも人々を煩わせることがない！</simpara>
<simpara>いったん人々があなたのページを開いたのであれば、次に考えるのは読者はどうやってあなたの記事に興味を持つようになるのかだ。もちろん、彼らはあなたの書いた記事を読み、インフォグラフィックスや地図を見る。あなたに意見をよこす顧客は非常に貴重だ。何より、あなたが書いた記事の主題や今後の課題について、素晴らしい洞察を与えてくれるからだ。</simpara>
<simpara>まず、言うまでもないが、あなたは記事と合わせて、生のデータを公開する必要がある。方式はCSV形式でも、GoogleDocsのようなサードパーティのサービスを介してでも構わない。ただし、公開するデータのバージョンは１つだけにし、データに間違いがあり修正しなければいけない場合など、必要に応じてそれを更新するようにする。さらに良いのは、両方の形式で公開し、読者ができるだけ簡単にデータを手に入れられるようにすることだ。</simpara>
<simpara>読者が関心を持つ事柄が他にもないか考えてみよう。あなたが作ったデータセットのどこに関心が集まっているのかを知るため、アクセス情報には常に目を光らせよう。最もトラフィック量の多い場所には、あなたが見落としているが語るに値する、そんな何かがあるだろう。例えば、あなたはアイスランドの貧困に関する統計を見ようとは思っていないかもしれないが、それらのセルに注目が集まっているのであれば、そこには何か観察に値する何かがあるだろう、ということだ。</simpara>
<?dbfo-need height="1in"?>
<simpara>コメントボックスを超えて考えよう。あなたのスプレッドシートは、セルにコメントを付けることはできるだろうか？インフォグラフィックの任意の部分にコメントを付けることは？大半の拡張可能なパブリッシングシステムにおいて、そのような機能が最初から組み込まれていることはない。だが、あなたが作っているものに、何かしらオーダーメードできる部分が含まれているのであれば、考えてみる価値はある。それがあなたのデータにもたらす価値を過小評価してはいけない。</simpara>
<simpara>他のユーザもコメントが見られるようにしよう。大抵の場合、それらは元のデータと同じくらいの価値を持っているからだ。もしあなたしかコメントを見ることができないのであれば、それは読者からその分の価値を奪っているのと同じことだ。</simpara>
<simpara>最後に。あなたが使ったのと同じデータを元に、インフォグラフィックスや記事を作りたいと思う人が出てくるかもしれない。彼らがどのようなものを作るか、どうすれば上手く結び付けられることができるかを考えてみよう。例えば、データセットに関するハッシュタグを作ることができるかもしれないし、絵が入っているものならFlickrでシェアするのも良いかもしれない。</simpara>
<simpara>情報を秘密で共有する方法を知っていることが役に立つこともある　――そうした方が、データセットの作成に貢献した人達が安全な場合もあるからだ。あるいは、単純に、公開されることを心地よく感じない人もいる。そのような人達は、電子メールでのコメントや匿名のコメントボックスをより好むのだ。</simpara>
<simpara>データに関して一番重要なのは、できるだけ広くオープンに情報を共有することだ。読者があなたの仕事をチェックしたり、間違いを見つけたり、あなたが見落としていることを指摘できるようにするのだ。そうすることで、あなたのジャーナリズムと、読者のエクスペリエンスは際限なく良くなっていくだろう。</simpara>
<simpara>&mdash; <emphasis>ダンカン・ジーレ, 英ワイアード</emphasis></simpara>
</section>
</section>
</article>
